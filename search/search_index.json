{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>This site contains the project documentation for the <code>mmushell</code> project, an OS-Agnostic memory morensics tool, a proof of concept for techniques developed by Andrea Oliveri and Davide Balzarotti in \"In the Land of MMUs: Multiarchitecture OS-Agnostic Virtual Memory Forensics\".</p>"},{"location":"#table-of-contents","title":"Table of contents","text":"<p>The documentation follows the best practice for project documentation as described by Daniele Procida in the Di\u00e1taxis documentation framework and consists of four separate parts:</p> <ol> <li>Tutorials</li> <li>How-To Guides</li> <li>Reference</li> <li>Explanation</li> </ol> <p>Quickly find what you're looking for depending on your use case by looking at the different pages.</p>"},{"location":"explanation/","title":"Explanation","text":"<p>The first step required to perform any analysis of a physical memory image is the reconstruction of the virtual address spaces, which allows translating virtual addresses to their corresponding physical offsets. However, this phase is often overlooked, and the challenges related to it are rarely discussed in the literature. Practical tools solve the problem by using a set of custom heuristics tailored on a very small number of well-known operating systems (OSs) running on few architectures.</p> <p>In the whitepaper, we look for the first time at all the different ways the virtual to physical translation can be operated in 10 different CPU architectures. In each case, we study the inviolable constraints imposed by the memory management unit that can be used to build signatures to recover the required data structures from memory without any knowledge about the running OS.</p> <p>This tool allows to experiment with the extraction of virtual address spaces, showing the challenges of performing an OS-agnostic virtual to physical address translation in real-world scenarios. It was tested on a large set of 26 different OSs, 6 architectures and a use case on a real hardware device.</p>"},{"location":"tutorials/","title":"Tutorials","text":""},{"location":"tutorials/#organisation","title":"Organisation","text":"<ul> <li><code>mmushell/architectures/</code> : various architectures parsers and a generic one</li> <li><code>mmushell/mmushell.py</code> : main script allowing to reconstruct virtual address spaces from a memory dump, more instructions below</li> <li><code>mmushell/exporter.py</code> : this is a POC showing the possible use of techniques to perform a preliminary analysis of a dump by exporting each virtual address space as a self-contained ELF Core dump file. See section TOWARDS OS AGNOSTIC MEMORY FORENSICS.</li> <li><code>converter.py</code> : export dump to be used in Fossil. It adds CPU registers and convert the kernel physical address space in virtual address space one. Note: you can ignore this script, is not part of mmushell</li> <li><code>qemu/</code> : contains scripts and patch necessary to get ground truth registers values from an emulated system</li> </ul>"},{"location":"tutorials/#quick-installation","title":"Quick installation","text":"<p>On a standard Linux distribution : <pre><code>$ python -m venv --system-site-packages --symlinks venv\n$ venv/bin/pip install -r requirements.txt\n</code></pre></p> <p>On Nix/NixOS : <pre><code>$ nix develop\n# or with direnv\n$ direnv allow .\n</code></pre></p>"},{"location":"tutorials/#usage","title":"Usage","text":""},{"location":"tutorials/#dataset","title":"Dataset","text":"<p>Here part of the dataset containing the memory dumps of the OSs used in the paper (only the open-source ones, due to license restrictions).</p> <p>In each archive there are a minimum of 4 files and require at least 4GB of free space (decompressed):</p> <ul> <li> <p><code>XXX.regs</code> : contains the values of the registers collected by QEMU during the execution (the ground truth), pickle format, to be used (optionally) with --gtruth option of mmushell</p> </li> <li> <p><code>XXX.yaml</code> : contains the hardware configuration of the machine which has run the OS, YAML file, to be used as argument of mmushell</p> </li> <li> <p><code>XXX.dump.Y</code> : chunk of the RAM dump of the machine</p> </li> <li> <p><code>XXX.lzma</code> : an mmushell session file, it contains the output of mmushell, pickle lzma format, to be used (optionally) with <code>--session</code> option of mmushell</p> </li> </ul> <p>The use of <code>XXX.lzma</code> allows to avoid reexecuting the parsing and data structure reconstructing phase, gaining time!</p>"},{"location":"tutorials/#cli","title":"CLI","text":"<p>MMUShell must be run in the folder containing dump/configuration files as all the paths are relatives.</p> <p>Warning</p> <p>Some OSs require a minimum of 32GB of RAM to be parsed (the Intel 32bit ones, in particular HaikuOS) or a minimum of 1 hour of execution (independently by the number of the CPU cores, Intel 32/PAE/IA64 OSs)</p> <p>Consider using the session file for them to gain time.</p> <p>Help :</p> <pre><code>$ mmushell.py\nusage: mmushell.py [-h] [--gtruth GTRUTH] [--session SESSION] [--debug] MACHINE_CONFIG\nmmushell.py: error: the following arguments are required: MACHINE_CONFIG\n</code></pre> <ol> <li>Dump all the RAM areas of the machine that you want to analyze in raw format, one file per physical memory area.</li> <li> <p>Create a YAML file describing the hardware configuration of the machine (see the examples available in the dataset)     The format is the following :     <pre><code>cpu:\n    # Architecture type\n    architecture: (aarch64|arm|intel|mips|ppc|riscv)\n\n    # Endianness level\n    endianness: (big|little)\n\n    # Bits used by architecture\n    bits: (32|64)\n\nmmu:\n    # MMU mode varying from architectures\n    mode: (ia64|ia32|pae|sv32|sv39|sv48|ppc32|mips32|Short|Long) # any class that inherits from MMU\n    #        ^^^^^^^^^     ^^^^^^^^^^    ^^    ^^^     ^^^^^^\n    #          intel         riscv      ppc    mips      arm\n\nmemspace:\n    # Physical RAM space region\n    ram:\n      - start: 0x0000000080000000 # ram start address\n        end:   0x000000017fffffff # ram end address\n        dumpfile: linux.dump\n\n    # Physical memory regions that are not RAM\n    # Example: reserved regions for MMIO, ROM, ... See https://en.wikipedia.org/wiki/Memory-mapped_I/O_and_port-mapped_I/O#Examples\n    # Those portions are needed because page tables also maps these special physical addresses, so the CPU can use these associated\n    # virtual addresses to write or read from them. We need to distinguish them otherwise we can misinterpret some page tables as data pages.\n    not_ram:\n      - start: 0x0000000000000000\n        end: 0x0000000000011fff\n\n      - start: 0x0000000000100000\n        end: 0x0000000000101023\n    # ...\n</code></pre></p> </li> <li> <p>Launch mmushell with the configuration file. Example with the provided RISC-V SV39 memory dump :     <pre><code>$ mmushell.py dataset/riscv/sv39/linux/linux.yaml\nMMUShell.   Type help or ? to list commands.\n\n[MMUShell riscv]# ?\n\nDocumented commands (type help &lt;topic&gt;):\n========================================\nexit              help     parse_memory  show_radix_trees\nfind_radix_trees  ipython  save_data     show_table\n</code></pre>     Use the interactive shell to find MMU registers, Radix-Trees, Hash tables etc. and explore them. The <code>help</code> command lists all the possible actions available for the selected CPU architecture.</p> </li> </ol>"},{"location":"tutorials/#ground-truth","title":"Ground truth","text":"<p><code>XXXX_gtruth</code> commands are available only if you load a <code>XXX.regs</code> file as they compare found results with the ground truth. These commands have an equivalent command which show only the results found by MMUShell without comparing them with the ground truth.</p> <p>Note</p> <p>The folder <code>qemu/</code> contains the patch for QEMU 5.0.0 in order to collect the ground truth values of the MMU registers during OSs execution. Please read the concerned README in qemu/README.md.</p>"},{"location":"tutorials/#notes-and-procedures","title":"Notes and procedures","text":"<p>As mmushell available commands differs from one architecture to another, here are different steps needed to be performed in order.</p> <p>Note</p> <p>Steps prefixed with \"*\" are necessary only if you don't use session files (e.g: <code>XXX.lzma</code>).</p> <p>RISC-V</p> <ol> <li>*<code>parse_memory</code> : find MMU tables</li> <li>*<code>find_radix_trees</code> : reconstruct radix trees</li> <li><code>show_radix_trees_gtruth</code> : compare radix trees found with the ground truth</li> </ol> <p>MIPS</p> <ol> <li>*<code>parse_memory</code> -&gt; find MMU opcodes</li> <li>*<code>find_registers_values</code> -&gt; perform dataflow analysis and retrieve registers values</li> <li><code>show_registers_gtruth</code> -&gt; compare registers found with the ground truth</li> </ol> <p>PowerPC</p> <ol> <li>*<code>parse_memory</code> -&gt; find MMU opcodes and hash tables</li> <li>*<code>find_registers_values</code> -&gt; perform dataflow analisys and retrieve registers values</li> <li><code>show_hashtables_gtruth</code> -&gt; compare the hash table found with the ground truth</li> <li><code>show_registers_gtruth</code> -&gt; compare the registers found with the ground truth</li> </ol> Note <p>For Linux Debian, Mac OS X, Morphos : <code>show_hashtables_gtruth</code> shows another Hash Table not retrieved by MMUShell, but it is a table used during startup (as shown by the timestamp) and we ignore it because it does not used during normal OS operation.</p> <p>For Mac OS X : ignore BAT registers values in <code>show_registers_gtruth</code> as it uses different values for each process (as shown by the ground truth), the falses and positives results are purely a coincidence.</p> <p>Intel</p> <ol> <li>*<code>parse_memory</code> -&gt; look for tables and IDT</li> <li>*<code>find_radix_trees</code> -&gt; reconstruct radix trees (could be slow)</li> <li>*<code>show_idtrs_gtruth</code> -&gt; show a comparization between true and found IDTs (note: some OSs define multiple IDTs, one per core). We deliberately ignore IDT table used during the boot phase (see PowerPC notes)</li> <li><code>show_radix_trees_gtruth XXXX</code> -&gt; where XXX must be the PHYSICAL address of the last IDT used by the system shown by show_idtrs_gtruth\". Shows a comparization between true and found radix trees which resolve the IDT PHYSICAL ADDRESS XXXX (obtained by the previous command, for our statistics we always use a true positive one)</li> </ol> Note <p>For BarrellfishOS, OmniOS : those allocate a different IDT for every single CPU core. Some processes are core specific and are able to resolve only the IDT of the same core. For each IDT found, MMUShell shows different proccesses as FN. They are not real false negatives because are the per-core processes which are not able to resolve that specific IDT but are found by MMUShell using one among the other IDT.</p> <p>For RCore : if you enter the physical address of the real IDT used by the system in <code>show_radix_trees_gtruth</code>, MMUShell does not show any entry because it has found a different IDT (a FP) and has no valid radix trees for the real IDT. Please use <code>show_idtrs</code> to show the IDT found (YYY) and <code>show_radix_trees XXXX</code> to show the radix trees associated (all FP).</p> <p>ARM</p> <ol> <li>*<code>find_registers_values</code> -&gt; perform dataflow analysis to recover TTBCR value</li> <li>*<code>show_registers_gtruth</code> -&gt; compare the values retrieved with the ground truth</li> <li>*<code>set_ttbcr XXX</code> -&gt; use REAL value of the TTBCR shown by the previous command</li> <li>*<code>find_tables</code> -&gt; find MMU tables</li> <li>*<code>find_radix_trees</code> -&gt; reconstruct radix trees</li> <li><code>show_radix_trees_gtruth</code> -&gt; compare radix trees found with the ground truth</li> </ol> <p>AArch64</p> <ol> <li>*<code>find_registers_values</code> -&gt; perform dataflow analysis to recover TCR value</li> <li>*<code>show_registers_gtruth</code> -&gt; compare the values retrieved with the ground truth</li> <li>*<code>set_tcr XXX</code> -&gt; use REAL value of the TCR shown by the previous command</li> <li>*<code>find_tables</code> -&gt; find MMU tables</li> <li>*<code>find_radix_trees</code> -&gt; reconstruct radix trees</li> <li><code>show_radix_trees_gtruth</code> -&gt; compare radix trees found with the ground truth</li> </ol>"},{"location":"reference/exporter/","title":"Exporter","text":""},{"location":"reference/exporter/#exporter","title":"Exporter","text":""},{"location":"reference/exporter/#mmushell.exporter.AddressTranslator","title":"<code>AddressTranslator</code>","text":"Source code in <code>mmushell/exporter.py</code> <pre><code>class AddressTranslator:\n    def __init__(self, dtb, phy):\n        self.dtb = dtb\n        self.phy = phy\n\n        # Set machine specifics\n        if self.wordsize == 4:\n            self.word_type = np.uint32\n            if self.phy.machine_data[\"Endianness\"] == \"big\":\n                self.word_fmt = \"&gt;u4\"\n            else:\n                self.word_fmt = \"&lt;u4\"\n        else:\n            self.word_type = np.uint64\n            if self.phy.machine_data[\"Endianness\"] == \"big\":\n                self.word_fmt = \"&gt;u8\"\n            else:\n                self.word_fmt = \"&lt;u8\"\n\n        self.v2o = None\n        self.o2v = None\n        self.pmasks = None\n        self.minimum_page = 0\n\n    def _read_entry(self, idx, entry, lvl):\n        \"\"\"Decode radix tree entry\"\"\"\n        raise NotImplementedError\n\n    def _reconstruct_permissions(self, pmask):\n        \"\"\"Reconstruct permission masks from radix tree entry\"\"\"\n        raise NotImplementedError\n\n    def _finalize_virt_addr(self, virt_addr, permissions):\n        \"\"\"Apply architecture specific virtual address modifications\"\"\"\n        raise NotImplementedError\n\n    def get_data_virt(self, vaddr, size=1):\n        \"\"\"Return data starting from a virtual address\"\"\"\n        size_available, intervals = self.v2o.contains(vaddr, size)\n        if size_available != size:\n            return bytes()\n\n        ret = bytearray()\n        for interval in intervals:\n            _, interval_size, offset = interval\n            ret.extend(self.elf_buf[offset : offset + interval_size].tobytes())\n\n        return ret\n\n    def get_data_phy(self, paddr, size):\n        \"\"\"Return data starting from a physical address\"\"\"\n        return self.phy.get_data(paddr, size)\n\n    def get_data_raw(self, offset, size):\n        \"\"\"Return data starting from an ELF offset\"\"\"\n        return self.phy.get_data_raw(offset, size)\n\n    def _explore_radixtree(\n        self, table_addr, mapping, reverse_mapping, lvl=0, prefix=0, upmask=list()\n    ):\n        \"\"\"Explore the radix tree returning virtual &lt;-&gt; physical mappings\"\"\"\n\n        table = self.phy.get_data(table_addr, self.table_sizes[lvl])\n        if not table:\n            print(\n                f\"Table {hex(table_addr)} size:{self.table_sizes[lvl]} at level {lvl} not in RAM\"\n            )\n            return\n\n        for index, entry in enumerate(iter_unpack(self.unpack_fmt, table)):\n            is_valid, pmask, phy_addr, page_size = self._read_entry(\n                index, entry[0], lvl\n            )\n\n            if not is_valid:\n                continue\n\n            virt_addr = prefix | (index &lt;&lt; self.shifts[lvl])\n            pmask = upmask + pmask\n\n            if (lvl == self.total_levels - 1) or page_size:  # Last radix level or Leaf\n                # Ignore pages not in RAM (some OSs map more RAM than available) and not memory mapped devices\n                in_ram = self.phy.in_ram(phy_addr, page_size)\n                in_mmd = self.phy.in_mmd(phy_addr, page_size)\n                if not in_ram and not in_mmd:\n                    continue\n\n                permissions = self._reconstruct_permissions(pmask)\n                virt_addr = self._finalize_virt_addr(virt_addr, permissions)\n                mapping[permissions].append((virt_addr, page_size, phy_addr, in_mmd))\n\n                # Add only RAM address to the reverse translation P2V\n                if in_ram and not in_mmd:\n                    if permissions not in reverse_mapping:\n                        reverse_mapping[permissions] = defaultdict(list)\n                    reverse_mapping[permissions][(phy_addr, page_size)].append(\n                        virt_addr\n                    )\n            else:\n                # Lower level entry\n                self._explore_radixtree(\n                    phy_addr,\n                    mapping,\n                    reverse_mapping,\n                    lvl=lvl + 1,\n                    prefix=virt_addr,\n                    upmask=pmask,\n                )\n\n    def _compact_intervals_virt_offset(self, intervals):\n        \"\"\"Compact intervals if virtual addresses and offsets values are\n        contigous (virt -&gt; offset)\"\"\"\n        fused_intervals = []\n        prev_begin = prev_end = prev_offset = -1\n        for interval in intervals:\n            begin, end, phy, _ = interval\n\n            offset = self.phy.p2o[phy]\n            if offset == -1:\n                continue\n\n            if prev_end == begin and prev_offset + (prev_end - prev_begin) == offset:\n                prev_end = end\n            else:\n                fused_intervals.append((prev_begin, (prev_end, prev_offset)))\n                prev_begin = begin\n                prev_end = end\n                prev_offset = offset\n\n        if prev_begin != begin:\n            fused_intervals.append((prev_begin, (prev_end, prev_offset)))\n        else:\n            offset = self.phy.p2o[phy]\n            if offset == -1:\n                print(f\"ERROR!! {phy}\")\n            else:\n                fused_intervals.append((begin, (end, offset)))\n        return fused_intervals[1:]\n\n    def _compact_intervals_permissions(self, intervals):\n        \"\"\"Compact intervals if virtual addresses are contigous and permissions are equals\"\"\"\n        fused_intervals = []\n        prev_begin = prev_end = -1\n        prev_pmask = (0, 0)\n        for interval in intervals:\n            begin, end, _, pmask = interval\n            if prev_end == begin and prev_pmask == pmask:\n                prev_end = end\n            else:\n                fused_intervals.append((prev_begin, (prev_end, prev_pmask)))\n                prev_begin = begin\n                prev_end = end\n                prev_pmask = pmask\n\n        if prev_begin != begin:\n            fused_intervals.append((prev_begin, (prev_end, prev_pmask)))\n        else:\n            fused_intervals.append((begin, (end, pmask)))\n\n        return fused_intervals[1:]\n\n    def _reconstruct_mappings(self, table_addr, upmask):\n        # Explore the radix tree\n        mapping = defaultdict(list)\n        reverse_mapping = {}\n        self._explore_radixtree(table_addr, mapping, reverse_mapping, upmask=upmask)\n\n        # Needed for ELF virtual mapping reconstruction\n        self.reverse_mapping = reverse_mapping\n        self.mapping = mapping\n\n        # Collect all intervals (start, end+1, phy_page, pmask)\n        intervals = []\n        for pmask, mapping_p in mapping.items():\n            if pmask[1] == 0:  # Ignore user not accessible pages\n                print(pmask)\n                continue\n            intervals.extend(\n                [(x[0], x[0] + x[1], x[2], pmask) for x in mapping_p if not x[3]]\n            )  # Ignore MMD\n        intervals.sort()\n\n        if not intervals:\n            raise Exception\n        # Fuse intervals in order to reduce the number of elements to speed up\n        fused_intervals_v2o = self._compact_intervals_virt_offset(intervals)\n        fused_intervals_permissions = self._compact_intervals_permissions(intervals)\n\n        # Offset to virtual is impossible to compact in a easy way due to the\n        # multiple-to-one mapping. We order the array and use bisection to find\n        # the possible results and a partial\n        intervals_o2v = []\n        for pmasks, d in reverse_mapping.items():\n            if pmasks[1] != 0:  # Ignore user accessible pages\n                continue\n            for k, v in d.items():\n                # We have to translate phy -&gt; offset\n                offset = self.phy.p2o[k[0]]\n                if offset == -1:  # Ignore unresolvable pages\n                    continue\n                intervals_o2v.append((offset, k[1] + offset, tuple(v)))\n        intervals_o2v.sort()\n\n        # Fill resolution objects\n        self.v2o = IMOffsets(*list(zip(*fused_intervals_v2o)))\n        self.o2v = IMOverlapping(intervals_o2v)\n        self.pmasks = IMData(*list(zip(*fused_intervals_permissions)))\n\n    def export_virtual_memory_elf(self, elf_filename):\n        \"\"\"Create an ELF file containg the virtual address space of the process\"\"\"\n        with open(elf_filename, \"wb\") as elf_fd:\n            # Create the ELF header and write it on the file\n            machine_data = self.phy.get_machine_data()\n            endianness = machine_data[\"Endianness\"]\n            machine = machine_data[\"Architecture\"].lower()\n\n            # Create ELF main header\n            if \"aarch64\" in machine:\n                e_machine = 0xB7\n            elif \"arm\" in machine:\n                e_machine = 0x28\n            elif \"riscv\" in machine:\n                e_machine = 0xF3\n            elif \"x86_64\" in machine:\n                e_machine = 0x3E\n            elif \"386\" in machine:\n                e_machine = 0x03\n            else:\n                raise Exception(\"Unknown architecture\")\n\n            e_ehsize = 0x40\n            e_phentsize = 0x38\n            elf_h = bytearray(e_ehsize)\n            elf_h[0x00:0x04] = b\"\\x7fELF\"  # Magic\n            elf_h[0x04] = 2  # Elf type\n            elf_h[0x05] = 1 if endianness == \"little\" else 2  # Endianness\n            elf_h[0x06] = 1  # Version\n            elf_h[0x10:0x12] = 0x4.to_bytes(2, endianness)  # e_type\n            elf_h[0x12:0x14] = e_machine.to_bytes(2, endianness)  # e_machine\n            elf_h[0x14:0x18] = 0x1.to_bytes(4, endianness)  # e_version\n            elf_h[0x34:0x36] = e_ehsize.to_bytes(2, endianness)  # e_ehsize\n            elf_h[0x36:0x38] = e_phentsize.to_bytes(2, endianness)  # e_phentsize\n            elf_fd.write(elf_h)\n\n            # For each pmask try to compact intervals in order to reduce the number of segments\n            intervals = defaultdict(list)\n            for (kpmask, pmask), intervals_list in self.mapping.items():\n                print(kpmask, pmask)\n\n                if pmask == 0:  # Ignore pages not accessible by the process\n                    continue\n\n                intervals[pmask].extend(\n                    [(x[0], x[0] + x[1], x[2]) for x in intervals_list if not x[3]]\n                )  # Ignore MMD\n                intervals[pmask].sort()\n\n                if len(intervals[pmask]) == 0:\n                    intervals.pop(pmask)\n                    continue\n\n                # Compact them\n                fused_intervals = []\n                prev_begin = prev_end = prev_offset = -1\n                for interval in intervals[pmask]:\n                    begin, end, phy = interval\n\n                    offset = self.phy.p2o[phy]\n                    if offset == -1:\n                        continue\n\n                    if (\n                        prev_end == begin\n                        and prev_offset + (prev_end - prev_begin) == offset\n                    ):\n                        prev_end = end\n                    else:\n                        fused_intervals.append([prev_begin, prev_end, prev_offset])\n                        prev_begin = begin\n                        prev_end = end\n                        prev_offset = offset\n\n                if prev_begin != begin:\n                    fused_intervals.append([prev_begin, prev_end, prev_offset])\n                else:\n                    offset = self.phy.p2o[phy]\n                    if offset == -1:\n                        print(f\"ERROR!! {phy}\")\n                    else:\n                        fused_intervals.append([begin, end, offset])\n                intervals[pmask] = sorted(\n                    fused_intervals[1:], key=lambda x: x[1] - x[0], reverse=True\n                )\n\n            # Write segments in the new file and fill the program header\n            p_offset = len(elf_h)\n            offset2p_offset = (\n                {}\n            )  # Slow but more easy to implement (best way: a tree sort structure able to be updated)\n            e_phnum = 0\n\n            for pmask, interval_list in intervals.items():\n                e_phnum += len(interval_list)\n                for idx, interval in enumerate(interval_list):\n                    begin, end, offset = interval\n                    size = end - begin\n                    if offset not in offset2p_offset:\n                        elf_fd.write(self.phy.get_data_raw(offset, size))\n                        if not self.phy.get_data_raw(offset, size):\n                            print(hex(offset), hex(size))\n                        new_offset = p_offset\n                        p_offset += size\n                        for page_idx in range(0, size, self.minimum_page):\n                            offset2p_offset[offset + page_idx] = new_offset + page_idx\n                    else:\n                        new_offset = offset2p_offset[offset]\n                    interval_list[idx].append(\n                        new_offset\n                    )  # Assign the new offset in the dest file\n\n            # Create the program header containing all the segments (ignoring not in RAM pages)\n            e_phoff = elf_fd.tell()\n            p_header = bytes()\n            for pmask, interval_list in intervals.items():\n                for begin, end, offset, p_offset in interval_list:\n                    p_filesz = end - begin\n\n                    # Back convert offset to physical page\n                    p_addr = self.phy.o2p[offset]\n                    assert p_addr != -1\n\n                    segment_entry = bytearray(e_phentsize)\n                    segment_entry[0x00:0x04] = 0x1.to_bytes(4, endianness)  # p_type\n                    segment_entry[0x04:0x08] = pmask.to_bytes(4, endianness)  # p_flags\n                    segment_entry[0x10:0x18] = begin.to_bytes(8, endianness)  # p_vaddr\n                    segment_entry[0x18:0x20] = p_addr.to_bytes(\n                        8, endianness\n                    )  # p_paddr Original physical address\n                    segment_entry[0x28:0x30] = p_filesz.to_bytes(\n                        8, endianness\n                    )  # p_memsz\n                    segment_entry[0x08:0x10] = p_offset.to_bytes(\n                        8, endianness\n                    )  # p_offset\n                    segment_entry[0x20:0x28] = p_filesz.to_bytes(\n                        8, endianness\n                    )  # p_filesz\n\n                    p_header += segment_entry\n\n            # Write the segment header\n            elf_fd.write(p_header)\n            s_header_pos = (\n                elf_fd.tell()\n            )  # Last position written (used if we need to write segment header)\n\n            # Modify the ELF header to point to program header\n            elf_fd.seek(0x20)\n            elf_fd.write(e_phoff.to_bytes(8, endianness))  # e_phoff\n\n            # If we have more than 65535 segments we have create a special Section entry contains the\n            # number of program entry (as specified in ELF64 specifications)\n            if e_phnum &lt; 65536:\n                elf_fd.seek(0x38)\n                elf_fd.write(e_phnum.to_bytes(2, endianness))  # e_phnum\n            else:\n                elf_fd.seek(0x28)\n                elf_fd.write(s_header_pos.to_bytes(8, endianness))  # e_shoff\n                elf_fd.seek(0x38)\n                elf_fd.write(0xFFFF.to_bytes(2, endianness))  # e_phnum\n                elf_fd.write(0x40.to_bytes(2, endianness))  # e_shentsize\n                elf_fd.write(0x1.to_bytes(2, endianness))  # e_shnum\n\n                section_entry = bytearray(0x40)\n                section_entry[0x2C:0x30] = e_phnum.to_bytes(4, endianness)  # sh_info\n                elf_fd.seek(s_header_pos)\n                elf_fd.write(section_entry)\n</code></pre>"},{"location":"reference/exporter/#mmushell.exporter.AddressTranslator.export_virtual_memory_elf","title":"<code>export_virtual_memory_elf(elf_filename)</code>","text":"<p>Create an ELF file containg the virtual address space of the process</p> Source code in <code>mmushell/exporter.py</code> <pre><code>def export_virtual_memory_elf(self, elf_filename):\n    \"\"\"Create an ELF file containg the virtual address space of the process\"\"\"\n    with open(elf_filename, \"wb\") as elf_fd:\n        # Create the ELF header and write it on the file\n        machine_data = self.phy.get_machine_data()\n        endianness = machine_data[\"Endianness\"]\n        machine = machine_data[\"Architecture\"].lower()\n\n        # Create ELF main header\n        if \"aarch64\" in machine:\n            e_machine = 0xB7\n        elif \"arm\" in machine:\n            e_machine = 0x28\n        elif \"riscv\" in machine:\n            e_machine = 0xF3\n        elif \"x86_64\" in machine:\n            e_machine = 0x3E\n        elif \"386\" in machine:\n            e_machine = 0x03\n        else:\n            raise Exception(\"Unknown architecture\")\n\n        e_ehsize = 0x40\n        e_phentsize = 0x38\n        elf_h = bytearray(e_ehsize)\n        elf_h[0x00:0x04] = b\"\\x7fELF\"  # Magic\n        elf_h[0x04] = 2  # Elf type\n        elf_h[0x05] = 1 if endianness == \"little\" else 2  # Endianness\n        elf_h[0x06] = 1  # Version\n        elf_h[0x10:0x12] = 0x4.to_bytes(2, endianness)  # e_type\n        elf_h[0x12:0x14] = e_machine.to_bytes(2, endianness)  # e_machine\n        elf_h[0x14:0x18] = 0x1.to_bytes(4, endianness)  # e_version\n        elf_h[0x34:0x36] = e_ehsize.to_bytes(2, endianness)  # e_ehsize\n        elf_h[0x36:0x38] = e_phentsize.to_bytes(2, endianness)  # e_phentsize\n        elf_fd.write(elf_h)\n\n        # For each pmask try to compact intervals in order to reduce the number of segments\n        intervals = defaultdict(list)\n        for (kpmask, pmask), intervals_list in self.mapping.items():\n            print(kpmask, pmask)\n\n            if pmask == 0:  # Ignore pages not accessible by the process\n                continue\n\n            intervals[pmask].extend(\n                [(x[0], x[0] + x[1], x[2]) for x in intervals_list if not x[3]]\n            )  # Ignore MMD\n            intervals[pmask].sort()\n\n            if len(intervals[pmask]) == 0:\n                intervals.pop(pmask)\n                continue\n\n            # Compact them\n            fused_intervals = []\n            prev_begin = prev_end = prev_offset = -1\n            for interval in intervals[pmask]:\n                begin, end, phy = interval\n\n                offset = self.phy.p2o[phy]\n                if offset == -1:\n                    continue\n\n                if (\n                    prev_end == begin\n                    and prev_offset + (prev_end - prev_begin) == offset\n                ):\n                    prev_end = end\n                else:\n                    fused_intervals.append([prev_begin, prev_end, prev_offset])\n                    prev_begin = begin\n                    prev_end = end\n                    prev_offset = offset\n\n            if prev_begin != begin:\n                fused_intervals.append([prev_begin, prev_end, prev_offset])\n            else:\n                offset = self.phy.p2o[phy]\n                if offset == -1:\n                    print(f\"ERROR!! {phy}\")\n                else:\n                    fused_intervals.append([begin, end, offset])\n            intervals[pmask] = sorted(\n                fused_intervals[1:], key=lambda x: x[1] - x[0], reverse=True\n            )\n\n        # Write segments in the new file and fill the program header\n        p_offset = len(elf_h)\n        offset2p_offset = (\n            {}\n        )  # Slow but more easy to implement (best way: a tree sort structure able to be updated)\n        e_phnum = 0\n\n        for pmask, interval_list in intervals.items():\n            e_phnum += len(interval_list)\n            for idx, interval in enumerate(interval_list):\n                begin, end, offset = interval\n                size = end - begin\n                if offset not in offset2p_offset:\n                    elf_fd.write(self.phy.get_data_raw(offset, size))\n                    if not self.phy.get_data_raw(offset, size):\n                        print(hex(offset), hex(size))\n                    new_offset = p_offset\n                    p_offset += size\n                    for page_idx in range(0, size, self.minimum_page):\n                        offset2p_offset[offset + page_idx] = new_offset + page_idx\n                else:\n                    new_offset = offset2p_offset[offset]\n                interval_list[idx].append(\n                    new_offset\n                )  # Assign the new offset in the dest file\n\n        # Create the program header containing all the segments (ignoring not in RAM pages)\n        e_phoff = elf_fd.tell()\n        p_header = bytes()\n        for pmask, interval_list in intervals.items():\n            for begin, end, offset, p_offset in interval_list:\n                p_filesz = end - begin\n\n                # Back convert offset to physical page\n                p_addr = self.phy.o2p[offset]\n                assert p_addr != -1\n\n                segment_entry = bytearray(e_phentsize)\n                segment_entry[0x00:0x04] = 0x1.to_bytes(4, endianness)  # p_type\n                segment_entry[0x04:0x08] = pmask.to_bytes(4, endianness)  # p_flags\n                segment_entry[0x10:0x18] = begin.to_bytes(8, endianness)  # p_vaddr\n                segment_entry[0x18:0x20] = p_addr.to_bytes(\n                    8, endianness\n                )  # p_paddr Original physical address\n                segment_entry[0x28:0x30] = p_filesz.to_bytes(\n                    8, endianness\n                )  # p_memsz\n                segment_entry[0x08:0x10] = p_offset.to_bytes(\n                    8, endianness\n                )  # p_offset\n                segment_entry[0x20:0x28] = p_filesz.to_bytes(\n                    8, endianness\n                )  # p_filesz\n\n                p_header += segment_entry\n\n        # Write the segment header\n        elf_fd.write(p_header)\n        s_header_pos = (\n            elf_fd.tell()\n        )  # Last position written (used if we need to write segment header)\n\n        # Modify the ELF header to point to program header\n        elf_fd.seek(0x20)\n        elf_fd.write(e_phoff.to_bytes(8, endianness))  # e_phoff\n\n        # If we have more than 65535 segments we have create a special Section entry contains the\n        # number of program entry (as specified in ELF64 specifications)\n        if e_phnum &lt; 65536:\n            elf_fd.seek(0x38)\n            elf_fd.write(e_phnum.to_bytes(2, endianness))  # e_phnum\n        else:\n            elf_fd.seek(0x28)\n            elf_fd.write(s_header_pos.to_bytes(8, endianness))  # e_shoff\n            elf_fd.seek(0x38)\n            elf_fd.write(0xFFFF.to_bytes(2, endianness))  # e_phnum\n            elf_fd.write(0x40.to_bytes(2, endianness))  # e_shentsize\n            elf_fd.write(0x1.to_bytes(2, endianness))  # e_shnum\n\n            section_entry = bytearray(0x40)\n            section_entry[0x2C:0x30] = e_phnum.to_bytes(4, endianness)  # sh_info\n            elf_fd.seek(s_header_pos)\n            elf_fd.write(section_entry)\n</code></pre>"},{"location":"reference/exporter/#mmushell.exporter.AddressTranslator.get_data_phy","title":"<code>get_data_phy(paddr, size)</code>","text":"<p>Return data starting from a physical address</p> Source code in <code>mmushell/exporter.py</code> <pre><code>def get_data_phy(self, paddr, size):\n    \"\"\"Return data starting from a physical address\"\"\"\n    return self.phy.get_data(paddr, size)\n</code></pre>"},{"location":"reference/exporter/#mmushell.exporter.AddressTranslator.get_data_raw","title":"<code>get_data_raw(offset, size)</code>","text":"<p>Return data starting from an ELF offset</p> Source code in <code>mmushell/exporter.py</code> <pre><code>def get_data_raw(self, offset, size):\n    \"\"\"Return data starting from an ELF offset\"\"\"\n    return self.phy.get_data_raw(offset, size)\n</code></pre>"},{"location":"reference/exporter/#mmushell.exporter.AddressTranslator.get_data_virt","title":"<code>get_data_virt(vaddr, size=1)</code>","text":"<p>Return data starting from a virtual address</p> Source code in <code>mmushell/exporter.py</code> <pre><code>def get_data_virt(self, vaddr, size=1):\n    \"\"\"Return data starting from a virtual address\"\"\"\n    size_available, intervals = self.v2o.contains(vaddr, size)\n    if size_available != size:\n        return bytes()\n\n    ret = bytearray()\n    for interval in intervals:\n        _, interval_size, offset = interval\n        ret.extend(self.elf_buf[offset : offset + interval_size].tobytes())\n\n    return ret\n</code></pre>"},{"location":"reference/exporter/#mmushell.exporter.ELFDump","title":"<code>ELFDump</code>","text":"Source code in <code>mmushell/exporter.py</code> <pre><code>class ELFDump:\n    def __init__(self, elf_filename):\n        self.filename = elf_filename\n        self.machine_data = {}\n        self.p2o = None  # Physical to RAM (ELF offset)\n        self.o2p = None  # RAM (ELF offset) to Physical\n        self.p2mmd = None  # Physical to Memory Mapped Devices (ELF offset)\n        self.elf_buf = np.zeros(0, dtype=np.byte)\n        self.elf_filename = elf_filename\n\n        with open(self.elf_filename, \"rb\") as elf_fd:\n            # Load the ELF in memory\n            self.elf_buf = np.fromfile(elf_fd, dtype=np.byte)\n            elf_fd.seek(0)\n\n            # Parse the ELF file\n            self.__read_elf_file(elf_fd)\n\n    def __read_elf_file(self, elf_fd):\n        \"\"\"Parse the dump in ELF format\"\"\"\n        o2p_list = []\n        p2o_list = []\n        p2mmd_list = []\n        elf_file = ELFFile(elf_fd)\n\n        for segm in elf_file.iter_segments():\n            # NOTES\n            if isinstance(segm, NoteSegment):\n                for note in segm.iter_notes():\n                    # Ignore NOTE genrated by other softwares\n                    if note[\"n_name\"] != \"FOSSIL\":\n                        continue\n\n                    # At moment only one type of note\n                    if note[\"n_type\"] != 0xDEADC0DE:\n                        continue\n\n                    # Suppose only one deadcode note\n                    self.machine_data = json.loads(note[\"n_desc\"].rstrip(\"\\x00\"))\n                    self.machine_data[\"Endianness\"] = (\n                        \"little\"\n                        if elf_file.header[\"e_ident\"].EI_DATA == \"ELFDATA2LSB\"\n                        else \"big\"\n                    )\n                    self.machine_data[\"Architecture\"] = \"_\".join(\n                        elf_file.header[\"e_machine\"].split(\"_\")[1:]\n                    )\n            else:\n                # Fill arrays needed to translate physical addresses to file offsets\n                r_start = segm[\"p_vaddr\"]\n                r_end = r_start + segm[\"p_memsz\"]\n\n                if segm[\"p_filesz\"]:\n                    p_offset = segm[\"p_offset\"]\n                    p2o_list.append((r_start, (r_end, p_offset)))\n                    o2p_list.append((p_offset, (p_offset + (r_end - r_start), r_start)))\n                else:\n                    # device_name = \"\" # UNUSED\n                    for device in self.machine_data[\n                        \"MemoryMappedDevices\"\n                    ]:  # Possible because NOTES always the first segment\n                        if device[0] == r_start:\n                            # device_name = device[1] # UNUSED\n                            break\n                    p2mmd_list.append((r_start, r_end))\n\n        # Debug\n        # self.p2o_list = p2o_list\n        # self.o2p_list = o2p_list\n        # self.p2mmd_list = p2mmd_list\n\n        # Compact intervals\n        p2o_list = self._compact_intervals(p2o_list)\n        o2p_list = self._compact_intervals(o2p_list)\n        p2mmd_list = self._compact_intervals_simple(p2mmd_list)\n\n        self.p2o = IMOffsets(*list(zip(*sorted(p2o_list))))\n        self.o2p = IMOffsets(*list(zip(*sorted(o2p_list))))\n        self.p2mmd = IMSimple(*list(zip(*sorted(p2mmd_list))))\n\n    def _compact_intervals_simple(self, intervals):\n        \"\"\"Compact intervals if pointer values are contiguos\"\"\"\n        fused_intervals = []\n        prev_begin = prev_end = -1\n        for interval in intervals:\n            begin, end = interval\n            if prev_end == begin:\n                prev_end = end\n            else:\n                fused_intervals.append((prev_begin, prev_end))\n                prev_begin = begin\n                prev_end = end\n\n        if prev_begin != begin:\n            fused_intervals.append((prev_begin, prev_end))\n        else:\n            fused_intervals.append((begin, end))\n\n        return fused_intervals[1:]\n\n    def _compact_intervals(self, intervals):\n        \"\"\"Compact intervals if pointer and pointed values are contigous\"\"\"\n        fused_intervals = []\n        prev_begin = prev_end = prev_phy = -1\n        for interval in intervals:\n            begin, (end, phy) = interval\n            if prev_end == begin and prev_phy + (prev_end - prev_begin) == phy:\n                prev_end = end\n            else:\n                fused_intervals.append((prev_begin, (prev_end, prev_phy)))\n                prev_begin = begin\n                prev_end = end\n                prev_phy = phy\n\n        if prev_begin != begin:\n            fused_intervals.append((prev_begin, (prev_end, prev_phy)))\n        else:\n            fused_intervals.append((begin, (end, phy)))\n\n        return fused_intervals[1:]\n\n    def in_ram(self, paddr, size=1):\n        \"\"\"Return True if the interval is completely in RAM\"\"\"\n        return self.p2o.contains(paddr, size)[0] == size\n\n    def in_mmd(self, paddr, size=1):\n        \"\"\"Return True if the interval is completely in Memory mapped devices space\"\"\"\n        return True if self.p2mmd.contains(paddr, size) != -1 else False\n\n    def get_data(self, paddr, size):\n        \"\"\"Return the data at physical address (interval)\"\"\"\n        size_available, intervals = self.p2o.contains(paddr, size)\n        if size_available != size:\n            return bytes()\n\n        ret = bytearray()\n        for interval in intervals:\n            _, interval_size, offset = interval\n            ret.extend(self.elf_buf[offset : offset + interval_size].tobytes())\n\n        return ret\n\n    def get_data_raw(self, offset, size=1):\n        \"\"\"Return the data at the offset in the ELF (interval)\"\"\"\n        return self.elf_buf[offset : offset + size].tobytes()\n\n    def get_machine_data(self):\n        \"\"\"Return a dict containing machine configuration\"\"\"\n        return self.machine_data\n\n    def get_ram_regions(self):\n        \"\"\"Return all the RAM regions of the machine and the associated offset\"\"\"\n        return self.p2o.get_values()\n\n    def get_mmd_regions(self):\n        \"\"\"Return all the Memory mapped devices intervals of the machine and the associated offset\"\"\"\n        return self.p2mmd.get_values()\n</code></pre>"},{"location":"reference/exporter/#mmushell.exporter.ELFDump.__read_elf_file","title":"<code>__read_elf_file(elf_fd)</code>","text":"<p>Parse the dump in ELF format</p> Source code in <code>mmushell/exporter.py</code> <pre><code>def __read_elf_file(self, elf_fd):\n    \"\"\"Parse the dump in ELF format\"\"\"\n    o2p_list = []\n    p2o_list = []\n    p2mmd_list = []\n    elf_file = ELFFile(elf_fd)\n\n    for segm in elf_file.iter_segments():\n        # NOTES\n        if isinstance(segm, NoteSegment):\n            for note in segm.iter_notes():\n                # Ignore NOTE genrated by other softwares\n                if note[\"n_name\"] != \"FOSSIL\":\n                    continue\n\n                # At moment only one type of note\n                if note[\"n_type\"] != 0xDEADC0DE:\n                    continue\n\n                # Suppose only one deadcode note\n                self.machine_data = json.loads(note[\"n_desc\"].rstrip(\"\\x00\"))\n                self.machine_data[\"Endianness\"] = (\n                    \"little\"\n                    if elf_file.header[\"e_ident\"].EI_DATA == \"ELFDATA2LSB\"\n                    else \"big\"\n                )\n                self.machine_data[\"Architecture\"] = \"_\".join(\n                    elf_file.header[\"e_machine\"].split(\"_\")[1:]\n                )\n        else:\n            # Fill arrays needed to translate physical addresses to file offsets\n            r_start = segm[\"p_vaddr\"]\n            r_end = r_start + segm[\"p_memsz\"]\n\n            if segm[\"p_filesz\"]:\n                p_offset = segm[\"p_offset\"]\n                p2o_list.append((r_start, (r_end, p_offset)))\n                o2p_list.append((p_offset, (p_offset + (r_end - r_start), r_start)))\n            else:\n                # device_name = \"\" # UNUSED\n                for device in self.machine_data[\n                    \"MemoryMappedDevices\"\n                ]:  # Possible because NOTES always the first segment\n                    if device[0] == r_start:\n                        # device_name = device[1] # UNUSED\n                        break\n                p2mmd_list.append((r_start, r_end))\n\n    # Debug\n    # self.p2o_list = p2o_list\n    # self.o2p_list = o2p_list\n    # self.p2mmd_list = p2mmd_list\n\n    # Compact intervals\n    p2o_list = self._compact_intervals(p2o_list)\n    o2p_list = self._compact_intervals(o2p_list)\n    p2mmd_list = self._compact_intervals_simple(p2mmd_list)\n\n    self.p2o = IMOffsets(*list(zip(*sorted(p2o_list))))\n    self.o2p = IMOffsets(*list(zip(*sorted(o2p_list))))\n    self.p2mmd = IMSimple(*list(zip(*sorted(p2mmd_list))))\n</code></pre>"},{"location":"reference/exporter/#mmushell.exporter.ELFDump.get_data","title":"<code>get_data(paddr, size)</code>","text":"<p>Return the data at physical address (interval)</p> Source code in <code>mmushell/exporter.py</code> <pre><code>def get_data(self, paddr, size):\n    \"\"\"Return the data at physical address (interval)\"\"\"\n    size_available, intervals = self.p2o.contains(paddr, size)\n    if size_available != size:\n        return bytes()\n\n    ret = bytearray()\n    for interval in intervals:\n        _, interval_size, offset = interval\n        ret.extend(self.elf_buf[offset : offset + interval_size].tobytes())\n\n    return ret\n</code></pre>"},{"location":"reference/exporter/#mmushell.exporter.ELFDump.get_data_raw","title":"<code>get_data_raw(offset, size=1)</code>","text":"<p>Return the data at the offset in the ELF (interval)</p> Source code in <code>mmushell/exporter.py</code> <pre><code>def get_data_raw(self, offset, size=1):\n    \"\"\"Return the data at the offset in the ELF (interval)\"\"\"\n    return self.elf_buf[offset : offset + size].tobytes()\n</code></pre>"},{"location":"reference/exporter/#mmushell.exporter.ELFDump.get_machine_data","title":"<code>get_machine_data()</code>","text":"<p>Return a dict containing machine configuration</p> Source code in <code>mmushell/exporter.py</code> <pre><code>def get_machine_data(self):\n    \"\"\"Return a dict containing machine configuration\"\"\"\n    return self.machine_data\n</code></pre>"},{"location":"reference/exporter/#mmushell.exporter.ELFDump.get_mmd_regions","title":"<code>get_mmd_regions()</code>","text":"<p>Return all the Memory mapped devices intervals of the machine and the associated offset</p> Source code in <code>mmushell/exporter.py</code> <pre><code>def get_mmd_regions(self):\n    \"\"\"Return all the Memory mapped devices intervals of the machine and the associated offset\"\"\"\n    return self.p2mmd.get_values()\n</code></pre>"},{"location":"reference/exporter/#mmushell.exporter.ELFDump.get_ram_regions","title":"<code>get_ram_regions()</code>","text":"<p>Return all the RAM regions of the machine and the associated offset</p> Source code in <code>mmushell/exporter.py</code> <pre><code>def get_ram_regions(self):\n    \"\"\"Return all the RAM regions of the machine and the associated offset\"\"\"\n    return self.p2o.get_values()\n</code></pre>"},{"location":"reference/exporter/#mmushell.exporter.ELFDump.in_mmd","title":"<code>in_mmd(paddr, size=1)</code>","text":"<p>Return True if the interval is completely in Memory mapped devices space</p> Source code in <code>mmushell/exporter.py</code> <pre><code>def in_mmd(self, paddr, size=1):\n    \"\"\"Return True if the interval is completely in Memory mapped devices space\"\"\"\n    return True if self.p2mmd.contains(paddr, size) != -1 else False\n</code></pre>"},{"location":"reference/exporter/#mmushell.exporter.ELFDump.in_ram","title":"<code>in_ram(paddr, size=1)</code>","text":"<p>Return True if the interval is completely in RAM</p> Source code in <code>mmushell/exporter.py</code> <pre><code>def in_ram(self, paddr, size=1):\n    \"\"\"Return True if the interval is completely in RAM\"\"\"\n    return self.p2o.contains(paddr, size)[0] == size\n</code></pre>"},{"location":"reference/exporter/#mmushell.exporter.IMData","title":"<code>IMData</code>","text":"<p>Fast search in intervals (begin), (end, associated data)</p> Source code in <code>mmushell/exporter.py</code> <pre><code>class IMData:\n    \"\"\"Fast search in intervals (begin), (end, associated data)\"\"\"\n\n    def __init__(self, keys, values):\n        self.keys = keys\n        self.values = values\n\n    def __getitem__(self, x):\n        idx = bisect(self.keys, x) - 1\n        begin = self.keys[idx]\n        end, data = self.values[idx]\n        if begin &lt;= x &lt; end:\n            return data\n        else:\n            return -1\n\n    def contains(self, x, size):\n        idx = bisect(self.keys, x) - 1\n        begin = self.keys[idx]\n        end, data = self.values[idx]\n        if not (begin &lt;= x &lt; end) or x + size &gt;= end:\n            return -1\n        else:\n            return data\n\n    def get_values(self):\n        return zip(self.keys, self.values)\n\n    def get_extremes(self):\n        return self.keys[0], self.values[-1][0]\n</code></pre>"},{"location":"reference/exporter/#mmushell.exporter.IMOffsets","title":"<code>IMOffsets</code>","text":"<p>Fast search in intervals (begin), (end, associated offset)</p> Source code in <code>mmushell/exporter.py</code> <pre><code>class IMOffsets:\n    \"\"\"Fast search in intervals (begin), (end, associated offset)\"\"\"\n\n    def __init__(self, keys, values):\n        self.keys = keys\n        self.values = values\n\n    def __getitem__(self, x):\n        idx = bisect(self.keys, x) - 1\n        begin = self.keys[idx]\n        end, data = self.values[idx]\n        if begin &lt;= x &lt; end:\n            return x - begin + data\n        else:\n            return -1\n\n    def contains(self, x, size):\n        \"\"\"Return the maximum size and the list of intervals\"\"\"\n        idx = bisect(self.keys, x) - 1\n        begin = self.keys[idx]\n        end, data = self.values[idx]\n        if not (begin &lt;= x &lt; end):\n            return 0, []\n\n        intervals = [(x, min(end - x, size), x - begin + data)]\n        if end - x &gt;= size:\n            return size, intervals\n\n        # The address space requested is bigger than a single interval\n        start = end\n        remaining = size - (end - x)\n        idx += 1\n        print(start, remaining, idx)\n        while idx &lt; len(self.values):\n            begin = self.keys[idx]\n            end, data = self.values[idx]\n\n            # Virtual addresses must be contigous\n            if begin != start:\n                return size - remaining, intervals\n\n            interval_size = min(end - begin, remaining)\n            intervals.append((start, interval_size, data))\n            remaining -= interval_size\n            if not remaining:\n                return size, intervals\n            start += interval_size\n            idx += 1\n\n    def get_values(self):\n        return zip(self.keys, self.values)\n\n    def get_extremes(self):\n        return self.keys[0], self.values[-1][0]\n</code></pre>"},{"location":"reference/exporter/#mmushell.exporter.IMOffsets.contains","title":"<code>contains(x, size)</code>","text":"<p>Return the maximum size and the list of intervals</p> Source code in <code>mmushell/exporter.py</code> <pre><code>def contains(self, x, size):\n    \"\"\"Return the maximum size and the list of intervals\"\"\"\n    idx = bisect(self.keys, x) - 1\n    begin = self.keys[idx]\n    end, data = self.values[idx]\n    if not (begin &lt;= x &lt; end):\n        return 0, []\n\n    intervals = [(x, min(end - x, size), x - begin + data)]\n    if end - x &gt;= size:\n        return size, intervals\n\n    # The address space requested is bigger than a single interval\n    start = end\n    remaining = size - (end - x)\n    idx += 1\n    print(start, remaining, idx)\n    while idx &lt; len(self.values):\n        begin = self.keys[idx]\n        end, data = self.values[idx]\n\n        # Virtual addresses must be contigous\n        if begin != start:\n            return size - remaining, intervals\n\n        interval_size = min(end - begin, remaining)\n        intervals.append((start, interval_size, data))\n        remaining -= interval_size\n        if not remaining:\n            return size, intervals\n        start += interval_size\n        idx += 1\n</code></pre>"},{"location":"reference/exporter/#mmushell.exporter.IMOverlapping","title":"<code>IMOverlapping</code>","text":"<p>Fast search in overlapping intervals (begin), (end, [associated offsets])</p> Source code in <code>mmushell/exporter.py</code> <pre><code>class IMOverlapping:\n    \"\"\"Fast search in overlapping intervals (begin), (end, [associated\n    offsets])\"\"\"\n\n    def __init__(self, intervals):\n        limit2changes = defaultdict(lambda: ([], []))\n        for idx, (l, r, v) in enumerate(intervals):\n            assert l &lt; r\n            limit2changes[l][0].append(v)\n            limit2changes[r][1].append(v)\n        self.limits, changes = zip(*sorted(limit2changes.items()))\n\n        self.results = [[]]\n        s = set()\n        offsets = {}\n        res = []\n        for idx, (arrivals, departures) in enumerate(changes):\n            s.difference_update(departures)\n            for i in departures:\n                offsets.pop(i)\n\n            for i in s:\n                offsets[i] += self.limits[idx] - self.limits[idx - 1]\n\n            s.update(arrivals)\n            for i in arrivals:\n                offsets[i] = 0\n\n            res.clear()\n            for k, v in offsets.items():\n                res.extend([i + v for i in k])\n            self.results.append(res.copy())\n\n    def __getitem__(self, x):\n        idx = bisect(self.limits, x)\n        k = x - self.limits[idx - 1]\n        return [k + p for p in self.results[idx]]\n\n    def get_values(self):\n        return zip(self.limits, self.results)\n</code></pre>"},{"location":"reference/exporter/#mmushell.exporter.IMSimple","title":"<code>IMSimple</code>","text":"<p>Fast search in intervals (begin) (end)</p> Source code in <code>mmushell/exporter.py</code> <pre><code>class IMSimple:\n    \"\"\"Fast search in intervals (begin) (end)\"\"\"\n\n    def __init__(self, keys, values):\n        self.keys = keys\n        self.values = values\n\n    def __getitem__(self, x):\n        idx = bisect(self.keys, x) - 1\n        begin = self.keys[idx]\n        if begin &lt;= x &lt; self.values[idx]:\n            return x - begin\n        else:\n            return -1\n\n    def contains(self, x, size):\n        idx = bisect(self.keys, x) - 1\n        begin = self.keys[idx]\n        end = self.values[idx]\n        if not (begin &lt;= x &lt; end) or x + size &gt;= end:\n            return -1\n        else:\n            return x - begin\n\n    def get_values(self):\n        return zip(self.keys, self.values)\n\n    def get_extremes(self):\n        return self.keys[0], self.values[-1]\n</code></pre>"},{"location":"reference/exporter/#mmushell.exporter.get_virtspace","title":"<code>get_virtspace(phy, mmu_values)</code>","text":"<p>Return a virtspace from a physical one</p> Source code in <code>mmushell/exporter.py</code> <pre><code>def get_virtspace(phy, mmu_values):\n    \"\"\"Return a virtspace from a physical one\"\"\"\n    architecture = phy.get_machine_data()[\"Architecture\"].lower()\n    if \"riscv\" in architecture:\n        return RISCVTranslator.factory(phy, mmu_values)\n    elif \"x86\" in architecture or \"386\" in architecture:\n        return IntelTranslator.factory(phy, mmu_values)\n    else:\n        raise Exception(\"Unknown architecture\")\n</code></pre>"},{"location":"reference/mmushell/","title":"MMUShell","text":""},{"location":"reference/mmushell/#mmushell","title":"MMUShell","text":""},{"location":"reference/architectures/aarch64/","title":"AArch64","text":""},{"location":"reference/architectures/aarch64/#aarch64","title":"AArch64","text":""},{"location":"reference/architectures/aarch64/#mmushell.architectures.aarch64.MMUShell","title":"<code>MMUShell</code>","text":"<p>             Bases: <code>MMUShell</code></p> Source code in <code>mmushell/architectures/aarch64.py</code> <pre><code>class MMUShell(MMUShellDefault):\n    def __init__(self, completekey=\"tab\", stdin=None, stdout=None, machine={}):\n        super(MMUShell, self).__init__(completekey, stdin, stdout, machine)\n\n        if not self.data:\n            self.data = Data(\n                is_tables_found=False,\n                is_radix_found=False,\n                is_registers_found=False,\n                opcodes={},\n                regs_values={},\n                page_tables={\"user\": defaultdict(dict), \"kernel\": defaultdict(dict)},\n                data_pages={\"user\": [], \"kernel\": []},\n                empty_tables={\"user\": [], \"kernel\": []},\n                reverse_map_tables={\"user\": None, \"kernel\": None},\n                reverse_map_pages={\"user\": None, \"kernel\": None},\n                used_tcr=None,\n                ttbrs=defaultdict(dict),\n            )\n\n    def reload_data_from_file(self, data_filename):\n        super(MMUShell, self).reload_data_from_file(data_filename)\n\n        # Reload TCR data and radix tree shape\n        LONG.tcr = self.data.used_tcr\n        self.do_set_tcr(str(LONG.tcr.value))\n\n    def do_find_registers_values(self, arg):\n        \"\"\"Find MMU load opcodes and execute MMU related functions inside the memory dump in order to extract MMU registers values\"\"\"\n\n        if self.data.is_registers_found:\n            logging.warning(\"Registers already searched\")\n            return\n\n        logger.info(\"Look for opcodes related to MMU setup...\")\n        parallel_results = self.machine.apply_parallel(\n            65536, self.machine.cpu.parse_opcodes_parallel\n        )\n\n        opcodes = {}\n        logger.info(\"Reaggregate threads data...\")\n        for result in parallel_results:\n            opcodes.update(result.get())\n\n        self.data.opcodes = opcodes\n\n        # Filter to look only for opcodes which write on MMU register only and not read from them or from other registers\n        filter_f = (\n            lambda it: True\n            if it[1][\"register\"] == \"TCR_EL1\" and it[1][\"instruction\"] == \"MSR\"\n            else False\n        )\n        mmu_wr_opcodes = {k: v for k, v in filter(filter_f, opcodes.items())}\n\n        logging.info(\"Use heuristics to find function addresses...\")\n        logging.info(\"This analysis could be extremely slow!\")\n        self.machine.cpu.identify_functions_start(mmu_wr_opcodes)\n\n        logging.info(\"Identify register values using data flow analysis...\")\n\n        # We use data flow analysis and merge the results\n        dataflow_values = self.machine.cpu.find_registers_values_dataflow(\n            mmu_wr_opcodes\n        )\n\n        filtered_values = defaultdict(set)\n        for register, values in dataflow_values.items():\n            for value in values:\n                reg_obj = CPURegAArch64.get_register_obj(register, value)\n                if reg_obj.valid and not any(\n                    [\n                        val_obj.is_mmu_equivalent_to(reg_obj)\n                        for val_obj in filtered_values[register]\n                    ]\n                ):\n                    filtered_values[register].add(reg_obj)\n\n        self.data.regs_values = filtered_values\n        self.data.is_registers_found = True\n\n        # Show results\n        logging.info(\"TCR_EL1 values recovered:\")\n        for reg_obj in self.data.regs_values[\"TCR_EL1\"]:\n            logging.info(reg_obj)\n\n    def do_show_registers(self, args):\n        \"\"\"Show TCR values found\"\"\"\n        if not self.data.is_registers_found:\n            logging.info(\"Please, find them first!\")\n            return\n\n        for registers in sorted(self.data.regs_values.keys()):\n            for register in self.data.regs_values[registers]:\n                print(register)\n\n    def do_set_tcr(self, args):\n        \"\"\"Set TCR to be used\"\"\"\n        args = args.split()\n        if len(args) == 0:\n            logging.error(\"Please use find_tables TCR_VALUE\")\n            return\n\n        try:\n            tcr_val = self.parse_int(args[0])\n            tcr = TCR_EL1(tcr_val)\n            if not tcr.valid:\n                raise ValueError\n        except ValueError:\n            logger.warning(\"Invalid TCR value\")\n            return\n\n        self.data.used_tcr = tcr\n\n        # Set all MMU parameters\n        LONG.tcr = tcr\n        LONG.radix_levels = {}\n        trees_struct = tcr.get_trees_struct()\n\n        for mode in [\"user\", \"kernel\"]:\n            granule = trees_struct[mode][\"granule\"]\n            total_levels = trees_struct[mode][\"total_levels\"]\n            top_table_size = trees_struct[mode][\"top_table_size\"]\n\n            LONG.radix_levels[mode] = total_levels\n            LONG.map_level_to_table_size[mode] = [top_table_size] + (\n                [granule] * (total_levels - 1)\n            )\n            LONG.map_reserved_entries_to_levels[mode] = [\n                [] for i in range(total_levels - 1)\n            ] + [[ReservedEntry]]\n\n            if granule == 4096:\n                if total_levels == 1:\n                    LONG.map_datapages_entries_to_levels[mode] = [PTPAGE_4KB]\n                    LONG.map_ptr_entries_to_levels[mode] = [None]\n                    LONG.map_entries_to_shifts[mode] = {PTPAGE_4KB: 12}\n                elif total_levels == 2:\n                    LONG.map_datapages_entries_to_levels[mode] = [\n                        [PTBLOCK_L2_4KB],\n                        [PTPAGE_4KB],\n                    ]\n                    LONG.map_ptr_entries_to_levels[mode] = [PTP_4KB_L0, None]\n                    LONG.map_entries_to_shifts[mode] = {\n                        PTP_4KB_L0: 21,\n                        PTPAGE_4KB: 12,\n                        PTBLOCK_L2_4KB: 21,\n                    }\n                elif total_levels == 3:\n                    LONG.map_datapages_entries_to_levels[mode] = [\n                        [PTBLOCK_L1_4KB],\n                        [PTBLOCK_L2_4KB],\n                        [PTPAGE_4KB],\n                    ]\n                    LONG.map_ptr_entries_to_levels[mode] = [\n                        PTP_4KB_L0,\n                        PTP_4KB_L1,\n                        None,\n                    ]\n                    LONG.map_entries_to_shifts[mode] = {\n                        PTP_4KB_L0: 30,\n                        PTP_4KB_L1: 21,\n                        PTPAGE_4KB: 12,\n                        PTBLOCK_L2_4KB: 21,\n                        PTBLOCK_L1_4KB: 30,\n                    }\n                else:\n                    LONG.map_datapages_entries_to_levels[mode] = [\n                        [None],\n                        [PTBLOCK_L1_4KB],\n                        [PTBLOCK_L2_4KB],\n                        [PTPAGE_4KB],\n                    ]\n                    LONG.map_ptr_entries_to_levels[mode] = [\n                        PTP_4KB_L0,\n                        PTP_4KB_L1,\n                        PTP_4KB_L2,\n                        None,\n                    ]\n                    LONG.map_entries_to_shifts[mode] = {\n                        PTP_4KB_L0: 39,\n                        PTP_4KB_L1: 30,\n                        PTP_4KB_L2: 21,\n                        PTPAGE_4KB: 12,\n                        PTBLOCK_L2_4KB: 21,\n                        PTBLOCK_L1_4KB: 30,\n                    }\n\n            elif granule == 16384:\n                if total_levels == 1:\n                    LONG.map_datapages_entries_to_levels[mode] = [PTPAGE_16KB]\n                    LONG.map_ptr_entries_to_levels[mode] = [None]\n                    LONG.map_entries_to_shifts[mode] = {PTPAGE_16KB: 14}\n                elif total_levels == 2:\n                    LONG.map_datapages_entries_to_levels[mode] = [\n                        [PTBLOCK_L2_16KB],\n                        [PTPAGE_16KB],\n                    ]\n                    LONG.map_ptr_entries_to_levels[mode] = [PTP_16KB_L0, None]\n                    LONG.map_entries_to_shifts[mode] = {\n                        PTP_16KB_L0: 25,\n                        PTPAGE_16KB: 14,\n                        PTBLOCK_L2_16KB: 25,\n                    }\n                elif total_levels == 3:\n                    LONG.map_datapages_entries_to_levels[mode] = [\n                        [None],\n                        [PTBLOCK_L2_16KB],\n                        [PTPAGE_16KB],\n                    ]\n                    LONG.map_ptr_entries_to_levels[mode] = [\n                        PTP_16KB_L0,\n                        PTP_16KB_L1,\n                        None,\n                    ]\n                    LONG.map_entries_to_shifts[mode] = {\n                        PTP_16KB_L0: 36,\n                        PTP_16KB_L1: 25,\n                        PTPAGE_16KB: 14,\n                        PTBLOCK_L2_16KB: 25,\n                    }\n                else:\n                    LONG.map_datapages_entries_to_levels[mode] = [\n                        [None],\n                        [None],\n                        [PTBLOCK_L2_16KB],\n                        [PTPAGE_16KB],\n                    ]\n                    LONG.map_ptr_entries_to_levels[mode] = [\n                        PTP_16KB_L0,\n                        PTP_16KB_L2,\n                        None,\n                    ]\n                    LONG.map_entries_to_shifts[mode] = {\n                        PTP_16KB_L0: 47,\n                        PTP_16KB_L1: 36,\n                        PTP_16KB_L2: 25,\n                        PTPAGE_16KB: 14,\n                        PTBLOCK_L2_16KB: 25,\n                    }\n\n            else:\n                if total_levels == 1:\n                    LONG.map_datapages_entries_to_levels[mode] = [PTPAGE_64KB]\n                    LONG.map_ptr_entries_to_levels[mode] = [None]\n                    LONG.map_entries_to_shifts[mode] = {\n                        PTPAGE_64KB: 16,\n                        PTBLOCK_L2_64KB: 29,\n                    }\n                elif total_levels == 2:\n                    LONG.map_datapages_entries_to_levels[mode] = [\n                        [PTBLOCK_L2_64KB],\n                        [PTPAGE_64KB],\n                    ]\n                    LONG.map_ptr_entries_to_levels[mode] = [PTP_64KB_L0, None]\n                    LONG.map_entries_to_shifts[mode] = {\n                        PTP_64KB_L0: 29,\n                        PTPAGE_64KB: 16,\n                        PTBLOCK_L2_16KB: 29,\n                    }\n                else:\n                    LONG.map_datapages_entries_to_levels[mode] = [\n                        [None],\n                        [PTBLOCK_L2_64KB],\n                        [PTPAGE_64KB],\n                    ]\n                    LONG.map_ptr_entries_to_levels[mode] = [\n                        PTP_64KB_L0,\n                        PTP_64KB_L1,\n                        None,\n                    ]\n                    LONG.map_entries_to_shifts[mode] = {\n                        PTP_64KB_L0: 42,\n                        PTP_64KB_L1: 29,\n                        PTPAGE_64KB: 16,\n                        PTBLOCK_L2_64KB: 29,\n                    }\n\n    def do_find_tables(self, args):\n        \"\"\"Find MMU tables in memory\"\"\"\n        if not self.data.used_tcr:\n            logging.error(\"Please set a TCR register to use, using set_tcr TCR\")\n            return\n        tcr = self.data.used_tcr\n\n        # Delete all the previous table data\n        if self.data.is_tables_found:\n            self.data.page_tables = {\n                \"user\": defaultdict(dict),\n                \"kernel\": defaultdict(dict),\n            }\n            self.data.data_pages = {\"user\": [], \"kernel\": []}\n            self.data.empty_tables = {\"user\": [], \"kernel\": []}\n            self.data.reverse_map_tables = {}\n            self.data.reverse_map_pages = {}\n\n        # WORKAROUND: initialize here because unpickable!\n        self.data.reverse_map_pages = {\n            \"kernel\": defaultdict(_dummy_f),\n            \"user\": defaultdict(_dummy_f),\n        }\n        self.data.reverse_map_tables = {\n            \"kernel\": defaultdict(_dummy_f),\n            \"user\": defaultdict(_dummy_f),\n        }\n\n        # Parse memory in chunk of 64KiB\n        logger.info(\"Look for paging tables...\")\n        parallel_results = self.machine.apply_parallel(\n            65536, self.machine.mmu.parse_parallel_frame, tcr=tcr\n        )\n        logger.info(\"Reaggregate threads data...\")\n        for result in parallel_results:\n            page_tables, data_pages, empty_tables = result.get()\n\n            for mode in [\"user\", \"kernel\"]:\n                for level in range(self.machine.mmu.radix_levels[mode]):\n                    self.data.page_tables[mode][level].update(page_tables[mode][level])\n\n                self.data.data_pages[mode].extend(data_pages[mode])\n                self.data.empty_tables[mode].extend(empty_tables[mode])\n\n        for mode in [\"user\", \"kernel\"]:\n            self.data.data_pages[mode] = set(self.data.data_pages[mode])\n            self.data.empty_tables[mode] = set(self.data.empty_tables[mode])\n\n        # Remove all tables which point to inexistent table of lower level\n        logger.info(\"Reduce false positives...\")\n        for mode in [\"user\", \"kernel\"]:\n            for lvl in range(self.machine.mmu.radix_levels[mode] - 1):\n                ptr_class = self.machine.mmu.map_ptr_entries_to_levels[mode][lvl]\n                referenced_nxt = []\n                for table_addr in list(self.data.page_tables[mode][lvl].keys()):\n                    for entry_obj in (\n                        self.data.page_tables[mode][lvl][table_addr]\n                        .entries[ptr_class]\n                        .values()\n                    ):\n                        if (\n                            entry_obj.address\n                            not in self.data.page_tables[mode][lvl + 1]\n                            and entry_obj.address not in self.data.empty_tables[mode]\n                        ):\n                            # Remove the table\n                            self.data.page_tables[mode][lvl].pop(table_addr)\n                            break\n\n                        else:\n                            referenced_nxt.append(entry_obj.address)\n\n                # Remove table not referenced by upper levels\n                referenced_nxt = set(referenced_nxt)\n                for table_addr in set(\n                    self.data.page_tables[mode][lvl + 1].keys()\n                ).difference(referenced_nxt):\n                    self.data.page_tables[mode][lvl + 1].pop(table_addr)\n\n        logger.info(\"Fill reverse maps...\")\n        for mode in [\"user\", \"kernel\"]:\n            for lvl in range(0, self.machine.mmu.radix_levels[mode]):\n                ptr_class = self.machine.mmu.map_ptr_entries_to_levels[mode][lvl]\n                page_classes = self.machine.mmu.map_datapages_entries_to_levels[mode][\n                    lvl\n                ]\n                for table_addr, table_obj in self.data.page_tables[mode][lvl].items():\n                    for entry_obj in table_obj.entries[ptr_class].values():\n                        self.data.reverse_map_tables[mode][lvl][entry_obj.address].add(\n                            table_obj.address\n                        )\n                    for page_class in page_classes:\n                        for entry_obj in table_obj.entries[page_class].values():\n                            self.data.reverse_map_pages[mode][lvl][\n                                entry_obj.address\n                            ].add(table_obj.address)\n\n        # If kernel and user space use the same configuration, copy kernel data to user\n        trees_struct = tcr.get_trees_struct()\n        if trees_struct[\"kernel\"] == trees_struct[\"user\"]:\n            self.data.page_tables[\"user\"] = self.data.page_tables[\"kernel\"]\n            self.data.reverse_map_pages[\"user\"] = self.data.reverse_map_pages[\"kernel\"]\n            self.data.reverse_map_tables[\"user\"] = self.data.reverse_map_tables[\n                \"kernel\"\n            ]\n            self.data.data_pages[\"user\"] = self.data.data_pages[\"kernel\"]\n            self.data.empty_tables[\"user\"] = self.data.empty_tables[\"kernel\"]\n\n        self.data.is_tables_found = True\n\n    def do_show_table(self, args):\n        \"\"\"Show MMU table at chosen address. Usage: show_table ADDRESS (user, kernel) [level size]\"\"\"\n        if not self.data.used_tcr:\n            logging.error(\"Please set a TCR register to use, using set_tcr TCR\")\n            return\n\n        args = args.split()\n        if len(args) &lt; 2:\n            logger.warning(\"Missing argument\")\n            return\n\n        try:\n            addr = self.parse_int(args[0])\n        except ValueError:\n            logger.warning(\"Invalid table address\")\n            return\n\n        if addr not in self.machine.memory:\n            logger.warning(\"Table not in RAM range\")\n            return\n\n        args[1] = args[1].lower()\n        if args[1] not in [\"kernel\", \"user\"]:\n            logger.warning(\"Mode must be kernel or user\")\n            return\n        mode = args[1]\n\n        if len(args) == 4:\n            try:\n                lvl = self.parse_int(args[2])\n                if lvl &gt; (self.machine.mmu.radix_levels[mode] - 1):\n                    raise ValueError\n            except ValueError:\n                logger.warning(\n                    f\"Level must be an integer between 0 and {self.machine.mmu.radix_levels[mode] - 1}\"\n                )\n                return\n\n            trees_struct = LONG.tcr.get_trees_struct()\n            valid_sizes = {\"user\": defaultdict(set), \"kernel\": defaultdict(set)}\n            valid_sizes[\"kernel\"][0].add(trees_struct[\"kernel\"][\"top_table_size\"])\n            valid_sizes[\"user\"][0].add(trees_struct[\"user\"][\"top_table_size\"])\n            for i in range(1, trees_struct[\"kernel\"][\"total_levels\"]):\n                valid_sizes[\"kernel\"][i].add(trees_struct[\"kernel\"][\"granule\"])\n            for i in range(1, trees_struct[\"user\"][\"total_levels\"]):\n                valid_sizes[\"user\"][i].add(trees_struct[\"user\"][\"granule\"])\n\n            try:\n                table_size = self.parse_int(args[3])\n                if table_size not in valid_sizes[mode][lvl]:\n                    logging.warning(\n                        f\"Size not allowed for choosen level! Valid sizes are:{valid_sizes[mode][lvl]}\"\n                    )\n                    return\n            except ValueError:\n                logger.warning(\"Invalid size value\")\n                return\n        else:\n            table_size = 0x10000\n            lvl = -1\n\n        table_buff = self.machine.memory.get_data(addr, table_size)\n        invalids, pt_classes, table_obj = self.machine.mmu.parse_frame(\n            table_buff, addr, table_size, lvl, mode=mode\n        )\n        print(table_obj)\n        print(f\"Invalid entries: {invalids} Table levels: {pt_classes}\")\n\n    def do_find_radix_trees(self, args):\n        \"\"\"Reconstruct radix trees\"\"\"\n        if not self.data.is_tables_found:\n            logging.info(\"Please, parse the memory first!\")\n            return\n\n        if not self.data.is_registers_found:\n            logging.info(\"Please find MMU related opcodes first!\")\n            return\n\n        if self.data.ttbrs:\n            self.data.ttbrs.clear()\n\n        # Some table level was not found...\n        if not len(self.data.page_tables[\"kernel\"][0]) and not len(\n            self.data.page_tables[\"user\"][0]\n        ):\n            logger.warning(\"OOPS... no tables in first level... Wrong MMU mode?\")\n            return\n\n        ttbrs_candidates = {\"kernel\": [], \"user\": []}\n        trees_struct = self.machine.mmu.tcr.get_trees_struct()\n\n        # Collect opcodes\n        opcode_classes = defaultdict(list)\n        for opcode_addr, opcode_data in self.data.opcodes.items():\n            opcode_classes[\n                (opcode_data[\"instruction\"], opcode_data[\"register\"])\n            ].append(opcode_addr)\n\n        # Find all TTBR1_EL1 which contain interrupt related opcodes\n        logging.info(\"Find TTBR1_EL1 candidates...\")\n        int_opcode_addrs = (\n            opcode_classes[(\"MRS\", \"ESR_EL1\")]\n            + opcode_classes[(\"MRS\", \"FAR_EL1\")]\n            + opcode_classes[(\"MRS\", \"ELR_EL1\")]\n        )\n        already_explored = set()\n        for opcode_addr in int_opcode_addrs:\n            derived_addresses = self.machine.mmu.derive_page_address(\n                opcode_addr, mode=\"kernel\"\n            )\n            for derived_address in derived_addresses:\n                if derived_address in already_explored:\n                    continue\n\n                lvl, addr = derived_address\n                ttbrs_candidates[\"kernel\"].extend(\n                    self.radix_roots_from_data_page(\n                        lvl,\n                        addr,\n                        self.data.reverse_map_pages[\"kernel\"],\n                        self.data.reverse_map_tables[\"kernel\"],\n                    )\n                )\n                already_explored.add(derived_address)\n\n        ttbrs_candidates[\"kernel\"] = list(\n            set(ttbrs_candidates[\"kernel\"]).intersection(\n                self.data.page_tables[\"kernel\"][0].keys()\n            )\n        )\n\n        # Filter kernel candidates for ERET and write on MMU registers\n        logger.info(\"Filtering TTBR1_EL1 candidates...\")\n        mmu_w_opcode_addrs = (\n            opcode_classes[(\"MSR\", \"TCR_EL1\")] + opcode_classes[(\"MSR\", \"TTBR0_EL1\")]\n        )\n        phy_cache = defaultdict(dict)\n        ttbrs_filtered = {\"kernel\": {}, \"user\": {}}\n        virt_cache = defaultdict(dict)\n        for candidate in tqdm(ttbrs_candidates[\"kernel\"]):\n            # Calculate physpace and discard empty ones\n            consistency, pas = self.physpace(\n                candidate,\n                self.data.page_tables[\"kernel\"],\n                self.data.empty_tables[\"kernel\"],\n                mode=\"kernel\",\n                hierarchical=True,\n                cache=phy_cache,\n            )\n\n            # Discard inconsistent one\n            if not consistency:\n                continue\n\n            # WARNING! We cannot filter for user_size = 0 due to TCR_EL1.E0PD1 !\n            # Check if at least one MMU opcode in physical address space\n            for opcode_addr in mmu_w_opcode_addrs:\n                if pas.is_in_kernel_space(opcode_addr):\n                    break\n            else:\n                continue\n\n            # Check if at least one ERET opcode in physical address space\n            for opcode_addr in opcode_classes[(\"ERET\", \"\")]:\n                if pas.is_in_kernel_space(opcode_addr):\n                    break\n            else:\n                continue\n\n            # At least a page must be writable by the kernel and not by user\n            for perms in pas.space:\n                if perms[1] and not perms[4]:\n                    break\n            else:\n                continue\n\n            vas = self.virtspace(\n                candidate, mode=\"kernel\", hierarchical=True, cache=virt_cache\n            )\n            radix_tree = RadixTree(\n                candidate,\n                trees_struct[\"kernel\"][\"total_levels\"],\n                pas,\n                vas,\n                kernel=True,\n                user=False,\n            )\n            ttbrs_filtered[\"kernel\"][candidate] = radix_tree\n\n        # Find all TTBR0_EL1 which contain at least one RET instruction\n        already_explored = set()\n        virt_cache.clear()\n        logging.info(\"Find TTBR0_EL1 candidates...\")\n        for opcode_addr in opcode_classes[(\"RET\", \"\")]:\n            derived_addresses = self.machine.mmu.derive_page_address(\n                opcode_addr, mode=\"user\"\n            )\n            for derived_address in derived_addresses:\n                if derived_address in already_explored:\n                    continue\n\n                lvl, addr = derived_address\n                ttbrs_candidates[\"user\"].extend(\n                    self.radix_roots_from_data_page(\n                        lvl,\n                        addr,\n                        self.data.reverse_map_pages[\"user\"],\n                        self.data.reverse_map_tables[\"user\"],\n                    )\n                )\n                already_explored.add(derived_address)\n\n        ttbrs_candidates[\"user\"] = list(\n            set(ttbrs_candidates[\"user\"]).intersection(\n                self.data.page_tables[\"user\"][0].keys()\n            )\n        )\n\n        logger.info(\"Filtering TTBR0_EL1 candidates...\")\n        phy_cache = defaultdict(dict)\n        for candidate in tqdm(ttbrs_candidates[\"user\"]):\n            # Calculate physpace and discard empty ones\n            consistency, pas = self.physpace(\n                candidate,\n                self.data.page_tables[\"user\"],\n                self.data.empty_tables[\"user\"],\n                mode=\"user\",\n                hierarchical=True,\n                cache=phy_cache,\n            )\n\n            # Discard inconsistent one\n            if not consistency:\n                continue\n\n            # At least a page must be R or W in usermode\n            for perms in pas.space:\n                if perms[3] or perms[4]:\n                    break\n            else:\n                continue\n\n            # Check if at least one BLR opcode in physical address space\n            for opcode_addr in opcode_classes[(\"BLR\", \"\")]:\n                if opcode_addr in pas:\n                    break\n            else:\n                continue\n\n            vas = self.virtspace(\n                candidate, mode=\"user\", hierarchical=True, cache=virt_cache\n            )\n            radix_tree = RadixTree(\n                candidate,\n                trees_struct[\"user\"][\"total_levels\"],\n                pas,\n                vas,\n                kernel=False,\n                user=True,\n            )\n            ttbrs_filtered[\"user\"][candidate] = radix_tree\n\n        self.data.ttbrs = ttbrs_filtered\n        self.data.is_radix_found = True\n\n    def do_show_radix_trees(self, args):\n        \"\"\"Show radix trees found\"\"\"\n        if not self.data.is_radix_found:\n            logging.info(\"Please, find them first!\")\n            return\n\n        labels = [\n            \"Radix address\",\n            \"Total levels\",\n            \"Kernel size (Bytes)\",\n            \"User size (Bytes)\",\n            \"Kernel\",\n        ]\n        table = PrettyTable()\n        table.field_names = labels\n        for mode in [\"kernel\", \"user\"]:\n            for ttbr in self.data.ttbrs[mode].values():\n                table.add_row(\n                    ttbr.entry_resume_stringified() + [\"X\" if mode == \"kernel\" else \"\"]\n                )\n        table.sortby = \"Radix address\"\n        print(table)\n</code></pre>"},{"location":"reference/architectures/aarch64/#mmushell.architectures.aarch64.MMUShell.do_find_radix_trees","title":"<code>do_find_radix_trees(args)</code>","text":"<p>Reconstruct radix trees</p> Source code in <code>mmushell/architectures/aarch64.py</code> <pre><code>def do_find_radix_trees(self, args):\n    \"\"\"Reconstruct radix trees\"\"\"\n    if not self.data.is_tables_found:\n        logging.info(\"Please, parse the memory first!\")\n        return\n\n    if not self.data.is_registers_found:\n        logging.info(\"Please find MMU related opcodes first!\")\n        return\n\n    if self.data.ttbrs:\n        self.data.ttbrs.clear()\n\n    # Some table level was not found...\n    if not len(self.data.page_tables[\"kernel\"][0]) and not len(\n        self.data.page_tables[\"user\"][0]\n    ):\n        logger.warning(\"OOPS... no tables in first level... Wrong MMU mode?\")\n        return\n\n    ttbrs_candidates = {\"kernel\": [], \"user\": []}\n    trees_struct = self.machine.mmu.tcr.get_trees_struct()\n\n    # Collect opcodes\n    opcode_classes = defaultdict(list)\n    for opcode_addr, opcode_data in self.data.opcodes.items():\n        opcode_classes[\n            (opcode_data[\"instruction\"], opcode_data[\"register\"])\n        ].append(opcode_addr)\n\n    # Find all TTBR1_EL1 which contain interrupt related opcodes\n    logging.info(\"Find TTBR1_EL1 candidates...\")\n    int_opcode_addrs = (\n        opcode_classes[(\"MRS\", \"ESR_EL1\")]\n        + opcode_classes[(\"MRS\", \"FAR_EL1\")]\n        + opcode_classes[(\"MRS\", \"ELR_EL1\")]\n    )\n    already_explored = set()\n    for opcode_addr in int_opcode_addrs:\n        derived_addresses = self.machine.mmu.derive_page_address(\n            opcode_addr, mode=\"kernel\"\n        )\n        for derived_address in derived_addresses:\n            if derived_address in already_explored:\n                continue\n\n            lvl, addr = derived_address\n            ttbrs_candidates[\"kernel\"].extend(\n                self.radix_roots_from_data_page(\n                    lvl,\n                    addr,\n                    self.data.reverse_map_pages[\"kernel\"],\n                    self.data.reverse_map_tables[\"kernel\"],\n                )\n            )\n            already_explored.add(derived_address)\n\n    ttbrs_candidates[\"kernel\"] = list(\n        set(ttbrs_candidates[\"kernel\"]).intersection(\n            self.data.page_tables[\"kernel\"][0].keys()\n        )\n    )\n\n    # Filter kernel candidates for ERET and write on MMU registers\n    logger.info(\"Filtering TTBR1_EL1 candidates...\")\n    mmu_w_opcode_addrs = (\n        opcode_classes[(\"MSR\", \"TCR_EL1\")] + opcode_classes[(\"MSR\", \"TTBR0_EL1\")]\n    )\n    phy_cache = defaultdict(dict)\n    ttbrs_filtered = {\"kernel\": {}, \"user\": {}}\n    virt_cache = defaultdict(dict)\n    for candidate in tqdm(ttbrs_candidates[\"kernel\"]):\n        # Calculate physpace and discard empty ones\n        consistency, pas = self.physpace(\n            candidate,\n            self.data.page_tables[\"kernel\"],\n            self.data.empty_tables[\"kernel\"],\n            mode=\"kernel\",\n            hierarchical=True,\n            cache=phy_cache,\n        )\n\n        # Discard inconsistent one\n        if not consistency:\n            continue\n\n        # WARNING! We cannot filter for user_size = 0 due to TCR_EL1.E0PD1 !\n        # Check if at least one MMU opcode in physical address space\n        for opcode_addr in mmu_w_opcode_addrs:\n            if pas.is_in_kernel_space(opcode_addr):\n                break\n        else:\n            continue\n\n        # Check if at least one ERET opcode in physical address space\n        for opcode_addr in opcode_classes[(\"ERET\", \"\")]:\n            if pas.is_in_kernel_space(opcode_addr):\n                break\n        else:\n            continue\n\n        # At least a page must be writable by the kernel and not by user\n        for perms in pas.space:\n            if perms[1] and not perms[4]:\n                break\n        else:\n            continue\n\n        vas = self.virtspace(\n            candidate, mode=\"kernel\", hierarchical=True, cache=virt_cache\n        )\n        radix_tree = RadixTree(\n            candidate,\n            trees_struct[\"kernel\"][\"total_levels\"],\n            pas,\n            vas,\n            kernel=True,\n            user=False,\n        )\n        ttbrs_filtered[\"kernel\"][candidate] = radix_tree\n\n    # Find all TTBR0_EL1 which contain at least one RET instruction\n    already_explored = set()\n    virt_cache.clear()\n    logging.info(\"Find TTBR0_EL1 candidates...\")\n    for opcode_addr in opcode_classes[(\"RET\", \"\")]:\n        derived_addresses = self.machine.mmu.derive_page_address(\n            opcode_addr, mode=\"user\"\n        )\n        for derived_address in derived_addresses:\n            if derived_address in already_explored:\n                continue\n\n            lvl, addr = derived_address\n            ttbrs_candidates[\"user\"].extend(\n                self.radix_roots_from_data_page(\n                    lvl,\n                    addr,\n                    self.data.reverse_map_pages[\"user\"],\n                    self.data.reverse_map_tables[\"user\"],\n                )\n            )\n            already_explored.add(derived_address)\n\n    ttbrs_candidates[\"user\"] = list(\n        set(ttbrs_candidates[\"user\"]).intersection(\n            self.data.page_tables[\"user\"][0].keys()\n        )\n    )\n\n    logger.info(\"Filtering TTBR0_EL1 candidates...\")\n    phy_cache = defaultdict(dict)\n    for candidate in tqdm(ttbrs_candidates[\"user\"]):\n        # Calculate physpace and discard empty ones\n        consistency, pas = self.physpace(\n            candidate,\n            self.data.page_tables[\"user\"],\n            self.data.empty_tables[\"user\"],\n            mode=\"user\",\n            hierarchical=True,\n            cache=phy_cache,\n        )\n\n        # Discard inconsistent one\n        if not consistency:\n            continue\n\n        # At least a page must be R or W in usermode\n        for perms in pas.space:\n            if perms[3] or perms[4]:\n                break\n        else:\n            continue\n\n        # Check if at least one BLR opcode in physical address space\n        for opcode_addr in opcode_classes[(\"BLR\", \"\")]:\n            if opcode_addr in pas:\n                break\n        else:\n            continue\n\n        vas = self.virtspace(\n            candidate, mode=\"user\", hierarchical=True, cache=virt_cache\n        )\n        radix_tree = RadixTree(\n            candidate,\n            trees_struct[\"user\"][\"total_levels\"],\n            pas,\n            vas,\n            kernel=False,\n            user=True,\n        )\n        ttbrs_filtered[\"user\"][candidate] = radix_tree\n\n    self.data.ttbrs = ttbrs_filtered\n    self.data.is_radix_found = True\n</code></pre>"},{"location":"reference/architectures/aarch64/#mmushell.architectures.aarch64.MMUShell.do_find_registers_values","title":"<code>do_find_registers_values(arg)</code>","text":"<p>Find MMU load opcodes and execute MMU related functions inside the memory dump in order to extract MMU registers values</p> Source code in <code>mmushell/architectures/aarch64.py</code> <pre><code>def do_find_registers_values(self, arg):\n    \"\"\"Find MMU load opcodes and execute MMU related functions inside the memory dump in order to extract MMU registers values\"\"\"\n\n    if self.data.is_registers_found:\n        logging.warning(\"Registers already searched\")\n        return\n\n    logger.info(\"Look for opcodes related to MMU setup...\")\n    parallel_results = self.machine.apply_parallel(\n        65536, self.machine.cpu.parse_opcodes_parallel\n    )\n\n    opcodes = {}\n    logger.info(\"Reaggregate threads data...\")\n    for result in parallel_results:\n        opcodes.update(result.get())\n\n    self.data.opcodes = opcodes\n\n    # Filter to look only for opcodes which write on MMU register only and not read from them or from other registers\n    filter_f = (\n        lambda it: True\n        if it[1][\"register\"] == \"TCR_EL1\" and it[1][\"instruction\"] == \"MSR\"\n        else False\n    )\n    mmu_wr_opcodes = {k: v for k, v in filter(filter_f, opcodes.items())}\n\n    logging.info(\"Use heuristics to find function addresses...\")\n    logging.info(\"This analysis could be extremely slow!\")\n    self.machine.cpu.identify_functions_start(mmu_wr_opcodes)\n\n    logging.info(\"Identify register values using data flow analysis...\")\n\n    # We use data flow analysis and merge the results\n    dataflow_values = self.machine.cpu.find_registers_values_dataflow(\n        mmu_wr_opcodes\n    )\n\n    filtered_values = defaultdict(set)\n    for register, values in dataflow_values.items():\n        for value in values:\n            reg_obj = CPURegAArch64.get_register_obj(register, value)\n            if reg_obj.valid and not any(\n                [\n                    val_obj.is_mmu_equivalent_to(reg_obj)\n                    for val_obj in filtered_values[register]\n                ]\n            ):\n                filtered_values[register].add(reg_obj)\n\n    self.data.regs_values = filtered_values\n    self.data.is_registers_found = True\n\n    # Show results\n    logging.info(\"TCR_EL1 values recovered:\")\n    for reg_obj in self.data.regs_values[\"TCR_EL1\"]:\n        logging.info(reg_obj)\n</code></pre>"},{"location":"reference/architectures/aarch64/#mmushell.architectures.aarch64.MMUShell.do_find_tables","title":"<code>do_find_tables(args)</code>","text":"<p>Find MMU tables in memory</p> Source code in <code>mmushell/architectures/aarch64.py</code> <pre><code>def do_find_tables(self, args):\n    \"\"\"Find MMU tables in memory\"\"\"\n    if not self.data.used_tcr:\n        logging.error(\"Please set a TCR register to use, using set_tcr TCR\")\n        return\n    tcr = self.data.used_tcr\n\n    # Delete all the previous table data\n    if self.data.is_tables_found:\n        self.data.page_tables = {\n            \"user\": defaultdict(dict),\n            \"kernel\": defaultdict(dict),\n        }\n        self.data.data_pages = {\"user\": [], \"kernel\": []}\n        self.data.empty_tables = {\"user\": [], \"kernel\": []}\n        self.data.reverse_map_tables = {}\n        self.data.reverse_map_pages = {}\n\n    # WORKAROUND: initialize here because unpickable!\n    self.data.reverse_map_pages = {\n        \"kernel\": defaultdict(_dummy_f),\n        \"user\": defaultdict(_dummy_f),\n    }\n    self.data.reverse_map_tables = {\n        \"kernel\": defaultdict(_dummy_f),\n        \"user\": defaultdict(_dummy_f),\n    }\n\n    # Parse memory in chunk of 64KiB\n    logger.info(\"Look for paging tables...\")\n    parallel_results = self.machine.apply_parallel(\n        65536, self.machine.mmu.parse_parallel_frame, tcr=tcr\n    )\n    logger.info(\"Reaggregate threads data...\")\n    for result in parallel_results:\n        page_tables, data_pages, empty_tables = result.get()\n\n        for mode in [\"user\", \"kernel\"]:\n            for level in range(self.machine.mmu.radix_levels[mode]):\n                self.data.page_tables[mode][level].update(page_tables[mode][level])\n\n            self.data.data_pages[mode].extend(data_pages[mode])\n            self.data.empty_tables[mode].extend(empty_tables[mode])\n\n    for mode in [\"user\", \"kernel\"]:\n        self.data.data_pages[mode] = set(self.data.data_pages[mode])\n        self.data.empty_tables[mode] = set(self.data.empty_tables[mode])\n\n    # Remove all tables which point to inexistent table of lower level\n    logger.info(\"Reduce false positives...\")\n    for mode in [\"user\", \"kernel\"]:\n        for lvl in range(self.machine.mmu.radix_levels[mode] - 1):\n            ptr_class = self.machine.mmu.map_ptr_entries_to_levels[mode][lvl]\n            referenced_nxt = []\n            for table_addr in list(self.data.page_tables[mode][lvl].keys()):\n                for entry_obj in (\n                    self.data.page_tables[mode][lvl][table_addr]\n                    .entries[ptr_class]\n                    .values()\n                ):\n                    if (\n                        entry_obj.address\n                        not in self.data.page_tables[mode][lvl + 1]\n                        and entry_obj.address not in self.data.empty_tables[mode]\n                    ):\n                        # Remove the table\n                        self.data.page_tables[mode][lvl].pop(table_addr)\n                        break\n\n                    else:\n                        referenced_nxt.append(entry_obj.address)\n\n            # Remove table not referenced by upper levels\n            referenced_nxt = set(referenced_nxt)\n            for table_addr in set(\n                self.data.page_tables[mode][lvl + 1].keys()\n            ).difference(referenced_nxt):\n                self.data.page_tables[mode][lvl + 1].pop(table_addr)\n\n    logger.info(\"Fill reverse maps...\")\n    for mode in [\"user\", \"kernel\"]:\n        for lvl in range(0, self.machine.mmu.radix_levels[mode]):\n            ptr_class = self.machine.mmu.map_ptr_entries_to_levels[mode][lvl]\n            page_classes = self.machine.mmu.map_datapages_entries_to_levels[mode][\n                lvl\n            ]\n            for table_addr, table_obj in self.data.page_tables[mode][lvl].items():\n                for entry_obj in table_obj.entries[ptr_class].values():\n                    self.data.reverse_map_tables[mode][lvl][entry_obj.address].add(\n                        table_obj.address\n                    )\n                for page_class in page_classes:\n                    for entry_obj in table_obj.entries[page_class].values():\n                        self.data.reverse_map_pages[mode][lvl][\n                            entry_obj.address\n                        ].add(table_obj.address)\n\n    # If kernel and user space use the same configuration, copy kernel data to user\n    trees_struct = tcr.get_trees_struct()\n    if trees_struct[\"kernel\"] == trees_struct[\"user\"]:\n        self.data.page_tables[\"user\"] = self.data.page_tables[\"kernel\"]\n        self.data.reverse_map_pages[\"user\"] = self.data.reverse_map_pages[\"kernel\"]\n        self.data.reverse_map_tables[\"user\"] = self.data.reverse_map_tables[\n            \"kernel\"\n        ]\n        self.data.data_pages[\"user\"] = self.data.data_pages[\"kernel\"]\n        self.data.empty_tables[\"user\"] = self.data.empty_tables[\"kernel\"]\n\n    self.data.is_tables_found = True\n</code></pre>"},{"location":"reference/architectures/aarch64/#mmushell.architectures.aarch64.MMUShell.do_set_tcr","title":"<code>do_set_tcr(args)</code>","text":"<p>Set TCR to be used</p> Source code in <code>mmushell/architectures/aarch64.py</code> <pre><code>def do_set_tcr(self, args):\n    \"\"\"Set TCR to be used\"\"\"\n    args = args.split()\n    if len(args) == 0:\n        logging.error(\"Please use find_tables TCR_VALUE\")\n        return\n\n    try:\n        tcr_val = self.parse_int(args[0])\n        tcr = TCR_EL1(tcr_val)\n        if not tcr.valid:\n            raise ValueError\n    except ValueError:\n        logger.warning(\"Invalid TCR value\")\n        return\n\n    self.data.used_tcr = tcr\n\n    # Set all MMU parameters\n    LONG.tcr = tcr\n    LONG.radix_levels = {}\n    trees_struct = tcr.get_trees_struct()\n\n    for mode in [\"user\", \"kernel\"]:\n        granule = trees_struct[mode][\"granule\"]\n        total_levels = trees_struct[mode][\"total_levels\"]\n        top_table_size = trees_struct[mode][\"top_table_size\"]\n\n        LONG.radix_levels[mode] = total_levels\n        LONG.map_level_to_table_size[mode] = [top_table_size] + (\n            [granule] * (total_levels - 1)\n        )\n        LONG.map_reserved_entries_to_levels[mode] = [\n            [] for i in range(total_levels - 1)\n        ] + [[ReservedEntry]]\n\n        if granule == 4096:\n            if total_levels == 1:\n                LONG.map_datapages_entries_to_levels[mode] = [PTPAGE_4KB]\n                LONG.map_ptr_entries_to_levels[mode] = [None]\n                LONG.map_entries_to_shifts[mode] = {PTPAGE_4KB: 12}\n            elif total_levels == 2:\n                LONG.map_datapages_entries_to_levels[mode] = [\n                    [PTBLOCK_L2_4KB],\n                    [PTPAGE_4KB],\n                ]\n                LONG.map_ptr_entries_to_levels[mode] = [PTP_4KB_L0, None]\n                LONG.map_entries_to_shifts[mode] = {\n                    PTP_4KB_L0: 21,\n                    PTPAGE_4KB: 12,\n                    PTBLOCK_L2_4KB: 21,\n                }\n            elif total_levels == 3:\n                LONG.map_datapages_entries_to_levels[mode] = [\n                    [PTBLOCK_L1_4KB],\n                    [PTBLOCK_L2_4KB],\n                    [PTPAGE_4KB],\n                ]\n                LONG.map_ptr_entries_to_levels[mode] = [\n                    PTP_4KB_L0,\n                    PTP_4KB_L1,\n                    None,\n                ]\n                LONG.map_entries_to_shifts[mode] = {\n                    PTP_4KB_L0: 30,\n                    PTP_4KB_L1: 21,\n                    PTPAGE_4KB: 12,\n                    PTBLOCK_L2_4KB: 21,\n                    PTBLOCK_L1_4KB: 30,\n                }\n            else:\n                LONG.map_datapages_entries_to_levels[mode] = [\n                    [None],\n                    [PTBLOCK_L1_4KB],\n                    [PTBLOCK_L2_4KB],\n                    [PTPAGE_4KB],\n                ]\n                LONG.map_ptr_entries_to_levels[mode] = [\n                    PTP_4KB_L0,\n                    PTP_4KB_L1,\n                    PTP_4KB_L2,\n                    None,\n                ]\n                LONG.map_entries_to_shifts[mode] = {\n                    PTP_4KB_L0: 39,\n                    PTP_4KB_L1: 30,\n                    PTP_4KB_L2: 21,\n                    PTPAGE_4KB: 12,\n                    PTBLOCK_L2_4KB: 21,\n                    PTBLOCK_L1_4KB: 30,\n                }\n\n        elif granule == 16384:\n            if total_levels == 1:\n                LONG.map_datapages_entries_to_levels[mode] = [PTPAGE_16KB]\n                LONG.map_ptr_entries_to_levels[mode] = [None]\n                LONG.map_entries_to_shifts[mode] = {PTPAGE_16KB: 14}\n            elif total_levels == 2:\n                LONG.map_datapages_entries_to_levels[mode] = [\n                    [PTBLOCK_L2_16KB],\n                    [PTPAGE_16KB],\n                ]\n                LONG.map_ptr_entries_to_levels[mode] = [PTP_16KB_L0, None]\n                LONG.map_entries_to_shifts[mode] = {\n                    PTP_16KB_L0: 25,\n                    PTPAGE_16KB: 14,\n                    PTBLOCK_L2_16KB: 25,\n                }\n            elif total_levels == 3:\n                LONG.map_datapages_entries_to_levels[mode] = [\n                    [None],\n                    [PTBLOCK_L2_16KB],\n                    [PTPAGE_16KB],\n                ]\n                LONG.map_ptr_entries_to_levels[mode] = [\n                    PTP_16KB_L0,\n                    PTP_16KB_L1,\n                    None,\n                ]\n                LONG.map_entries_to_shifts[mode] = {\n                    PTP_16KB_L0: 36,\n                    PTP_16KB_L1: 25,\n                    PTPAGE_16KB: 14,\n                    PTBLOCK_L2_16KB: 25,\n                }\n            else:\n                LONG.map_datapages_entries_to_levels[mode] = [\n                    [None],\n                    [None],\n                    [PTBLOCK_L2_16KB],\n                    [PTPAGE_16KB],\n                ]\n                LONG.map_ptr_entries_to_levels[mode] = [\n                    PTP_16KB_L0,\n                    PTP_16KB_L2,\n                    None,\n                ]\n                LONG.map_entries_to_shifts[mode] = {\n                    PTP_16KB_L0: 47,\n                    PTP_16KB_L1: 36,\n                    PTP_16KB_L2: 25,\n                    PTPAGE_16KB: 14,\n                    PTBLOCK_L2_16KB: 25,\n                }\n\n        else:\n            if total_levels == 1:\n                LONG.map_datapages_entries_to_levels[mode] = [PTPAGE_64KB]\n                LONG.map_ptr_entries_to_levels[mode] = [None]\n                LONG.map_entries_to_shifts[mode] = {\n                    PTPAGE_64KB: 16,\n                    PTBLOCK_L2_64KB: 29,\n                }\n            elif total_levels == 2:\n                LONG.map_datapages_entries_to_levels[mode] = [\n                    [PTBLOCK_L2_64KB],\n                    [PTPAGE_64KB],\n                ]\n                LONG.map_ptr_entries_to_levels[mode] = [PTP_64KB_L0, None]\n                LONG.map_entries_to_shifts[mode] = {\n                    PTP_64KB_L0: 29,\n                    PTPAGE_64KB: 16,\n                    PTBLOCK_L2_16KB: 29,\n                }\n            else:\n                LONG.map_datapages_entries_to_levels[mode] = [\n                    [None],\n                    [PTBLOCK_L2_64KB],\n                    [PTPAGE_64KB],\n                ]\n                LONG.map_ptr_entries_to_levels[mode] = [\n                    PTP_64KB_L0,\n                    PTP_64KB_L1,\n                    None,\n                ]\n                LONG.map_entries_to_shifts[mode] = {\n                    PTP_64KB_L0: 42,\n                    PTP_64KB_L1: 29,\n                    PTPAGE_64KB: 16,\n                    PTBLOCK_L2_64KB: 29,\n                }\n</code></pre>"},{"location":"reference/architectures/aarch64/#mmushell.architectures.aarch64.MMUShell.do_show_radix_trees","title":"<code>do_show_radix_trees(args)</code>","text":"<p>Show radix trees found</p> Source code in <code>mmushell/architectures/aarch64.py</code> <pre><code>def do_show_radix_trees(self, args):\n    \"\"\"Show radix trees found\"\"\"\n    if not self.data.is_radix_found:\n        logging.info(\"Please, find them first!\")\n        return\n\n    labels = [\n        \"Radix address\",\n        \"Total levels\",\n        \"Kernel size (Bytes)\",\n        \"User size (Bytes)\",\n        \"Kernel\",\n    ]\n    table = PrettyTable()\n    table.field_names = labels\n    for mode in [\"kernel\", \"user\"]:\n        for ttbr in self.data.ttbrs[mode].values():\n            table.add_row(\n                ttbr.entry_resume_stringified() + [\"X\" if mode == \"kernel\" else \"\"]\n            )\n    table.sortby = \"Radix address\"\n    print(table)\n</code></pre>"},{"location":"reference/architectures/aarch64/#mmushell.architectures.aarch64.MMUShell.do_show_registers","title":"<code>do_show_registers(args)</code>","text":"<p>Show TCR values found</p> Source code in <code>mmushell/architectures/aarch64.py</code> <pre><code>def do_show_registers(self, args):\n    \"\"\"Show TCR values found\"\"\"\n    if not self.data.is_registers_found:\n        logging.info(\"Please, find them first!\")\n        return\n\n    for registers in sorted(self.data.regs_values.keys()):\n        for register in self.data.regs_values[registers]:\n            print(register)\n</code></pre>"},{"location":"reference/architectures/aarch64/#mmushell.architectures.aarch64.MMUShell.do_show_table","title":"<code>do_show_table(args)</code>","text":"<p>Show MMU table at chosen address. Usage: show_table ADDRESS (user, kernel) [level size]</p> Source code in <code>mmushell/architectures/aarch64.py</code> <pre><code>def do_show_table(self, args):\n    \"\"\"Show MMU table at chosen address. Usage: show_table ADDRESS (user, kernel) [level size]\"\"\"\n    if not self.data.used_tcr:\n        logging.error(\"Please set a TCR register to use, using set_tcr TCR\")\n        return\n\n    args = args.split()\n    if len(args) &lt; 2:\n        logger.warning(\"Missing argument\")\n        return\n\n    try:\n        addr = self.parse_int(args[0])\n    except ValueError:\n        logger.warning(\"Invalid table address\")\n        return\n\n    if addr not in self.machine.memory:\n        logger.warning(\"Table not in RAM range\")\n        return\n\n    args[1] = args[1].lower()\n    if args[1] not in [\"kernel\", \"user\"]:\n        logger.warning(\"Mode must be kernel or user\")\n        return\n    mode = args[1]\n\n    if len(args) == 4:\n        try:\n            lvl = self.parse_int(args[2])\n            if lvl &gt; (self.machine.mmu.radix_levels[mode] - 1):\n                raise ValueError\n        except ValueError:\n            logger.warning(\n                f\"Level must be an integer between 0 and {self.machine.mmu.radix_levels[mode] - 1}\"\n            )\n            return\n\n        trees_struct = LONG.tcr.get_trees_struct()\n        valid_sizes = {\"user\": defaultdict(set), \"kernel\": defaultdict(set)}\n        valid_sizes[\"kernel\"][0].add(trees_struct[\"kernel\"][\"top_table_size\"])\n        valid_sizes[\"user\"][0].add(trees_struct[\"user\"][\"top_table_size\"])\n        for i in range(1, trees_struct[\"kernel\"][\"total_levels\"]):\n            valid_sizes[\"kernel\"][i].add(trees_struct[\"kernel\"][\"granule\"])\n        for i in range(1, trees_struct[\"user\"][\"total_levels\"]):\n            valid_sizes[\"user\"][i].add(trees_struct[\"user\"][\"granule\"])\n\n        try:\n            table_size = self.parse_int(args[3])\n            if table_size not in valid_sizes[mode][lvl]:\n                logging.warning(\n                    f\"Size not allowed for choosen level! Valid sizes are:{valid_sizes[mode][lvl]}\"\n                )\n                return\n        except ValueError:\n            logger.warning(\"Invalid size value\")\n            return\n    else:\n        table_size = 0x10000\n        lvl = -1\n\n    table_buff = self.machine.memory.get_data(addr, table_size)\n    invalids, pt_classes, table_obj = self.machine.mmu.parse_frame(\n        table_buff, addr, table_size, lvl, mode=mode\n    )\n    print(table_obj)\n    print(f\"Invalid entries: {invalids} Table levels: {pt_classes}\")\n</code></pre>"},{"location":"reference/architectures/aarch64/#mmushell.architectures.aarch64.MMUShellGTruth","title":"<code>MMUShellGTruth</code>","text":"<p>             Bases: <code>MMUShell</code></p> Source code in <code>mmushell/architectures/aarch64.py</code> <pre><code>class MMUShellGTruth(MMUShell):\n    def do_show_registers_gtruth(self, args):\n        \"\"\"Compare TCR values found with the ground truth\"\"\"\n        if not self.data.is_registers_found:\n            logging.info(\"Please, find them first!\")\n            return\n\n        # Check if the last value of TCR was found\n        all_tcrs = {}\n        for reg_name, value_data in self.gtruth.items():\n            if \"TCR_EL1\" in reg_name:\n                for value, value_info in value_data.items():\n                    if value not in all_tcrs or (value_info[1] &gt; all_tcrs[value][1]):\n                        all_tcrs[value] = (value_info[0], value_info[1])\n\n        last_tcr = TCR_EL1(\n            sorted(all_tcrs.keys(), key=lambda x: all_tcrs[x][1], reverse=True)[0]\n        )\n\n        tcr_fields_equals = {}\n        for value_found_obj in self.data.regs_values[\"TCR_EL1\"]:\n            tcr_fields_equals[value_found_obj] = value_found_obj.count_fields_equals(\n                last_tcr\n            )\n        k_sorted = sorted(\n            tcr_fields_equals.keys(), key=lambda x: tcr_fields_equals[x], reverse=True\n        )\n        if not k_sorted:\n            print(f\"Correct TCR_EL1 value: {last_tcr}\")\n            print(\"TCR_EL1 fields found:... 0/4\")\n            print(\"FP: {}\".format(str(len(self.data.regs_values[\"TCR_EL1\"]))))\n            return\n        else:\n            tcr_found = k_sorted[0]\n            correct_fields_found = tcr_fields_equals[tcr_found]\n            print(f\"Correct TCR_EL1 value: {last_tcr}, Found: {tcr_found}\")\n            print(\"TCR_EL1 fields found:... {}/4\".format(correct_fields_found))\n            print(\"FP: {}\".format(str(len(self.data.regs_values[\"TCR_EL1\"]) - 1)))\n\n    def do_show_radix_trees_gtruth(self, args):\n        \"\"\"Compare radix trees found with the ground truth\"\"\"\n        if not self.data.is_radix_found:\n            logging.info(\"Please, find them first!\")\n            return\n\n        # Collect TTBR0 and TTBR1 values from the gtruth\n        ttbr0s = {}\n        ttbr1s = {}\n        ttbr0_phy_cache = defaultdict(dict)\n        ttbr1_phy_cache = defaultdict(dict)\n        virt_cache = defaultdict(dict)\n\n        # Collect opcodes\n        opcode_classes = defaultdict(list)\n        for opcode_addr, opcode_data in self.data.opcodes.items():\n            opcode_classes[\n                (opcode_data[\"instruction\"], opcode_data[\"register\"])\n            ].append(opcode_addr)\n\n        # Kernel radix trees\n        # Filtering using the same criteria used by the algorithm, however we test only candidates which are possible\n        # False Negatives beacuse the interection must always pass the check!\n        mmu_w_opcode_addrs = (\n            opcode_classes[(\"MSR\", \"TCR_EL1\")]\n            + opcode_classes[(\"MSR\", \"TTBR0_EL1\")]\n            + opcode_classes[(\"MSR\", \"TTBR1_EL1\")]\n        )\n\n        kernel_radix_trees = (\n            False  # Some AArch64 machines do not have TTBR1_EL1 but only TTBR0_EL1\n        )\n        for key in [\"TTBR1_EL1\", \"TTBR1_EL1_S\"]:\n            for value, data in tqdm(self.gtruth.get(key, {}).items()):\n                ttbr = TTBR1_EL1(value)\n\n                try:\n                    for addr_r, data_r in ttbr1s.items():\n                        ttbr_r, dates_r = data_r\n                        if ttbr.is_mmu_equivalent_to(ttbr_r):\n                            if data[0] &lt; dates_r[0]:\n                                ttbr1s[addr_r][1][0] = data[0]\n                            if data[1] &gt; dates_r[1]:\n                                ttbr1s[addr_r][1][1] = data[1]\n                            raise UserWarning\n                except UserWarning:\n                    continue\n\n                if ttbr.address not in self.data.page_tables[\"kernel\"][0]:\n                    continue\n\n                ttbr1s[ttbr.address] = [ttbr, list(data)]\n                kernel_radix_trees = True\n\n        if kernel_radix_trees:\n            tps = sorted(\n                set(ttbr1s.keys()).intersection(set(self.data.ttbrs[\"kernel\"].keys()))\n            )\n            fps = sorted(\n                set(self.data.ttbrs[\"kernel\"].keys()).difference(set(ttbr1s.keys()))\n            )\n            fns_candidates = set(ttbr1s.keys()).difference(\n                set(self.data.ttbrs[\"kernel\"].keys())\n            )\n\n            fns = []\n            # Check False negatives\n            for candidate in tqdm(fns_candidates):\n                # Calculate physpace and discard empty ones\n                consistency, pas = self.physpace(\n                    candidate,\n                    self.data.page_tables[\"kernel\"],\n                    self.data.empty_tables[\"kernel\"],\n                    mode=\"kernel\",\n                    hierarchical=True,\n                    cache=ttbr1_phy_cache,\n                )\n\n                # Discard inconsistent one\n                if not consistency:\n                    continue\n\n                # Check if at least one ERET opcode in physical address space\n                for opcode_addr in opcode_classes[(\"ERET\", \"\")]:\n                    if pas.is_in_kernel_space(opcode_addr):\n                        break\n                else:\n                    continue\n\n                # WARNING! We cannot filter for user_size = 0 due to TCR_EL1.E0PD1 !\n                # Check if at least one MMU opcode in physical address space\n                for opcode_addr in mmu_w_opcode_addrs:\n                    if pas.is_in_kernel_space(opcode_addr):\n                        break\n                else:\n                    continue\n\n                fns.append(candidate)\n            fns.sort()\n\n        # User radix trees\n        for key in [\"TTBR0_EL1\", \"TTBR0_EL1_S\"]:\n            for value, data in tqdm(self.gtruth.get(key, {}).items()):\n                ttbr = TTBR0_EL1(value)\n\n                try:\n                    for addr_r, data_r in ttbr0s.items():\n                        ttbr_r, dates_r = data_r\n                        if ttbr.is_mmu_equivalent_to(ttbr_r):\n                            if data[0] &lt; dates_r[0]:\n                                ttbr0s[addr_r][1][0] = data[0]\n                            if data[1] &gt; dates_r[1]:\n                                ttbr0s[addr_r][1][1] = data[1]\n                            raise UserWarning\n                except UserWarning:\n                    continue\n\n                if ttbr.address not in self.data.page_tables[\"user\"][0]:\n                    continue\n\n                ttbr0s[ttbr.address] = [ttbr, list(data)]\n\n        # If not TTBR1 uses TTBR0 as TTBR0+TTBR1\n        user_ttbrs = list(self.data.ttbrs[\"user\"])\n        if not kernel_radix_trees:\n            user_ttbrs.extend(self.data.ttbrs[\"kernel\"].keys())\n\n        tpsu = sorted(set(ttbr0s.keys()).intersection(set(user_ttbrs)))\n        fpsu = sorted(set(user_ttbrs).difference(set(ttbr0s.keys())))\n        fnsu_candidates = set(ttbr0s.keys()).difference(set(user_ttbrs))\n\n        # Filter FN\n        fnsu = []\n        for candidate in tqdm(fnsu_candidates):\n            # Calculate physpace and discard empty ones\n            consistency, pas = self.physpace(\n                candidate,\n                self.data.page_tables[\"user\"],\n                self.data.empty_tables[\"user\"],\n                mode=\"user\",\n                hierarchical=True,\n                cache=ttbr0_phy_cache,\n            )\n\n            # Discard inconsistent one\n            if not consistency:\n                continue\n\n            # At least a page must be R or W in usermode\n            for perms in pas.space:\n                if perms[3] or perms[4]:\n                    break\n            else:\n                continue\n\n            # Check if at least one BLR opcode in physical address space\n            for opcode_addr in opcode_classes[(\"BLR\", \"\")]:\n                if opcode_addr in pas:\n                    break\n            else:\n                continue\n\n            # Check if at least one RET opcode in physical address space\n            for opcode_addr in opcode_classes[(\"RET\", \"\")]:\n                if opcode_addr in pas:\n                    break\n            else:\n                continue\n\n            fnsu.append(candidate)\n        fnsu.sort()\n\n        # Show results\n        table = PrettyTable()\n        table.field_names = [\"Address\", \"Found\", \"Mode\", \"First seen\", \"Last seen\"]\n        kernel_regs = ttbr1s\n\n        if kernel_radix_trees:\n            umode = \"U\"\n            for tp in sorted(tps):\n                table.add_row(\n                    [hex(tp), \"X\", \"K\", kernel_regs[tp][1][0], kernel_regs[tp][1][1]]\n                )\n\n            for fn in sorted(fns):\n                table.add_row(\n                    [hex(fn), \"\", \"K\", kernel_regs[fn][1][0], kernel_regs[fn][1][1]]\n                )\n\n            for fp in sorted(fps):\n                table.add_row([hex(fp), \"False positive\", \"K\", \"\", \"\"])\n        else:\n            umode = \"K\"\n\n        # User\n        for tp in sorted(tpsu):\n            table.add_row([hex(tp), \"X\", umode, ttbr0s[tp][1][0], ttbr0s[tp][1][1]])\n\n        for fn in sorted(fnsu):\n            table.add_row([hex(fn), \"\", umode, ttbr0s[fn][1][0], ttbr0s[fn][1][1]])\n\n        for fp in sorted(fpsu):\n            table.add_row([hex(fp), \"False positive\", umode, \"\", \"\"])\n\n        print(table)\n        if kernel_radix_trees:\n            print(f\"TP:{len(tps)} FN:{len(fns)} FP:{len(fps)}\")\n            print(f\"USER TP:{len(tpsu)} FN:{len(fnsu)} FP:{len(fpsu)}\")\n        else:\n            print(f\"TP:{len(tpsu)} FN:{len(fnsu)} FP:{len(fpsu)}\")\n</code></pre>"},{"location":"reference/architectures/aarch64/#mmushell.architectures.aarch64.MMUShellGTruth.do_show_radix_trees_gtruth","title":"<code>do_show_radix_trees_gtruth(args)</code>","text":"<p>Compare radix trees found with the ground truth</p> Source code in <code>mmushell/architectures/aarch64.py</code> <pre><code>def do_show_radix_trees_gtruth(self, args):\n    \"\"\"Compare radix trees found with the ground truth\"\"\"\n    if not self.data.is_radix_found:\n        logging.info(\"Please, find them first!\")\n        return\n\n    # Collect TTBR0 and TTBR1 values from the gtruth\n    ttbr0s = {}\n    ttbr1s = {}\n    ttbr0_phy_cache = defaultdict(dict)\n    ttbr1_phy_cache = defaultdict(dict)\n    virt_cache = defaultdict(dict)\n\n    # Collect opcodes\n    opcode_classes = defaultdict(list)\n    for opcode_addr, opcode_data in self.data.opcodes.items():\n        opcode_classes[\n            (opcode_data[\"instruction\"], opcode_data[\"register\"])\n        ].append(opcode_addr)\n\n    # Kernel radix trees\n    # Filtering using the same criteria used by the algorithm, however we test only candidates which are possible\n    # False Negatives beacuse the interection must always pass the check!\n    mmu_w_opcode_addrs = (\n        opcode_classes[(\"MSR\", \"TCR_EL1\")]\n        + opcode_classes[(\"MSR\", \"TTBR0_EL1\")]\n        + opcode_classes[(\"MSR\", \"TTBR1_EL1\")]\n    )\n\n    kernel_radix_trees = (\n        False  # Some AArch64 machines do not have TTBR1_EL1 but only TTBR0_EL1\n    )\n    for key in [\"TTBR1_EL1\", \"TTBR1_EL1_S\"]:\n        for value, data in tqdm(self.gtruth.get(key, {}).items()):\n            ttbr = TTBR1_EL1(value)\n\n            try:\n                for addr_r, data_r in ttbr1s.items():\n                    ttbr_r, dates_r = data_r\n                    if ttbr.is_mmu_equivalent_to(ttbr_r):\n                        if data[0] &lt; dates_r[0]:\n                            ttbr1s[addr_r][1][0] = data[0]\n                        if data[1] &gt; dates_r[1]:\n                            ttbr1s[addr_r][1][1] = data[1]\n                        raise UserWarning\n            except UserWarning:\n                continue\n\n            if ttbr.address not in self.data.page_tables[\"kernel\"][0]:\n                continue\n\n            ttbr1s[ttbr.address] = [ttbr, list(data)]\n            kernel_radix_trees = True\n\n    if kernel_radix_trees:\n        tps = sorted(\n            set(ttbr1s.keys()).intersection(set(self.data.ttbrs[\"kernel\"].keys()))\n        )\n        fps = sorted(\n            set(self.data.ttbrs[\"kernel\"].keys()).difference(set(ttbr1s.keys()))\n        )\n        fns_candidates = set(ttbr1s.keys()).difference(\n            set(self.data.ttbrs[\"kernel\"].keys())\n        )\n\n        fns = []\n        # Check False negatives\n        for candidate in tqdm(fns_candidates):\n            # Calculate physpace and discard empty ones\n            consistency, pas = self.physpace(\n                candidate,\n                self.data.page_tables[\"kernel\"],\n                self.data.empty_tables[\"kernel\"],\n                mode=\"kernel\",\n                hierarchical=True,\n                cache=ttbr1_phy_cache,\n            )\n\n            # Discard inconsistent one\n            if not consistency:\n                continue\n\n            # Check if at least one ERET opcode in physical address space\n            for opcode_addr in opcode_classes[(\"ERET\", \"\")]:\n                if pas.is_in_kernel_space(opcode_addr):\n                    break\n            else:\n                continue\n\n            # WARNING! We cannot filter for user_size = 0 due to TCR_EL1.E0PD1 !\n            # Check if at least one MMU opcode in physical address space\n            for opcode_addr in mmu_w_opcode_addrs:\n                if pas.is_in_kernel_space(opcode_addr):\n                    break\n            else:\n                continue\n\n            fns.append(candidate)\n        fns.sort()\n\n    # User radix trees\n    for key in [\"TTBR0_EL1\", \"TTBR0_EL1_S\"]:\n        for value, data in tqdm(self.gtruth.get(key, {}).items()):\n            ttbr = TTBR0_EL1(value)\n\n            try:\n                for addr_r, data_r in ttbr0s.items():\n                    ttbr_r, dates_r = data_r\n                    if ttbr.is_mmu_equivalent_to(ttbr_r):\n                        if data[0] &lt; dates_r[0]:\n                            ttbr0s[addr_r][1][0] = data[0]\n                        if data[1] &gt; dates_r[1]:\n                            ttbr0s[addr_r][1][1] = data[1]\n                        raise UserWarning\n            except UserWarning:\n                continue\n\n            if ttbr.address not in self.data.page_tables[\"user\"][0]:\n                continue\n\n            ttbr0s[ttbr.address] = [ttbr, list(data)]\n\n    # If not TTBR1 uses TTBR0 as TTBR0+TTBR1\n    user_ttbrs = list(self.data.ttbrs[\"user\"])\n    if not kernel_radix_trees:\n        user_ttbrs.extend(self.data.ttbrs[\"kernel\"].keys())\n\n    tpsu = sorted(set(ttbr0s.keys()).intersection(set(user_ttbrs)))\n    fpsu = sorted(set(user_ttbrs).difference(set(ttbr0s.keys())))\n    fnsu_candidates = set(ttbr0s.keys()).difference(set(user_ttbrs))\n\n    # Filter FN\n    fnsu = []\n    for candidate in tqdm(fnsu_candidates):\n        # Calculate physpace and discard empty ones\n        consistency, pas = self.physpace(\n            candidate,\n            self.data.page_tables[\"user\"],\n            self.data.empty_tables[\"user\"],\n            mode=\"user\",\n            hierarchical=True,\n            cache=ttbr0_phy_cache,\n        )\n\n        # Discard inconsistent one\n        if not consistency:\n            continue\n\n        # At least a page must be R or W in usermode\n        for perms in pas.space:\n            if perms[3] or perms[4]:\n                break\n        else:\n            continue\n\n        # Check if at least one BLR opcode in physical address space\n        for opcode_addr in opcode_classes[(\"BLR\", \"\")]:\n            if opcode_addr in pas:\n                break\n        else:\n            continue\n\n        # Check if at least one RET opcode in physical address space\n        for opcode_addr in opcode_classes[(\"RET\", \"\")]:\n            if opcode_addr in pas:\n                break\n        else:\n            continue\n\n        fnsu.append(candidate)\n    fnsu.sort()\n\n    # Show results\n    table = PrettyTable()\n    table.field_names = [\"Address\", \"Found\", \"Mode\", \"First seen\", \"Last seen\"]\n    kernel_regs = ttbr1s\n\n    if kernel_radix_trees:\n        umode = \"U\"\n        for tp in sorted(tps):\n            table.add_row(\n                [hex(tp), \"X\", \"K\", kernel_regs[tp][1][0], kernel_regs[tp][1][1]]\n            )\n\n        for fn in sorted(fns):\n            table.add_row(\n                [hex(fn), \"\", \"K\", kernel_regs[fn][1][0], kernel_regs[fn][1][1]]\n            )\n\n        for fp in sorted(fps):\n            table.add_row([hex(fp), \"False positive\", \"K\", \"\", \"\"])\n    else:\n        umode = \"K\"\n\n    # User\n    for tp in sorted(tpsu):\n        table.add_row([hex(tp), \"X\", umode, ttbr0s[tp][1][0], ttbr0s[tp][1][1]])\n\n    for fn in sorted(fnsu):\n        table.add_row([hex(fn), \"\", umode, ttbr0s[fn][1][0], ttbr0s[fn][1][1]])\n\n    for fp in sorted(fpsu):\n        table.add_row([hex(fp), \"False positive\", umode, \"\", \"\"])\n\n    print(table)\n    if kernel_radix_trees:\n        print(f\"TP:{len(tps)} FN:{len(fns)} FP:{len(fps)}\")\n        print(f\"USER TP:{len(tpsu)} FN:{len(fnsu)} FP:{len(fpsu)}\")\n    else:\n        print(f\"TP:{len(tpsu)} FN:{len(fnsu)} FP:{len(fpsu)}\")\n</code></pre>"},{"location":"reference/architectures/aarch64/#mmushell.architectures.aarch64.MMUShellGTruth.do_show_registers_gtruth","title":"<code>do_show_registers_gtruth(args)</code>","text":"<p>Compare TCR values found with the ground truth</p> Source code in <code>mmushell/architectures/aarch64.py</code> <pre><code>def do_show_registers_gtruth(self, args):\n    \"\"\"Compare TCR values found with the ground truth\"\"\"\n    if not self.data.is_registers_found:\n        logging.info(\"Please, find them first!\")\n        return\n\n    # Check if the last value of TCR was found\n    all_tcrs = {}\n    for reg_name, value_data in self.gtruth.items():\n        if \"TCR_EL1\" in reg_name:\n            for value, value_info in value_data.items():\n                if value not in all_tcrs or (value_info[1] &gt; all_tcrs[value][1]):\n                    all_tcrs[value] = (value_info[0], value_info[1])\n\n    last_tcr = TCR_EL1(\n        sorted(all_tcrs.keys(), key=lambda x: all_tcrs[x][1], reverse=True)[0]\n    )\n\n    tcr_fields_equals = {}\n    for value_found_obj in self.data.regs_values[\"TCR_EL1\"]:\n        tcr_fields_equals[value_found_obj] = value_found_obj.count_fields_equals(\n            last_tcr\n        )\n    k_sorted = sorted(\n        tcr_fields_equals.keys(), key=lambda x: tcr_fields_equals[x], reverse=True\n    )\n    if not k_sorted:\n        print(f\"Correct TCR_EL1 value: {last_tcr}\")\n        print(\"TCR_EL1 fields found:... 0/4\")\n        print(\"FP: {}\".format(str(len(self.data.regs_values[\"TCR_EL1\"]))))\n        return\n    else:\n        tcr_found = k_sorted[0]\n        correct_fields_found = tcr_fields_equals[tcr_found]\n        print(f\"Correct TCR_EL1 value: {last_tcr}, Found: {tcr_found}\")\n        print(\"TCR_EL1 fields found:... {}/4\".format(correct_fields_found))\n        print(\"FP: {}\".format(str(len(self.data.regs_values[\"TCR_EL1\"]) - 1)))\n</code></pre>"},{"location":"reference/architectures/arm/","title":"ARM","text":""},{"location":"reference/architectures/arm/#arm","title":"ARM","text":""},{"location":"reference/architectures/arm/#mmushell.architectures.arm.MMUShell","title":"<code>MMUShell</code>","text":"<p>             Bases: <code>MMUShell</code></p> Source code in <code>mmushell/architectures/arm.py</code> <pre><code>class MMUShell(MMUShellDefault):\n    def __init__(self, completekey=\"tab\", stdin=None, stdout=None, machine={}):\n        super(MMUShell, self).__init__(completekey, stdin, stdout, machine)\n\n        if not self.data:\n            self.data = Data(\n                is_tables_found=False,\n                is_radix_found=False,\n                is_registers_found=False,\n                opcodes={},\n                regs_values={},\n                page_tables={\n                    \"user\": [\n                        {} for i in range(self.machine.mmu.radix_levels[\"global\"])\n                    ],\n                    \"kernel\": [\n                        {} for i in range(self.machine.mmu.radix_levels[\"global\"])\n                    ],\n                },\n                data_pages=[],\n                empty_tables=[],\n                reverse_map_tables={\n                    \"user\": [\n                        defaultdict(set)\n                        for i in range(self.machine.mmu.radix_levels[\"global\"])\n                    ],\n                    \"kernel\": [\n                        defaultdict(set)\n                        for i in range(self.machine.mmu.radix_levels[\"global\"])\n                    ],\n                },\n                reverse_map_pages={\n                    \"user\": [\n                        defaultdict(set)\n                        for i in range(self.machine.mmu.radix_levels[\"global\"])\n                    ],\n                    \"kernel\": [\n                        defaultdict(set)\n                        for i in range(self.machine.mmu.radix_levels[\"global\"])\n                    ],\n                },\n                used_ttbcr=None,\n                ttbrs=defaultdict(dict),\n            )\n\n    def reload_data_from_file(self, data_filename):\n        super(MMUShell, self).reload_data_from_file(data_filename)\n        SHORT.ttbcr_n = self.data.used_ttbcr.n\n\n    def do_find_registers_values(self, arg):\n        \"\"\"Find MMU load opcodes and execute MMU related functions inside the memory dump in order to extract MMU registers values\"\"\"\n\n        if self.data.is_registers_found:\n            logging.warning(\"Registers already searched\")\n            return\n\n        logger.info(\"Look for opcodes related to MMU setup...\")\n        parallel_results = self.machine.apply_parallel(\n            self.machine.mmu.PAGE_SIZE, self.machine.cpu.parse_opcodes_parallel\n        )\n\n        opcodes = {}\n        logger.info(\"Reaggregate threads data...\")\n        for result in parallel_results:\n            opcodes.update(result.get())\n\n        self.data.opcodes = opcodes\n\n        # Filter to look only for opcodes which write on MMU register only and not read from them or from other registers\n        filter_f = (\n            lambda it: True\n            if it[1][\"register\"] == \"TTBCR\" and it[1][\"instruction\"] == \"MCR\"\n            else False\n        )\n        mmu_wr_opcodes = {k: v for k, v in filter(filter_f, opcodes.items())}\n\n        logging.info(\"Use heuristics to find function addresses...\")\n        logging.info(\"This analysis could be extremely slow!\")\n        self.machine.cpu.identify_functions_start(mmu_wr_opcodes)\n\n        logging.info(\"Identify register values using data flow analysis...\")\n\n        # We use data flow analysis and merge the results\n        dataflow_values = self.machine.cpu.find_registers_values_dataflow(\n            mmu_wr_opcodes\n        )\n\n        filtered_values = defaultdict(set)\n        for register, values in dataflow_values.items():\n            for value in values:\n                reg_obj = CPURegARM32.get_register_obj(register, value)\n                if reg_obj.valid and not any(\n                    [\n                        val_obj.is_mmu_equivalent_to(reg_obj)\n                        for val_obj in filtered_values[register]\n                    ]\n                ):\n                    filtered_values[register].add(reg_obj)\n\n        # Add default values\n        reg_obj = CPURegARM32.get_register_obj(\n            \"TTBCR\", self.machine.cpu.registers_values[\"TTBCR\"]\n        )\n        if reg_obj.valid and all(\n            [not reg_obj.is_mmu_equivalent_to(x) for x in filtered_values[\"TTBCR\"]]\n        ):\n            filtered_values[\"TTBCR\"].add(reg_obj)\n\n        self.data.regs_values = filtered_values\n        self.data.is_registers_found = True\n\n        # Show results\n        logging.info(\"TTBCR values recovered:\")\n        for reg_obj in self.data.regs_values[\"TTBCR\"]:\n            logging.info(reg_obj)\n\n    def do_show_registers(self, args):\n        \"\"\"Show registers values found\"\"\"\n        if not self.data.is_registers_found:\n            logging.info(\"Please, find them first!\")\n            return\n\n        for registers in sorted(self.data.regs_values.keys()):\n            for register in self.data.regs_values[registers]:\n                print(register)\n\n    def do_set_ttbcr(self, args):\n        \"\"\"Set the value of TTBCR register to be used\"\"\"\n        args = args.split()\n        if len(args) == 0:\n            logging.error(\"Please use find_tables TTBCR_VALUE\")\n            return\n\n        # The shape of PTL0 tables depends on N value of TTBCR register\n        try:\n            ttbcr_val = self.parse_int(args[0])\n            ttbcr = TTBCR(ttbcr_val)\n            if not ttbcr.valid:\n                raise ValueError\n        except ValueError:\n            logger.warning(\"Invalid TTBCR value\")\n            return\n\n        self.data.used_ttbcr = ttbcr\n        SHORT.ttbcr_n = ttbcr.n\n\n    def do_find_tables(self, args):\n        \"\"\"Find MMU tables in memory\"\"\"\n        if not self.data.used_ttbcr:\n            logging.error(\"Please set a TTBCR register to use, using set_ttbcr TTBCR\")\n            return\n        ttbcr = self.data.used_ttbcr\n\n        # Delete all the previous table data\n        if self.data.is_tables_found:\n            for mode in [\"user\", \"kernel\"]:\n                self.data.reverse_map_pages[mode].clear()\n                self.data.reverse_map_tables[mode].clear()\n                self.data.page_tables[mode].clear()\n            self.data.empty_tables = []\n            self.data.data_pages = []\n\n        # Parse memory in chunk of 16KiB\n        PTL0_USER_TABLE_SIZE = ttbcr.get_ptl0_user_table_size()\n        logger.info(\"Look for paging tables...\")\n        parallel_results = self.machine.apply_parallel(\n            16384,\n            self.machine.mmu.parse_parallel_frame,\n            ptl0_u_size=PTL0_USER_TABLE_SIZE,\n        )\n        logger.info(\"Reaggregate threads data...\")\n        for result in parallel_results:\n            page_tables, data_pages, empty_tables = result.get()\n\n            for level in range(self.machine.mmu.radix_levels[\"global\"]):\n                self.data.page_tables[\"user\"][level].update(page_tables[\"user\"][level])\n                self.data.page_tables[\"kernel\"][level].update(\n                    page_tables[\"kernel\"][level]\n                )\n\n            self.data.data_pages.extend(data_pages)\n            self.data.empty_tables.extend(empty_tables)\n\n        self.data.data_pages = set(self.data.data_pages)\n        self.data.empty_tables = set(self.data.empty_tables)\n\n        # Prepare fo dumplicates removing\n        modes = [\"kernel\"]\n        fps = {\"kernel\": []}\n        if PTL0_USER_TABLE_SIZE != 16384:\n            modes.append(\"user\")\n            fps[\"user\"] = []\n            self.data.page_tables[\"user\"][1] = deepcopy(\n                self.data.page_tables[\"kernel\"][1]\n            )\n\n        # Remove all tables which point to inexistent table of lower level\n        logger.info(\"Reduce false positives...\")\n        ptr_class = self.machine.mmu.map_ptr_entries_to_levels[\"global\"][0]\n\n        for mode in modes:\n            referenced_nxt = []\n            for table_addr in list(self.data.page_tables[mode][0].keys()):\n                for entry_obj in (\n                    self.data.page_tables[mode][0][table_addr]\n                    .entries[ptr_class]\n                    .values()\n                ):\n                    if (\n                        entry_obj.address not in self.data.page_tables[mode][1]\n                        and entry_obj.address not in self.data.empty_tables\n                    ):\n                        # Remove the table\n                        self.data.page_tables[mode][0].pop(table_addr)\n                        break\n\n                    else:\n                        referenced_nxt.append(entry_obj.address)\n\n            # Remove table not referenced by upper levels\n            referenced_nxt = set(referenced_nxt)\n            for table_addr in set(self.data.page_tables[mode][1].keys()).difference(\n                referenced_nxt\n            ):\n                self.data.page_tables[mode][1].pop(table_addr)\n\n        logger.info(\"Fill reverse maps...\")\n        for mode in modes:\n            for lvl in range(0, self.machine.mmu.radix_levels[\"global\"]):\n                ptr_class = self.machine.mmu.map_ptr_entries_to_levels[\"global\"][lvl]\n                page_classes = self.machine.mmu.map_datapages_entries_to_levels[\n                    \"global\"\n                ][lvl]\n                for table_addr, table_obj in self.data.page_tables[mode][lvl].items():\n                    for entry_obj in table_obj.entries[ptr_class].values():\n                        self.data.reverse_map_tables[mode][lvl][entry_obj.address].add(\n                            table_obj.address\n                        )\n                    for page_class in page_classes:\n                        for entry_obj in table_obj.entries[page_class].values():\n                            self.data.reverse_map_pages[mode][lvl][\n                                entry_obj.address\n                            ].add(table_obj.address)\n\n        self.data.is_tables_found = True\n\n    def do_show_table(self, args):\n        \"\"\"Show an MMU table at a chosen address. Usage show_table ADDRESS [level table size]\"\"\"\n        if not self.data.used_ttbcr:\n            logging.error(\"Please set a TTBCR register to use, using set_ttbcr TTBCR\")\n            return\n\n        args = args.split()\n        if len(args) &lt; 1:\n            logger.warning(\"Missing table address\")\n            return\n\n        try:\n            addr = self.parse_int(args[0])\n        except ValueError:\n            logger.warning(\"Invalid table address\")\n            return\n\n        if addr not in self.machine.memory:\n            logger.warning(\"Table not in RAM range\")\n            return\n\n        if len(args) == 3:\n            valid_sizes = {0: set([0x4000]), 1: set([0x400])}\n            valid_sizes[0].add(self.data.used_ttbcr.get_ptl0_user_table_size())\n\n            try:\n                lvl = self.parse_int(args[1])\n                if lvl &gt; self.machine.mmu.radix_levels[\"global\"] - 1:\n                    raise ValueError\n            except ValueError:\n                logger.warning(\n                    \"Level must be an integer between 0 and {}\".format(\n                        str(self.machine.mmu.radix_levels[\"global\"] - 1)\n                    )\n                )\n                return\n\n            try:\n                table_size = self.parse_int(args[2])\n                if table_size not in valid_sizes[lvl]:\n                    logging.warning(\n                        f\"Size not allowed for choosen level! Valid sizes are:{valid_sizes[lvl]}\"\n                    )\n                    return\n            except ValueError:\n                logger.warning(\"Invalid size value\")\n                return\n        else:\n            table_size = 0x4000\n            lvl = -1\n\n        table_buff = self.machine.memory.get_data(addr, table_size)\n        invalids, pt_classes, table_obj = self.machine.mmu.parse_frame(\n            table_buff, addr, table_size, lvl\n        )\n        print(table_obj)\n        print(f\"Invalid entries: {invalids} Table levels: {pt_classes}\")\n\n    def virtspace_short(\n        self, addr, page_tables, lvl=0, prefix=0, ukx=True, cache=defaultdict(dict)\n    ):\n        \"\"\"Recursively reconstruct virtual address space for SHORT mode\"\"\"\n\n        virtspace = VASShort()\n        data_classes = self.machine.mmu.map_datapages_entries_to_levels[\"global\"][lvl]\n        ptr_class = self.machine.mmu.map_ptr_entries_to_levels[\"global\"][lvl]\n        cache[lvl][addr] = defaultdict(portion.empty)\n\n        if lvl == self.machine.mmu.radix_levels[\"global\"] - 1:\n            for data_class in data_classes:\n                shift = self.machine.mmu.map_entries_to_shifts[\"global\"][data_class]\n                for entry_idx, entry in (\n                    page_tables[lvl][addr].entries[data_class].items()\n                ):\n                    permissions = entry.extract_permissions()\n                    kx = entry.is_kernel_executable_entry() and ukx\n                    x = entry.is_executable_entry()\n\n                    virt_addr = prefix | (entry_idx &lt;&lt; shift)\n                    virtspace[(permissions, x, kx)] |= portion.closedopen(\n                        virt_addr, virt_addr + entry.size\n                    )\n                    cache[lvl][addr][(permissions, x, kx)] |= portion.closedopen(\n                        virt_addr, virt_addr + entry.size\n                    )\n\n            return virtspace\n\n        else:\n            if ptr_class in page_tables[lvl][addr].entries:\n                shift = self.machine.mmu.map_entries_to_shifts[\"global\"][ptr_class]\n                for entry_idx, entry in (\n                    page_tables[lvl][addr].entries[ptr_class].items()\n                ):\n                    if entry.address not in page_tables[lvl + 1]:\n                        continue\n                    else:\n                        if entry.address not in cache[lvl + 1]:\n                            permissions = entry.extract_permissions()\n                            kx = entry.is_kernel_executable_entry() and ukx\n                            x = entry.is_executable_entry()\n\n                            virt_addr = prefix | (entry_idx &lt;&lt; shift)\n                            low_virts = self.virtspace_short(\n                                entry.address,\n                                page_tables,\n                                lvl + 1,\n                                virt_addr,\n                                kx,\n                                cache=cache,\n                            )\n                        else:\n                            low_virts = cache[lvl + 1][entry.address]\n\n                        for perm, virts_fragment in low_virts.items():\n                            virtspace[perm] |= virts_fragment\n                            cache[lvl][addr][perm] |= virts_fragment\n\n            for data_class in data_classes:\n                if (\n                    data_class in page_tables[lvl][addr].entries\n                    and data_class is not None\n                ):\n                    shift = self.machine.mmu.map_entries_to_shifts[\"global\"][data_class]\n                    for entry_idx, entry in (\n                        page_tables[lvl][addr].entries[data_class].items()\n                    ):\n                        permissions = entry.extract_permissions()\n                        kx = entry.is_kernel_executable_entry() and ukx\n                        x = entry.is_executable_entry()\n\n                        virt_addr = prefix | (entry_idx &lt;&lt; shift)\n                        virtspace[(permissions, x, kx)] |= portion.closedopen(\n                            virt_addr, virt_addr + entry.size\n                        )\n                        cache[lvl][addr][(permissions, x, kx)] |= portion.closedopen(\n                            virt_addr, virt_addr + entry.size\n                        )\n\n            return virtspace\n\n    def do_find_radix_trees(self, args):\n        \"\"\"Reconstruct radix trees\"\"\"\n        if not self.data.is_tables_found:\n            logging.info(\"Please, parse the memory first!\")\n            return\n\n        if not self.data.is_registers_found:\n            logging.info(\"Please find MMU related opcodes first!\")\n            return\n\n        if self.data.ttbrs:\n            self.data.ttbrs.clear()\n\n        # Some table level was not found...\n        if not len(self.data.page_tables[\"kernel\"][0]):\n            logger.warning(\"OOPS... no tables in first level... Wrong MMU mode?\")\n            return\n\n        # Go back from PTL1 up to PTL0, the particular form of PTLn permits to find PTL0\n        logging.info(\"Go up the paging trees starting from data pages...\")\n        candidates = {\"kernel\": []}\n        modes = [\"kernel\"]\n        if SHORT.ttbcr_n != 0:\n            modes.append(\"user\")\n            candidates[\"user\"] = []\n\n        # TTBR0 can be used by a process which manages HW so it can point only to not in RAM pages!\n        # This is a special case which it can occur only in ARM\n        not_ram_pages = []\n        for p in self.machine.memory.physpace[\"not_ram\"]:\n            not_ram_pages.extend([x for x in range(p.lower, p.upper, 4096)])\n        not_ram_pages = set(not_ram_pages)\n\n        for mode in modes:\n            already_explored = set()\n            for page_addr in tqdm(\n                self.data.data_pages.union(self.data.empty_tables).union(not_ram_pages)\n            ):\n                derived_addresses = self.machine.mmu.derive_page_address(page_addr)\n                for derived_address in derived_addresses:\n                    if derived_address in already_explored:\n                        continue\n\n                    lvl, addr = derived_address\n                    candidates[mode].extend(\n                        self.radix_roots_from_data_page(\n                            lvl,\n                            addr,\n                            self.data.reverse_map_pages[mode],\n                            self.data.reverse_map_tables[mode],\n                        )\n                    )\n                    already_explored.add(derived_address)\n\n            candidates[mode] = list(\n                set(candidates[mode]).intersection(\n                    self.data.page_tables[mode][0].keys()\n                )\n            )\n            candidates[mode].sort()\n\n        # Collect interrupt/paging opcodes\n        filter_f_read = (\n            lambda it: True\n            if it[1][\"register\"] in [\"DFSR\", \"IFSR\"] and it[1][\"instruction\"] == \"MRC\"\n            else False\n        )\n        kernel_opcodes_read = [\n            x[0] for x in filter(filter_f_read, self.data.opcodes.items())\n        ]\n        filter_f_write = (\n            lambda it: True\n            if it[1][\"register\"] in [\"TTBR0\", \"TTBCR\"] and it[1][\"instruction\"] == \"MCR\"\n            else False\n        )\n        kernel_opcodes_write = [\n            x[0] for x in filter(filter_f_write, self.data.opcodes.items())\n        ]\n\n        logging.info(\"Filtering candidates...\")\n        filtered = {\"kernel\": {}, \"user\": {}}\n        for mode in modes:\n            physpace_cache = defaultdict(\n                dict\n            )  # We need to use different caches for user and kernel modes\n            virtspace_cache = defaultdict(dict)\n            for candidate in tqdm(candidates[mode]):\n                consistency, pas = self.physpace(\n                    candidate,\n                    self.data.page_tables[mode],\n                    self.data.empty_tables,\n                    cache=physpace_cache,\n                )\n\n                # Ignore inconsistent radix-tress or which maps zero spaces\n                if not consistency or (\n                    pas.get_kernel_size() == 0 and pas.get_user_size() == 0\n                ):\n                    continue\n\n                # Look for kernel trees able to map at least one interrupt/paging related opcodes\n                if mode == \"kernel\":\n                    # We check also in user pages (when ttbr1 is not used!) because user pages are always accessible also by the kernel!\n                    if not any(\n                        [opcode_addr in pas for opcode_addr in kernel_opcodes_read]\n                    ) or (\n                        SHORT.ttbcr_n != 0\n                        and not any(\n                            [opcode_addr in pas for opcode_addr in kernel_opcodes_write]\n                        )\n                    ):\n                        continue\n\n                    vas = self.virtspace_short(\n                        candidate, self.data.page_tables[mode], cache=virtspace_cache\n                    )\n\n                    # At least a kernel executable page must be exist\n                    for _, _, kx in vas:\n                        if kx:\n                            break\n                    else:\n                        continue\n\n                    radix_tree = RadixTree(\n                        candidate, 0, pas, vas, kernel=True, user=False\n                    )\n                    filtered[mode][candidate] = radix_tree\n\n                else:\n                    # No kernel pages are allowed on user radix trees!\n                    if pas.get_kernel_size() != 0:\n                        continue\n\n                    # At least an executable page must exists\n                    vas = self.virtspace_short(\n                        candidate, self.data.page_tables[mode], cache=virtspace_cache\n                    )\n                    for _, x, _ in vas:\n                        if x:\n                            break\n                    else:\n                        continue\n\n                    # Filter for at least a writable page for user (AP[1] == 1)\n                    for p, _, _ in vas:\n                        if p &amp; 0b10 == 2:\n                            break\n                    else:\n                        continue\n\n                    radix_tree = RadixTree(\n                        candidate, 0, pas, vas, kernel=False, user=True\n                    )\n                    filtered[mode][candidate] = radix_tree\n\n        self.data.ttbrs = filtered\n        self.data.is_radix_found = True\n\n    def do_show_radix_trees(self, args):\n        \"\"\"Show radix trees found\"\"\"\n        if not self.data.is_radix_found:\n            logging.info(\"Please, find them first!\")\n            return\n\n        labels = [\n            \"Radix address\",\n            \"First level\",\n            \"Kernel size (Bytes)\",\n            \"User size (Bytes)\",\n            \"Kernel\",\n        ]\n        table = PrettyTable()\n        table.field_names = labels\n        for mode in [\"kernel\", \"user\"]:\n            for ttbr in self.data.ttbrs[mode].values():\n                table.add_row(\n                    ttbr.entry_resume_stringified() + [\"X\" if mode == \"kernel\" else \"\"]\n                )\n        table.sortby = \"Radix address\"\n        print(table)\n</code></pre>"},{"location":"reference/architectures/arm/#mmushell.architectures.arm.MMUShell.do_find_radix_trees","title":"<code>do_find_radix_trees(args)</code>","text":"<p>Reconstruct radix trees</p> Source code in <code>mmushell/architectures/arm.py</code> <pre><code>def do_find_radix_trees(self, args):\n    \"\"\"Reconstruct radix trees\"\"\"\n    if not self.data.is_tables_found:\n        logging.info(\"Please, parse the memory first!\")\n        return\n\n    if not self.data.is_registers_found:\n        logging.info(\"Please find MMU related opcodes first!\")\n        return\n\n    if self.data.ttbrs:\n        self.data.ttbrs.clear()\n\n    # Some table level was not found...\n    if not len(self.data.page_tables[\"kernel\"][0]):\n        logger.warning(\"OOPS... no tables in first level... Wrong MMU mode?\")\n        return\n\n    # Go back from PTL1 up to PTL0, the particular form of PTLn permits to find PTL0\n    logging.info(\"Go up the paging trees starting from data pages...\")\n    candidates = {\"kernel\": []}\n    modes = [\"kernel\"]\n    if SHORT.ttbcr_n != 0:\n        modes.append(\"user\")\n        candidates[\"user\"] = []\n\n    # TTBR0 can be used by a process which manages HW so it can point only to not in RAM pages!\n    # This is a special case which it can occur only in ARM\n    not_ram_pages = []\n    for p in self.machine.memory.physpace[\"not_ram\"]:\n        not_ram_pages.extend([x for x in range(p.lower, p.upper, 4096)])\n    not_ram_pages = set(not_ram_pages)\n\n    for mode in modes:\n        already_explored = set()\n        for page_addr in tqdm(\n            self.data.data_pages.union(self.data.empty_tables).union(not_ram_pages)\n        ):\n            derived_addresses = self.machine.mmu.derive_page_address(page_addr)\n            for derived_address in derived_addresses:\n                if derived_address in already_explored:\n                    continue\n\n                lvl, addr = derived_address\n                candidates[mode].extend(\n                    self.radix_roots_from_data_page(\n                        lvl,\n                        addr,\n                        self.data.reverse_map_pages[mode],\n                        self.data.reverse_map_tables[mode],\n                    )\n                )\n                already_explored.add(derived_address)\n\n        candidates[mode] = list(\n            set(candidates[mode]).intersection(\n                self.data.page_tables[mode][0].keys()\n            )\n        )\n        candidates[mode].sort()\n\n    # Collect interrupt/paging opcodes\n    filter_f_read = (\n        lambda it: True\n        if it[1][\"register\"] in [\"DFSR\", \"IFSR\"] and it[1][\"instruction\"] == \"MRC\"\n        else False\n    )\n    kernel_opcodes_read = [\n        x[0] for x in filter(filter_f_read, self.data.opcodes.items())\n    ]\n    filter_f_write = (\n        lambda it: True\n        if it[1][\"register\"] in [\"TTBR0\", \"TTBCR\"] and it[1][\"instruction\"] == \"MCR\"\n        else False\n    )\n    kernel_opcodes_write = [\n        x[0] for x in filter(filter_f_write, self.data.opcodes.items())\n    ]\n\n    logging.info(\"Filtering candidates...\")\n    filtered = {\"kernel\": {}, \"user\": {}}\n    for mode in modes:\n        physpace_cache = defaultdict(\n            dict\n        )  # We need to use different caches for user and kernel modes\n        virtspace_cache = defaultdict(dict)\n        for candidate in tqdm(candidates[mode]):\n            consistency, pas = self.physpace(\n                candidate,\n                self.data.page_tables[mode],\n                self.data.empty_tables,\n                cache=physpace_cache,\n            )\n\n            # Ignore inconsistent radix-tress or which maps zero spaces\n            if not consistency or (\n                pas.get_kernel_size() == 0 and pas.get_user_size() == 0\n            ):\n                continue\n\n            # Look for kernel trees able to map at least one interrupt/paging related opcodes\n            if mode == \"kernel\":\n                # We check also in user pages (when ttbr1 is not used!) because user pages are always accessible also by the kernel!\n                if not any(\n                    [opcode_addr in pas for opcode_addr in kernel_opcodes_read]\n                ) or (\n                    SHORT.ttbcr_n != 0\n                    and not any(\n                        [opcode_addr in pas for opcode_addr in kernel_opcodes_write]\n                    )\n                ):\n                    continue\n\n                vas = self.virtspace_short(\n                    candidate, self.data.page_tables[mode], cache=virtspace_cache\n                )\n\n                # At least a kernel executable page must be exist\n                for _, _, kx in vas:\n                    if kx:\n                        break\n                else:\n                    continue\n\n                radix_tree = RadixTree(\n                    candidate, 0, pas, vas, kernel=True, user=False\n                )\n                filtered[mode][candidate] = radix_tree\n\n            else:\n                # No kernel pages are allowed on user radix trees!\n                if pas.get_kernel_size() != 0:\n                    continue\n\n                # At least an executable page must exists\n                vas = self.virtspace_short(\n                    candidate, self.data.page_tables[mode], cache=virtspace_cache\n                )\n                for _, x, _ in vas:\n                    if x:\n                        break\n                else:\n                    continue\n\n                # Filter for at least a writable page for user (AP[1] == 1)\n                for p, _, _ in vas:\n                    if p &amp; 0b10 == 2:\n                        break\n                else:\n                    continue\n\n                radix_tree = RadixTree(\n                    candidate, 0, pas, vas, kernel=False, user=True\n                )\n                filtered[mode][candidate] = radix_tree\n\n    self.data.ttbrs = filtered\n    self.data.is_radix_found = True\n</code></pre>"},{"location":"reference/architectures/arm/#mmushell.architectures.arm.MMUShell.do_find_registers_values","title":"<code>do_find_registers_values(arg)</code>","text":"<p>Find MMU load opcodes and execute MMU related functions inside the memory dump in order to extract MMU registers values</p> Source code in <code>mmushell/architectures/arm.py</code> <pre><code>def do_find_registers_values(self, arg):\n    \"\"\"Find MMU load opcodes and execute MMU related functions inside the memory dump in order to extract MMU registers values\"\"\"\n\n    if self.data.is_registers_found:\n        logging.warning(\"Registers already searched\")\n        return\n\n    logger.info(\"Look for opcodes related to MMU setup...\")\n    parallel_results = self.machine.apply_parallel(\n        self.machine.mmu.PAGE_SIZE, self.machine.cpu.parse_opcodes_parallel\n    )\n\n    opcodes = {}\n    logger.info(\"Reaggregate threads data...\")\n    for result in parallel_results:\n        opcodes.update(result.get())\n\n    self.data.opcodes = opcodes\n\n    # Filter to look only for opcodes which write on MMU register only and not read from them or from other registers\n    filter_f = (\n        lambda it: True\n        if it[1][\"register\"] == \"TTBCR\" and it[1][\"instruction\"] == \"MCR\"\n        else False\n    )\n    mmu_wr_opcodes = {k: v for k, v in filter(filter_f, opcodes.items())}\n\n    logging.info(\"Use heuristics to find function addresses...\")\n    logging.info(\"This analysis could be extremely slow!\")\n    self.machine.cpu.identify_functions_start(mmu_wr_opcodes)\n\n    logging.info(\"Identify register values using data flow analysis...\")\n\n    # We use data flow analysis and merge the results\n    dataflow_values = self.machine.cpu.find_registers_values_dataflow(\n        mmu_wr_opcodes\n    )\n\n    filtered_values = defaultdict(set)\n    for register, values in dataflow_values.items():\n        for value in values:\n            reg_obj = CPURegARM32.get_register_obj(register, value)\n            if reg_obj.valid and not any(\n                [\n                    val_obj.is_mmu_equivalent_to(reg_obj)\n                    for val_obj in filtered_values[register]\n                ]\n            ):\n                filtered_values[register].add(reg_obj)\n\n    # Add default values\n    reg_obj = CPURegARM32.get_register_obj(\n        \"TTBCR\", self.machine.cpu.registers_values[\"TTBCR\"]\n    )\n    if reg_obj.valid and all(\n        [not reg_obj.is_mmu_equivalent_to(x) for x in filtered_values[\"TTBCR\"]]\n    ):\n        filtered_values[\"TTBCR\"].add(reg_obj)\n\n    self.data.regs_values = filtered_values\n    self.data.is_registers_found = True\n\n    # Show results\n    logging.info(\"TTBCR values recovered:\")\n    for reg_obj in self.data.regs_values[\"TTBCR\"]:\n        logging.info(reg_obj)\n</code></pre>"},{"location":"reference/architectures/arm/#mmushell.architectures.arm.MMUShell.do_find_tables","title":"<code>do_find_tables(args)</code>","text":"<p>Find MMU tables in memory</p> Source code in <code>mmushell/architectures/arm.py</code> <pre><code>def do_find_tables(self, args):\n    \"\"\"Find MMU tables in memory\"\"\"\n    if not self.data.used_ttbcr:\n        logging.error(\"Please set a TTBCR register to use, using set_ttbcr TTBCR\")\n        return\n    ttbcr = self.data.used_ttbcr\n\n    # Delete all the previous table data\n    if self.data.is_tables_found:\n        for mode in [\"user\", \"kernel\"]:\n            self.data.reverse_map_pages[mode].clear()\n            self.data.reverse_map_tables[mode].clear()\n            self.data.page_tables[mode].clear()\n        self.data.empty_tables = []\n        self.data.data_pages = []\n\n    # Parse memory in chunk of 16KiB\n    PTL0_USER_TABLE_SIZE = ttbcr.get_ptl0_user_table_size()\n    logger.info(\"Look for paging tables...\")\n    parallel_results = self.machine.apply_parallel(\n        16384,\n        self.machine.mmu.parse_parallel_frame,\n        ptl0_u_size=PTL0_USER_TABLE_SIZE,\n    )\n    logger.info(\"Reaggregate threads data...\")\n    for result in parallel_results:\n        page_tables, data_pages, empty_tables = result.get()\n\n        for level in range(self.machine.mmu.radix_levels[\"global\"]):\n            self.data.page_tables[\"user\"][level].update(page_tables[\"user\"][level])\n            self.data.page_tables[\"kernel\"][level].update(\n                page_tables[\"kernel\"][level]\n            )\n\n        self.data.data_pages.extend(data_pages)\n        self.data.empty_tables.extend(empty_tables)\n\n    self.data.data_pages = set(self.data.data_pages)\n    self.data.empty_tables = set(self.data.empty_tables)\n\n    # Prepare fo dumplicates removing\n    modes = [\"kernel\"]\n    fps = {\"kernel\": []}\n    if PTL0_USER_TABLE_SIZE != 16384:\n        modes.append(\"user\")\n        fps[\"user\"] = []\n        self.data.page_tables[\"user\"][1] = deepcopy(\n            self.data.page_tables[\"kernel\"][1]\n        )\n\n    # Remove all tables which point to inexistent table of lower level\n    logger.info(\"Reduce false positives...\")\n    ptr_class = self.machine.mmu.map_ptr_entries_to_levels[\"global\"][0]\n\n    for mode in modes:\n        referenced_nxt = []\n        for table_addr in list(self.data.page_tables[mode][0].keys()):\n            for entry_obj in (\n                self.data.page_tables[mode][0][table_addr]\n                .entries[ptr_class]\n                .values()\n            ):\n                if (\n                    entry_obj.address not in self.data.page_tables[mode][1]\n                    and entry_obj.address not in self.data.empty_tables\n                ):\n                    # Remove the table\n                    self.data.page_tables[mode][0].pop(table_addr)\n                    break\n\n                else:\n                    referenced_nxt.append(entry_obj.address)\n\n        # Remove table not referenced by upper levels\n        referenced_nxt = set(referenced_nxt)\n        for table_addr in set(self.data.page_tables[mode][1].keys()).difference(\n            referenced_nxt\n        ):\n            self.data.page_tables[mode][1].pop(table_addr)\n\n    logger.info(\"Fill reverse maps...\")\n    for mode in modes:\n        for lvl in range(0, self.machine.mmu.radix_levels[\"global\"]):\n            ptr_class = self.machine.mmu.map_ptr_entries_to_levels[\"global\"][lvl]\n            page_classes = self.machine.mmu.map_datapages_entries_to_levels[\n                \"global\"\n            ][lvl]\n            for table_addr, table_obj in self.data.page_tables[mode][lvl].items():\n                for entry_obj in table_obj.entries[ptr_class].values():\n                    self.data.reverse_map_tables[mode][lvl][entry_obj.address].add(\n                        table_obj.address\n                    )\n                for page_class in page_classes:\n                    for entry_obj in table_obj.entries[page_class].values():\n                        self.data.reverse_map_pages[mode][lvl][\n                            entry_obj.address\n                        ].add(table_obj.address)\n\n    self.data.is_tables_found = True\n</code></pre>"},{"location":"reference/architectures/arm/#mmushell.architectures.arm.MMUShell.do_set_ttbcr","title":"<code>do_set_ttbcr(args)</code>","text":"<p>Set the value of TTBCR register to be used</p> Source code in <code>mmushell/architectures/arm.py</code> <pre><code>def do_set_ttbcr(self, args):\n    \"\"\"Set the value of TTBCR register to be used\"\"\"\n    args = args.split()\n    if len(args) == 0:\n        logging.error(\"Please use find_tables TTBCR_VALUE\")\n        return\n\n    # The shape of PTL0 tables depends on N value of TTBCR register\n    try:\n        ttbcr_val = self.parse_int(args[0])\n        ttbcr = TTBCR(ttbcr_val)\n        if not ttbcr.valid:\n            raise ValueError\n    except ValueError:\n        logger.warning(\"Invalid TTBCR value\")\n        return\n\n    self.data.used_ttbcr = ttbcr\n    SHORT.ttbcr_n = ttbcr.n\n</code></pre>"},{"location":"reference/architectures/arm/#mmushell.architectures.arm.MMUShell.do_show_radix_trees","title":"<code>do_show_radix_trees(args)</code>","text":"<p>Show radix trees found</p> Source code in <code>mmushell/architectures/arm.py</code> <pre><code>def do_show_radix_trees(self, args):\n    \"\"\"Show radix trees found\"\"\"\n    if not self.data.is_radix_found:\n        logging.info(\"Please, find them first!\")\n        return\n\n    labels = [\n        \"Radix address\",\n        \"First level\",\n        \"Kernel size (Bytes)\",\n        \"User size (Bytes)\",\n        \"Kernel\",\n    ]\n    table = PrettyTable()\n    table.field_names = labels\n    for mode in [\"kernel\", \"user\"]:\n        for ttbr in self.data.ttbrs[mode].values():\n            table.add_row(\n                ttbr.entry_resume_stringified() + [\"X\" if mode == \"kernel\" else \"\"]\n            )\n    table.sortby = \"Radix address\"\n    print(table)\n</code></pre>"},{"location":"reference/architectures/arm/#mmushell.architectures.arm.MMUShell.do_show_registers","title":"<code>do_show_registers(args)</code>","text":"<p>Show registers values found</p> Source code in <code>mmushell/architectures/arm.py</code> <pre><code>def do_show_registers(self, args):\n    \"\"\"Show registers values found\"\"\"\n    if not self.data.is_registers_found:\n        logging.info(\"Please, find them first!\")\n        return\n\n    for registers in sorted(self.data.regs_values.keys()):\n        for register in self.data.regs_values[registers]:\n            print(register)\n</code></pre>"},{"location":"reference/architectures/arm/#mmushell.architectures.arm.MMUShell.do_show_table","title":"<code>do_show_table(args)</code>","text":"<p>Show an MMU table at a chosen address. Usage show_table ADDRESS [level table size]</p> Source code in <code>mmushell/architectures/arm.py</code> <pre><code>def do_show_table(self, args):\n    \"\"\"Show an MMU table at a chosen address. Usage show_table ADDRESS [level table size]\"\"\"\n    if not self.data.used_ttbcr:\n        logging.error(\"Please set a TTBCR register to use, using set_ttbcr TTBCR\")\n        return\n\n    args = args.split()\n    if len(args) &lt; 1:\n        logger.warning(\"Missing table address\")\n        return\n\n    try:\n        addr = self.parse_int(args[0])\n    except ValueError:\n        logger.warning(\"Invalid table address\")\n        return\n\n    if addr not in self.machine.memory:\n        logger.warning(\"Table not in RAM range\")\n        return\n\n    if len(args) == 3:\n        valid_sizes = {0: set([0x4000]), 1: set([0x400])}\n        valid_sizes[0].add(self.data.used_ttbcr.get_ptl0_user_table_size())\n\n        try:\n            lvl = self.parse_int(args[1])\n            if lvl &gt; self.machine.mmu.radix_levels[\"global\"] - 1:\n                raise ValueError\n        except ValueError:\n            logger.warning(\n                \"Level must be an integer between 0 and {}\".format(\n                    str(self.machine.mmu.radix_levels[\"global\"] - 1)\n                )\n            )\n            return\n\n        try:\n            table_size = self.parse_int(args[2])\n            if table_size not in valid_sizes[lvl]:\n                logging.warning(\n                    f\"Size not allowed for choosen level! Valid sizes are:{valid_sizes[lvl]}\"\n                )\n                return\n        except ValueError:\n            logger.warning(\"Invalid size value\")\n            return\n    else:\n        table_size = 0x4000\n        lvl = -1\n\n    table_buff = self.machine.memory.get_data(addr, table_size)\n    invalids, pt_classes, table_obj = self.machine.mmu.parse_frame(\n        table_buff, addr, table_size, lvl\n    )\n    print(table_obj)\n    print(f\"Invalid entries: {invalids} Table levels: {pt_classes}\")\n</code></pre>"},{"location":"reference/architectures/arm/#mmushell.architectures.arm.MMUShell.virtspace_short","title":"<code>virtspace_short(addr, page_tables, lvl=0, prefix=0, ukx=True, cache=defaultdict(dict))</code>","text":"<p>Recursively reconstruct virtual address space for SHORT mode</p> Source code in <code>mmushell/architectures/arm.py</code> <pre><code>def virtspace_short(\n    self, addr, page_tables, lvl=0, prefix=0, ukx=True, cache=defaultdict(dict)\n):\n    \"\"\"Recursively reconstruct virtual address space for SHORT mode\"\"\"\n\n    virtspace = VASShort()\n    data_classes = self.machine.mmu.map_datapages_entries_to_levels[\"global\"][lvl]\n    ptr_class = self.machine.mmu.map_ptr_entries_to_levels[\"global\"][lvl]\n    cache[lvl][addr] = defaultdict(portion.empty)\n\n    if lvl == self.machine.mmu.radix_levels[\"global\"] - 1:\n        for data_class in data_classes:\n            shift = self.machine.mmu.map_entries_to_shifts[\"global\"][data_class]\n            for entry_idx, entry in (\n                page_tables[lvl][addr].entries[data_class].items()\n            ):\n                permissions = entry.extract_permissions()\n                kx = entry.is_kernel_executable_entry() and ukx\n                x = entry.is_executable_entry()\n\n                virt_addr = prefix | (entry_idx &lt;&lt; shift)\n                virtspace[(permissions, x, kx)] |= portion.closedopen(\n                    virt_addr, virt_addr + entry.size\n                )\n                cache[lvl][addr][(permissions, x, kx)] |= portion.closedopen(\n                    virt_addr, virt_addr + entry.size\n                )\n\n        return virtspace\n\n    else:\n        if ptr_class in page_tables[lvl][addr].entries:\n            shift = self.machine.mmu.map_entries_to_shifts[\"global\"][ptr_class]\n            for entry_idx, entry in (\n                page_tables[lvl][addr].entries[ptr_class].items()\n            ):\n                if entry.address not in page_tables[lvl + 1]:\n                    continue\n                else:\n                    if entry.address not in cache[lvl + 1]:\n                        permissions = entry.extract_permissions()\n                        kx = entry.is_kernel_executable_entry() and ukx\n                        x = entry.is_executable_entry()\n\n                        virt_addr = prefix | (entry_idx &lt;&lt; shift)\n                        low_virts = self.virtspace_short(\n                            entry.address,\n                            page_tables,\n                            lvl + 1,\n                            virt_addr,\n                            kx,\n                            cache=cache,\n                        )\n                    else:\n                        low_virts = cache[lvl + 1][entry.address]\n\n                    for perm, virts_fragment in low_virts.items():\n                        virtspace[perm] |= virts_fragment\n                        cache[lvl][addr][perm] |= virts_fragment\n\n        for data_class in data_classes:\n            if (\n                data_class in page_tables[lvl][addr].entries\n                and data_class is not None\n            ):\n                shift = self.machine.mmu.map_entries_to_shifts[\"global\"][data_class]\n                for entry_idx, entry in (\n                    page_tables[lvl][addr].entries[data_class].items()\n                ):\n                    permissions = entry.extract_permissions()\n                    kx = entry.is_kernel_executable_entry() and ukx\n                    x = entry.is_executable_entry()\n\n                    virt_addr = prefix | (entry_idx &lt;&lt; shift)\n                    virtspace[(permissions, x, kx)] |= portion.closedopen(\n                        virt_addr, virt_addr + entry.size\n                    )\n                    cache[lvl][addr][(permissions, x, kx)] |= portion.closedopen(\n                        virt_addr, virt_addr + entry.size\n                    )\n\n        return virtspace\n</code></pre>"},{"location":"reference/architectures/arm/#mmushell.architectures.arm.MMUShellGTruth","title":"<code>MMUShellGTruth</code>","text":"<p>             Bases: <code>MMUShell</code></p> Source code in <code>mmushell/architectures/arm.py</code> <pre><code>class MMUShellGTruth(MMUShell):\n    def do_show_registers_gtruth(self, args):\n        \"\"\"Compare TTBCR register values found with the ground truth\"\"\"\n        if not self.data.is_registers_found:\n            logging.info(\"Please, find them first!\")\n            return\n\n        # Check if the last value of TTBCR was found\n        all_ttbcrs = (\n            {}\n        )  # QEMU export TTBCR inside various registers as TTBCR, TTBCR, TCR_S etc. due to it's capability to emulate different ARM/ARM64 systems\n        for reg_name, value_data in self.gtruth.items():\n            if \"TCR\" in reg_name or \"TTBCR\" in reg_name:\n                for value, value_info in value_data.items():\n                    if value not in all_ttbcrs or (\n                        value_info[1] &gt; all_ttbcrs[value][1]\n                    ):\n                        all_ttbcrs[value] = (value_info[0], value_info[1])\n\n        last_ttbcr = TTBCR(\n            sorted(all_ttbcrs.keys(), key=lambda x: all_ttbcrs[x][1], reverse=True)[0]\n        )\n\n        ttbcr_fields_equals = {}\n        for value_found_obj in self.data.regs_values[\"TTBCR\"]:\n            ttbcr_fields_equals[value_found_obj] = value_found_obj.count_fields_equals(\n                last_ttbcr\n            )\n        k_sorted = sorted(\n            ttbcr_fields_equals.keys(),\n            key=lambda x: ttbcr_fields_equals[x],\n            reverse=True,\n        )\n        tcr_found = k_sorted[0]\n        correct_fields_found = ttbcr_fields_equals[tcr_found]\n\n        if correct_fields_found:\n            print(f\"Correct TTBCR value: {last_ttbcr}, Found: {tcr_found}\")\n            print(\"TTBCR fields found:... {}/2\".format(correct_fields_found))\n            print(\"FP: {}\".format(str(len(self.data.regs_values[\"TTBCR\"]) - 1)))\n        else:\n            print(f\"Correct TTBCR value: {last_ttbcr}\")\n            print(\"TTBCR fields found:... 0/2\")\n            print(\"FP: {}\".format(str(len(self.data.regs_values[\"TTBCR\"]))))\n\n    def do_show_radix_trees_gtruth(self, args):\n        \"\"\"Compare found radix trees with the ground truth\"\"\"\n        if not self.data.is_radix_found:\n            logging.info(\"Please, find them first!\")\n            return\n\n        # Collect TTBR0 and TTBR1 values from the gtruth\n        ttbr0s = {}\n        ttbr1s = {}\n        ttbr0_phy_cache = defaultdict(dict)\n        ttbr1_phy_cache = defaultdict(dict)\n        virt_cache = defaultdict(dict)\n        filter_f_read = (\n            lambda it: True\n            if it[1][\"register\"] in [\"DFSR\", \"IFSR\"] and it[1][\"instruction\"] == \"MRC\"\n            else False\n        )\n        kernel_opcodes_read = [\n            x[0] for x in filter(filter_f_read, self.data.opcodes.items())\n        ]\n        filter_f_write = (\n            lambda it: True\n            if it[1][\"register\"] in [\"TTBR0\", \"TTBCR\"] and it[1][\"instruction\"] == \"MCR\"\n            else False\n        )\n        kernel_opcodes_write = [\n            x[0] for x in filter(filter_f_write, self.data.opcodes.items())\n        ]\n\n        # User or kernel+user radix trees\n        for key in [\"TTBR0\", \"TTBR0_S\", \"TTBR0_EL1\", \"TTBR0_EL1_S\"]:\n            for value, data in self.gtruth.get(key, {}).items():\n                ttbr = TTBR0(value)\n                if any([ttbr.is_mmu_equivalent_to(x[0]) for x in ttbr0s.values()]):\n                    continue\n\n                if SHORT.ttbcr_n != 0:\n                    if ttbr.address not in self.data.page_tables[\"user\"][0]:\n                        continue\n\n                    consistency, pas = self.physpace(\n                        ttbr.address,\n                        self.data.page_tables[\"user\"],\n                        self.data.empty_tables,\n                        cache=ttbr0_phy_cache,\n                    )\n                    if not consistency:\n                        continue\n\n                    if pas.get_kernel_size() != 0:\n                        continue\n\n                    virtspace = self.virtspace_short(\n                        ttbr.address, self.data.page_tables[\"user\"], cache=virt_cache\n                    )\n                    for _, x, _ in virtspace:\n                        if x:\n                            break\n                    else:\n                        continue\n\n                    # Filter for at least a writable page\n                    for p, _, _ in virtspace:\n                        if p &amp; 0b10 == 2:\n                            break\n                    else:\n                        continue\n\n                    ttbr0s[ttbr.address] = (ttbr, data)\n\n                else:\n                    if ttbr.address not in self.data.page_tables[\"kernel\"][0]:\n                        continue\n\n                    consistency, pas = self.physpace(\n                        ttbr.address,\n                        self.data.page_tables[\"kernel\"],\n                        self.data.empty_tables,\n                        cache=ttbr0_phy_cache,\n                    )\n                    if not consistency or (\n                        pas.get_kernel_size() == 0 and pas.get_user_size() == 0\n                    ):\n                        continue\n\n                    if not any(\n                        [opcode_addr in pas for opcode_addr in kernel_opcodes_read]\n                    ) or not any(\n                        [opcode_addr in pas for opcode_addr in kernel_opcodes_write]\n                    ):\n                        continue\n\n                    # At least a kernel executable page must be exist\n                    virtspace = self.virtspace_short(\n                        ttbr.address, self.data.page_tables[\"kernel\"], cache=virt_cache\n                    )\n                    for _, _, kx in virtspace:\n                        if kx:\n                            break\n                    else:\n                        continue\n\n                    ttbr0s[ttbr.address] = (ttbr, data)\n\n        # Use only TTBR0 if TTBCR.N = 0\n        if SHORT.ttbcr_n != 0:\n            virt_cache = defaultdict(dict)\n            for key in [\"TTBR1\", \"TTBR1_S\", \"TTBR1_EL1\", \"TTBR1_EL1_S\"]:\n                for value, data in self.gtruth.get(key, {}).items():\n                    ttbr = TTBR1(value)\n                    if any([ttbr.is_mmu_equivalent_to(x[0]) for x in ttbr1s.values()]):\n                        continue\n\n                    if ttbr.address not in self.data.page_tables[\"kernel\"][0]:\n                        continue\n\n                    consistency, pas = self.physpace(\n                        ttbr.address,\n                        self.data.page_tables[\"kernel\"],\n                        self.data.empty_tables,\n                        cache=ttbr1_phy_cache,\n                    )\n                    if not consistency or (\n                        pas.get_kernel_size() == 0 and pas.get_user_size() == 0\n                    ):\n                        continue\n\n                    if not any(\n                        [opcode_addr in pas for opcode_addr in kernel_opcodes_read]\n                    ):\n                        continue\n\n                    # At least a kernel executable page must be exist\n                    virtspace = self.virtspace_short(\n                        ttbr.address, self.data.page_tables[\"kernel\"], cache=virt_cache\n                    )\n                    for _, _, kx in virtspace:\n                        if kx:\n                            break\n                    else:\n                        continue\n\n                    ttbr1s[ttbr.address] = (ttbr, data)\n\n        # True positives, false negatives, false positives\n        if SHORT.ttbcr_n == 0:\n            tps = sorted(\n                set(ttbr0s.keys()).intersection(set(self.data.ttbrs[\"kernel\"].keys()))\n            )\n            fns = sorted(\n                set(ttbr0s.keys()).difference(set(self.data.ttbrs[\"kernel\"].keys()))\n            )\n            fps = sorted(\n                set(self.data.ttbrs[\"kernel\"].keys()).difference(set(ttbr0s.keys()))\n            )\n        else:\n            tps = sorted(\n                set(ttbr1s.keys()).intersection(set(self.data.ttbrs[\"kernel\"].keys()))\n            )\n            fns = sorted(\n                set(ttbr1s.keys()).difference(set(self.data.ttbrs[\"kernel\"].keys()))\n            )\n            fps = sorted(\n                set(self.data.ttbrs[\"kernel\"].keys()).difference(set(ttbr1s.keys()))\n            )\n            tpsu = sorted(\n                set(ttbr0s.keys()).intersection(set(self.data.ttbrs[\"user\"].keys()))\n            )\n            fnsu = sorted(\n                set(ttbr0s.keys()).difference(set(self.data.ttbrs[\"user\"].keys()))\n            )\n            fpsu = sorted(\n                set(self.data.ttbrs[\"user\"].keys()).difference(set(ttbr0s.keys()))\n            )\n\n        # Show results\n        table = PrettyTable()\n        table.field_names = [\"Address\", \"Found\", \"Mode\", \"First seen\", \"Last seen\"]\n        if SHORT.ttbcr_n == 0:\n            kernel_regs = ttbr0s\n            mode = \"K/U\"\n        else:\n            kernel_regs = ttbr1s\n            mode = \"K\"\n\n        for tp in sorted(tps):\n            table.add_row(\n                [hex(tp), \"X\", mode, kernel_regs[tp][1][0], kernel_regs[tp][1][1]]\n            )\n\n        for fn in sorted(fns):\n            table.add_row(\n                [hex(fn), \"\", mode, kernel_regs[fn][1][0], kernel_regs[fn][1][1]]\n            )\n\n        for fp in sorted(fps):\n            table.add_row([hex(fp), \"False positive\", mode, \"\", \"\"])\n\n        # User\n        if SHORT.ttbcr_n != 0:\n            for tp in sorted(tpsu):\n                table.add_row([hex(tp), \"X\", \"U\", ttbr0s[tp][1][0], ttbr0s[tp][1][1]])\n\n            for fn in sorted(fnsu):\n                table.add_row([hex(fn), \"\", \"U\", ttbr0s[fn][1][0], ttbr0s[fn][1][1]])\n\n            for fp in sorted(fpsu):\n                table.add_row([hex(fp), \"False positive\", \"U\", \"\", \"\"])\n\n        print(table)\n        print(f\"TP:{len(tps)} FN:{len(fns)} FP:{len(fps)}\")\n        if SHORT.ttbcr_n != 0:\n            print(f\"USER TP:{len(tpsu)} FN:{len(fnsu)} FP:{len(fpsu)}\")\n</code></pre>"},{"location":"reference/architectures/arm/#mmushell.architectures.arm.MMUShellGTruth.do_show_radix_trees_gtruth","title":"<code>do_show_radix_trees_gtruth(args)</code>","text":"<p>Compare found radix trees with the ground truth</p> Source code in <code>mmushell/architectures/arm.py</code> <pre><code>def do_show_radix_trees_gtruth(self, args):\n    \"\"\"Compare found radix trees with the ground truth\"\"\"\n    if not self.data.is_radix_found:\n        logging.info(\"Please, find them first!\")\n        return\n\n    # Collect TTBR0 and TTBR1 values from the gtruth\n    ttbr0s = {}\n    ttbr1s = {}\n    ttbr0_phy_cache = defaultdict(dict)\n    ttbr1_phy_cache = defaultdict(dict)\n    virt_cache = defaultdict(dict)\n    filter_f_read = (\n        lambda it: True\n        if it[1][\"register\"] in [\"DFSR\", \"IFSR\"] and it[1][\"instruction\"] == \"MRC\"\n        else False\n    )\n    kernel_opcodes_read = [\n        x[0] for x in filter(filter_f_read, self.data.opcodes.items())\n    ]\n    filter_f_write = (\n        lambda it: True\n        if it[1][\"register\"] in [\"TTBR0\", \"TTBCR\"] and it[1][\"instruction\"] == \"MCR\"\n        else False\n    )\n    kernel_opcodes_write = [\n        x[0] for x in filter(filter_f_write, self.data.opcodes.items())\n    ]\n\n    # User or kernel+user radix trees\n    for key in [\"TTBR0\", \"TTBR0_S\", \"TTBR0_EL1\", \"TTBR0_EL1_S\"]:\n        for value, data in self.gtruth.get(key, {}).items():\n            ttbr = TTBR0(value)\n            if any([ttbr.is_mmu_equivalent_to(x[0]) for x in ttbr0s.values()]):\n                continue\n\n            if SHORT.ttbcr_n != 0:\n                if ttbr.address not in self.data.page_tables[\"user\"][0]:\n                    continue\n\n                consistency, pas = self.physpace(\n                    ttbr.address,\n                    self.data.page_tables[\"user\"],\n                    self.data.empty_tables,\n                    cache=ttbr0_phy_cache,\n                )\n                if not consistency:\n                    continue\n\n                if pas.get_kernel_size() != 0:\n                    continue\n\n                virtspace = self.virtspace_short(\n                    ttbr.address, self.data.page_tables[\"user\"], cache=virt_cache\n                )\n                for _, x, _ in virtspace:\n                    if x:\n                        break\n                else:\n                    continue\n\n                # Filter for at least a writable page\n                for p, _, _ in virtspace:\n                    if p &amp; 0b10 == 2:\n                        break\n                else:\n                    continue\n\n                ttbr0s[ttbr.address] = (ttbr, data)\n\n            else:\n                if ttbr.address not in self.data.page_tables[\"kernel\"][0]:\n                    continue\n\n                consistency, pas = self.physpace(\n                    ttbr.address,\n                    self.data.page_tables[\"kernel\"],\n                    self.data.empty_tables,\n                    cache=ttbr0_phy_cache,\n                )\n                if not consistency or (\n                    pas.get_kernel_size() == 0 and pas.get_user_size() == 0\n                ):\n                    continue\n\n                if not any(\n                    [opcode_addr in pas for opcode_addr in kernel_opcodes_read]\n                ) or not any(\n                    [opcode_addr in pas for opcode_addr in kernel_opcodes_write]\n                ):\n                    continue\n\n                # At least a kernel executable page must be exist\n                virtspace = self.virtspace_short(\n                    ttbr.address, self.data.page_tables[\"kernel\"], cache=virt_cache\n                )\n                for _, _, kx in virtspace:\n                    if kx:\n                        break\n                else:\n                    continue\n\n                ttbr0s[ttbr.address] = (ttbr, data)\n\n    # Use only TTBR0 if TTBCR.N = 0\n    if SHORT.ttbcr_n != 0:\n        virt_cache = defaultdict(dict)\n        for key in [\"TTBR1\", \"TTBR1_S\", \"TTBR1_EL1\", \"TTBR1_EL1_S\"]:\n            for value, data in self.gtruth.get(key, {}).items():\n                ttbr = TTBR1(value)\n                if any([ttbr.is_mmu_equivalent_to(x[0]) for x in ttbr1s.values()]):\n                    continue\n\n                if ttbr.address not in self.data.page_tables[\"kernel\"][0]:\n                    continue\n\n                consistency, pas = self.physpace(\n                    ttbr.address,\n                    self.data.page_tables[\"kernel\"],\n                    self.data.empty_tables,\n                    cache=ttbr1_phy_cache,\n                )\n                if not consistency or (\n                    pas.get_kernel_size() == 0 and pas.get_user_size() == 0\n                ):\n                    continue\n\n                if not any(\n                    [opcode_addr in pas for opcode_addr in kernel_opcodes_read]\n                ):\n                    continue\n\n                # At least a kernel executable page must be exist\n                virtspace = self.virtspace_short(\n                    ttbr.address, self.data.page_tables[\"kernel\"], cache=virt_cache\n                )\n                for _, _, kx in virtspace:\n                    if kx:\n                        break\n                else:\n                    continue\n\n                ttbr1s[ttbr.address] = (ttbr, data)\n\n    # True positives, false negatives, false positives\n    if SHORT.ttbcr_n == 0:\n        tps = sorted(\n            set(ttbr0s.keys()).intersection(set(self.data.ttbrs[\"kernel\"].keys()))\n        )\n        fns = sorted(\n            set(ttbr0s.keys()).difference(set(self.data.ttbrs[\"kernel\"].keys()))\n        )\n        fps = sorted(\n            set(self.data.ttbrs[\"kernel\"].keys()).difference(set(ttbr0s.keys()))\n        )\n    else:\n        tps = sorted(\n            set(ttbr1s.keys()).intersection(set(self.data.ttbrs[\"kernel\"].keys()))\n        )\n        fns = sorted(\n            set(ttbr1s.keys()).difference(set(self.data.ttbrs[\"kernel\"].keys()))\n        )\n        fps = sorted(\n            set(self.data.ttbrs[\"kernel\"].keys()).difference(set(ttbr1s.keys()))\n        )\n        tpsu = sorted(\n            set(ttbr0s.keys()).intersection(set(self.data.ttbrs[\"user\"].keys()))\n        )\n        fnsu = sorted(\n            set(ttbr0s.keys()).difference(set(self.data.ttbrs[\"user\"].keys()))\n        )\n        fpsu = sorted(\n            set(self.data.ttbrs[\"user\"].keys()).difference(set(ttbr0s.keys()))\n        )\n\n    # Show results\n    table = PrettyTable()\n    table.field_names = [\"Address\", \"Found\", \"Mode\", \"First seen\", \"Last seen\"]\n    if SHORT.ttbcr_n == 0:\n        kernel_regs = ttbr0s\n        mode = \"K/U\"\n    else:\n        kernel_regs = ttbr1s\n        mode = \"K\"\n\n    for tp in sorted(tps):\n        table.add_row(\n            [hex(tp), \"X\", mode, kernel_regs[tp][1][0], kernel_regs[tp][1][1]]\n        )\n\n    for fn in sorted(fns):\n        table.add_row(\n            [hex(fn), \"\", mode, kernel_regs[fn][1][0], kernel_regs[fn][1][1]]\n        )\n\n    for fp in sorted(fps):\n        table.add_row([hex(fp), \"False positive\", mode, \"\", \"\"])\n\n    # User\n    if SHORT.ttbcr_n != 0:\n        for tp in sorted(tpsu):\n            table.add_row([hex(tp), \"X\", \"U\", ttbr0s[tp][1][0], ttbr0s[tp][1][1]])\n\n        for fn in sorted(fnsu):\n            table.add_row([hex(fn), \"\", \"U\", ttbr0s[fn][1][0], ttbr0s[fn][1][1]])\n\n        for fp in sorted(fpsu):\n            table.add_row([hex(fp), \"False positive\", \"U\", \"\", \"\"])\n\n    print(table)\n    print(f\"TP:{len(tps)} FN:{len(fns)} FP:{len(fps)}\")\n    if SHORT.ttbcr_n != 0:\n        print(f\"USER TP:{len(tpsu)} FN:{len(fnsu)} FP:{len(fpsu)}\")\n</code></pre>"},{"location":"reference/architectures/arm/#mmushell.architectures.arm.MMUShellGTruth.do_show_registers_gtruth","title":"<code>do_show_registers_gtruth(args)</code>","text":"<p>Compare TTBCR register values found with the ground truth</p> Source code in <code>mmushell/architectures/arm.py</code> <pre><code>def do_show_registers_gtruth(self, args):\n    \"\"\"Compare TTBCR register values found with the ground truth\"\"\"\n    if not self.data.is_registers_found:\n        logging.info(\"Please, find them first!\")\n        return\n\n    # Check if the last value of TTBCR was found\n    all_ttbcrs = (\n        {}\n    )  # QEMU export TTBCR inside various registers as TTBCR, TTBCR, TCR_S etc. due to it's capability to emulate different ARM/ARM64 systems\n    for reg_name, value_data in self.gtruth.items():\n        if \"TCR\" in reg_name or \"TTBCR\" in reg_name:\n            for value, value_info in value_data.items():\n                if value not in all_ttbcrs or (\n                    value_info[1] &gt; all_ttbcrs[value][1]\n                ):\n                    all_ttbcrs[value] = (value_info[0], value_info[1])\n\n    last_ttbcr = TTBCR(\n        sorted(all_ttbcrs.keys(), key=lambda x: all_ttbcrs[x][1], reverse=True)[0]\n    )\n\n    ttbcr_fields_equals = {}\n    for value_found_obj in self.data.regs_values[\"TTBCR\"]:\n        ttbcr_fields_equals[value_found_obj] = value_found_obj.count_fields_equals(\n            last_ttbcr\n        )\n    k_sorted = sorted(\n        ttbcr_fields_equals.keys(),\n        key=lambda x: ttbcr_fields_equals[x],\n        reverse=True,\n    )\n    tcr_found = k_sorted[0]\n    correct_fields_found = ttbcr_fields_equals[tcr_found]\n\n    if correct_fields_found:\n        print(f\"Correct TTBCR value: {last_ttbcr}, Found: {tcr_found}\")\n        print(\"TTBCR fields found:... {}/2\".format(correct_fields_found))\n        print(\"FP: {}\".format(str(len(self.data.regs_values[\"TTBCR\"]) - 1)))\n    else:\n        print(f\"Correct TTBCR value: {last_ttbcr}\")\n        print(\"TTBCR fields found:... 0/2\")\n        print(\"FP: {}\".format(str(len(self.data.regs_values[\"TTBCR\"]))))\n</code></pre>"},{"location":"reference/architectures/generic/","title":"Generic","text":""},{"location":"reference/architectures/generic/#generic","title":"Generic","text":""},{"location":"reference/architectures/generic/#mmushell.architectures.generic.CPU","title":"<code>CPU</code>","text":"<p>Represents a generic CPU</p> <p>A CPU is able to parse opcodes and to find the dataflow of the registers.</p> <p>Aimed to be inherited by child classes to represent different architectures</p> <p>Attributes:</p> Name Type Description <code>architecture</code> <p>the architecture of the CPU</p> <code>bits</code> <p>the bits of the CPU</p> <code>endianness</code> <p>the endianness of the CPU</p> <code>processor_features</code> <p>the processor features of the CPU</p> <code>registers_values</code> <p>the registers values of the CPU</p> <code>opcode_to_mmu_regs</code> <p>the mapping between opcodes and MMU registers</p> <code>opcode_to_gregs</code> <p>the mapping between opcodes and general registers</p> <code>machine</code> <p>the machine of the CPU</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>class CPU:\n    \"\"\"Represents a generic CPU\n\n    A CPU is able to parse opcodes and to find the dataflow of the registers.\n\n    Aimed to be inherited by child classes to represent different architectures\n\n    Attributes:\n        architecture: the architecture of the CPU\n        bits: the bits of the CPU\n        endianness: the endianness of the CPU\n        processor_features: the processor features of the CPU\n        registers_values: the registers values of the CPU\n        opcode_to_mmu_regs: the mapping between opcodes and MMU registers\n        opcode_to_gregs: the mapping between opcodes and general registers\n        machine: the machine of the CPU\n    \"\"\"\n\n    opcode_to_mmu_regs = None\n    opcode_to_gregs = None\n\n    @classmethod\n    def from_cpu_config(cls, cpu_config, **kwargs):\n        \"\"\"Create a CPU starting from a YAML file descriptor\n\n        Args:\n            cpu_config: the YAML file descriptor\n            **kwargs: additional arguments\n\n        Returns:\n            a new CPU object\n        \"\"\"\n        return CPU(cpu_config)\n\n    machine = None\n\n    def __init__(self, params):\n        \"\"\"Initialize the CPU\n\n        Args:\n            params: the parameters of the CPU\n        \"\"\"\n        self.architecture = params[\"architecture\"]\n        self.bits = params[\"bits\"]\n        self.endianness = params[\"endianness\"]\n        self.processor_features = params.get(\"processor_features\", {})\n        self.registers_values = params.get(\"registers_values\", {})\n\n    @staticmethod\n    def extract_bits_little(entry, pos, n):\n        \"\"\"Extract bits from an entry in little endian\n\n        Args:\n            entry: the entry to extract bits from\n            pos: the position of the bits\n            n: the number of bits to extract\n\n        Returns:\n            the extracted bits\n        \"\"\"\n        return (entry &gt;&gt; pos) &amp; ((1 &lt;&lt; n) - 1)\n\n    @staticmethod\n    def extract_bits_big(entry, pos, n):\n        \"\"\"Extract bits from an entry in big endian\n\n        Args:\n            entry: the entry to extract bits from\n            pos: the position of the bits\n            n: the number of bits to extract\n\n        Returns:\n            the extracted bits\n        \"\"\"\n        return (entry &gt;&gt; (32 - pos - n)) &amp; ((1 &lt;&lt; n) - 1)\n\n    @staticmethod\n    def extract_bits_big64(entry, pos, n):\n        \"\"\"Extract bits from an entry in big endian 64 bits\n\n        Args:\n            entry: the entry to extract bits from\n            pos: the position of the bits\n            n: the number of bits to extract\n\n        Returns:\n            the extracted bits\n        \"\"\"\n        return (entry &gt;&gt; (64 - pos - n)) &amp; ((1 &lt;&lt; n) - 1)\n\n    def parse_opcode(self, buff, page_addr, offset):\n        \"\"\"Parse an opcode\n\n        Aimed to be overloaded by child classes\n\n        Args:\n            buff: the buffer to parse\n            page_addr: the address of the page\n            offset: the offset of the opcode\n\n        Returns:\n            the parsed opcode\n        \"\"\"\n        raise NotImplementedError\n\n    def parse_opcodes_parallel(self, addresses, frame_size, pidx, **kwargs) -&gt; dict:\n        \"\"\"Parse opcodes in parallel\n\n        Every process sleep a random delay in order to desynchronise access to disk and maximixe the throuput\n\n        Args:\n            addresses: the addresses to parse\n            frame_size: the size of the frame\n            pidx: the process index\n            **kwargs: additional arguments\n\n        Returns:\n            dictionnary of parsed opcodes\n        \"\"\"\n        # Every process sleep a random delay in order to desincronize access to disk and maximixe the throuput\n        sleep(uniform(pidx, pidx + 1) // 1000)\n\n        opcodes = {}\n        mm = copy(self.machine.memory)\n        mm.reopen()\n\n        # Cicle over every frame\n        total_elems, iterator = addresses\n        for frame_addr in tqdm(\n            iterator, position=-pidx, total=total_elems, leave=False\n        ):\n            frame_buf = mm.get_data(\n                frame_addr, frame_size\n            )  # We parse memory in PAGE_SIZE chunks\n\n            for idx, opcode in enumerate(\n                iter_unpack(self.processor_features[\"opcode_unpack_fmt\"], frame_buf)\n            ):\n                opcode = opcode[0]\n                opcodes.update(\n                    self.parse_opcode(\n                        opcode, frame_addr, idx * self.processor_features[\"instr_len\"]\n                    )\n                )\n\n        return opcodes\n\n    def find_registers_values_dataflow(self, opcodes, zero_registers=[]) -&gt; set:\n        \"\"\"Find the dataflow of the registers\n\n        Args:\n            opcodes: the opcodes to analyze\n            zero_registers: the registers to ignore\n\n        Returns:\n            a dictionnary with the dataflow of the registers\n        \"\"\"\n        # Miasm require to define a memory() function to access to the underlaying\n        # memory layer during the Python translation\n        # WORKAROUND: memory() does not permit more than 2 args...\n        endianness = self.endianness\n\n        def memory(addr, size):\n            return int.from_bytes(self.machine.memory.get_data(addr, size), endianness)\n\n        machine = self.machine.get_miasm_machine()\n        vm = self.machine.memory.get_miasm_vmmngr()\n        mdis = machine.dis_engine(\n            bin_stream_vm(vm), dont_dis_nulstart_bloc=False, loc_db=LocationDB()\n        )\n\n        ir_arch = machine.ira(mdis.loc_db)\n        py_transl = TranslatorPython()\n\n        # Disable MIASM logging\n        logging.getLogger(\"asmblock\").disabled = True\n\n        registers_values = defaultdict(set)\n        # We use a stack data structure (deque) in order to also manage parent functions (EXPERIMENTAL not implemented here)\n        instr_deque = deque([(addr, opcodes[addr]) for addr in opcodes])\n        while len(instr_deque):\n            instr_addr, instr_data = instr_deque.pop()\n\n            # Ignore instruction with associated function not found\n            if instr_data[\"f_addr\"] == -1:\n                continue\n\n            # Do not dataflow instructions with source registers in zero_registers\n            # because contain zero\n            if instr_data[\"gpr\"] in zero_registers:\n                registers_values[instr_data[\"register\"]].add(0x0)\n                continue\n\n            # Disable disassemble logging for unimplemented opcodes\n            with DisableLogs():\n                try:\n                    # Initialize dependency graph machinery\n                    mdis.dont_dis = [instr_addr + self.processor_features[\"instr_len\"]]\n                    asmcfg = mdis.dis_multiblock(instr_data[\"f_addr\"])\n                    ircfg = ir_arch.new_ircfg_from_asmcfg(asmcfg)\n                    dg = DependencyGraph(ircfg)\n                except Exception as e:\n                    # Disassembler can raises exception if a JMP address is register dependent,\n                    # in that case the analysis fails..\n                    # print(e)\n                    # traceback.print_exc()\n                    continue\n\n            # Collect function informations\n            try:\n                current_loc_key = next(iter(ircfg.getby_offset(instr_addr)))\n                assignblk_index = 0\n                current_block = ircfg.get_block(current_loc_key)\n                for assignblk_index, assignblk in enumerate(current_block):\n                    if assignblk.instr.offset == instr_addr:\n                        break\n            except Exception as e:\n                # If the function graph does not contain the instruction or the disassembler cannot complete the\n                # task due to unimplemented instructions next(iter(...)) raises a fatal exception\n                # print(e)\n                # traceback.print_exc()\n                continue\n\n            # Recreate default CPU config registers state and general registers to look for\n            bits = self.bits\n            gp_registers = [ExprId(reg, bits) for reg in instr_data[\"gpr\"]]\n            init_ctx = {\n                ExprId(name.upper(), bits): ExprInt(value, bits)\n                for name, value in self.registers_values.items()\n            }\n\n            # Generate solutions\n            loops = 0\n            for sol_nb, sol in enumerate(\n                dg.get(current_block.loc_key, gp_registers, assignblk_index, set())\n            ):\n                # The solution contains a loop, we permit only a maximum of 10 solutions with loops...\n                if sol.has_loop:\n                    loops += 1\n                    if loops &gt; 10:\n                        break\n\n                # Emulate the blocks chain\n                results = sol.emul(ir_arch, ctx=init_ctx)\n\n                # Retrieve the solutions and translate it in a python expression\n                for reg_name, reg_value_expr in results.items():\n                    try:\n                        translated_expr = py_transl.from_expr(reg_value_expr)\n                        evaluated_expr = eval(translated_expr)\n                        registers_values[instr_data[\"register\"]].add(evaluated_expr)\n\n                    except NameError:\n                        # The expression depends on another register which can imply that the function is called\n                        # by another one which pass it the value\n\n                        # using parents function drastically slow down (block?) the analysis (EXPERIMENTAL not used here)\n                        # for f_parent in instr_data[\"f_parents\"]:\n                        #     instr_deque.append((instr_addr, {\"register\": instr_data[\"register\"],\n                        #                                      \"gpr\": instr_data[\"gpr\"],\n                        #                                      \"f_addr\": f_parent,\n                        #                                      \"f_parents\": []\n                        #                                     }))\n\n                        continue\n\n                    except Exception as e:\n                        # Possible other exceptions due to MIASM incomplete internal implementation\n                        # print(e)\n                        # traceback.print_exc()\n                        continue\n\n        del vm\n        self.machine.memory.free_miasm_memory()\n        return registers_values\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.CPU.__init__","title":"<code>__init__(params)</code>","text":"<p>Initialize the CPU</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <p>the parameters of the CPU</p> required Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def __init__(self, params):\n    \"\"\"Initialize the CPU\n\n    Args:\n        params: the parameters of the CPU\n    \"\"\"\n    self.architecture = params[\"architecture\"]\n    self.bits = params[\"bits\"]\n    self.endianness = params[\"endianness\"]\n    self.processor_features = params.get(\"processor_features\", {})\n    self.registers_values = params.get(\"registers_values\", {})\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.CPU.extract_bits_big","title":"<code>extract_bits_big(entry, pos, n)</code>  <code>staticmethod</code>","text":"<p>Extract bits from an entry in big endian</p> <p>Parameters:</p> Name Type Description Default <code>entry</code> <p>the entry to extract bits from</p> required <code>pos</code> <p>the position of the bits</p> required <code>n</code> <p>the number of bits to extract</p> required <p>Returns:</p> Type Description <p>the extracted bits</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>@staticmethod\ndef extract_bits_big(entry, pos, n):\n    \"\"\"Extract bits from an entry in big endian\n\n    Args:\n        entry: the entry to extract bits from\n        pos: the position of the bits\n        n: the number of bits to extract\n\n    Returns:\n        the extracted bits\n    \"\"\"\n    return (entry &gt;&gt; (32 - pos - n)) &amp; ((1 &lt;&lt; n) - 1)\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.CPU.extract_bits_big64","title":"<code>extract_bits_big64(entry, pos, n)</code>  <code>staticmethod</code>","text":"<p>Extract bits from an entry in big endian 64 bits</p> <p>Parameters:</p> Name Type Description Default <code>entry</code> <p>the entry to extract bits from</p> required <code>pos</code> <p>the position of the bits</p> required <code>n</code> <p>the number of bits to extract</p> required <p>Returns:</p> Type Description <p>the extracted bits</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>@staticmethod\ndef extract_bits_big64(entry, pos, n):\n    \"\"\"Extract bits from an entry in big endian 64 bits\n\n    Args:\n        entry: the entry to extract bits from\n        pos: the position of the bits\n        n: the number of bits to extract\n\n    Returns:\n        the extracted bits\n    \"\"\"\n    return (entry &gt;&gt; (64 - pos - n)) &amp; ((1 &lt;&lt; n) - 1)\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.CPU.extract_bits_little","title":"<code>extract_bits_little(entry, pos, n)</code>  <code>staticmethod</code>","text":"<p>Extract bits from an entry in little endian</p> <p>Parameters:</p> Name Type Description Default <code>entry</code> <p>the entry to extract bits from</p> required <code>pos</code> <p>the position of the bits</p> required <code>n</code> <p>the number of bits to extract</p> required <p>Returns:</p> Type Description <p>the extracted bits</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>@staticmethod\ndef extract_bits_little(entry, pos, n):\n    \"\"\"Extract bits from an entry in little endian\n\n    Args:\n        entry: the entry to extract bits from\n        pos: the position of the bits\n        n: the number of bits to extract\n\n    Returns:\n        the extracted bits\n    \"\"\"\n    return (entry &gt;&gt; pos) &amp; ((1 &lt;&lt; n) - 1)\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.CPU.find_registers_values_dataflow","title":"<code>find_registers_values_dataflow(opcodes, zero_registers=[])</code>","text":"<p>Find the dataflow of the registers</p> <p>Parameters:</p> Name Type Description Default <code>opcodes</code> <p>the opcodes to analyze</p> required <code>zero_registers</code> <p>the registers to ignore</p> <code>[]</code> <p>Returns:</p> Type Description <code>set</code> <p>a dictionnary with the dataflow of the registers</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def find_registers_values_dataflow(self, opcodes, zero_registers=[]) -&gt; set:\n    \"\"\"Find the dataflow of the registers\n\n    Args:\n        opcodes: the opcodes to analyze\n        zero_registers: the registers to ignore\n\n    Returns:\n        a dictionnary with the dataflow of the registers\n    \"\"\"\n    # Miasm require to define a memory() function to access to the underlaying\n    # memory layer during the Python translation\n    # WORKAROUND: memory() does not permit more than 2 args...\n    endianness = self.endianness\n\n    def memory(addr, size):\n        return int.from_bytes(self.machine.memory.get_data(addr, size), endianness)\n\n    machine = self.machine.get_miasm_machine()\n    vm = self.machine.memory.get_miasm_vmmngr()\n    mdis = machine.dis_engine(\n        bin_stream_vm(vm), dont_dis_nulstart_bloc=False, loc_db=LocationDB()\n    )\n\n    ir_arch = machine.ira(mdis.loc_db)\n    py_transl = TranslatorPython()\n\n    # Disable MIASM logging\n    logging.getLogger(\"asmblock\").disabled = True\n\n    registers_values = defaultdict(set)\n    # We use a stack data structure (deque) in order to also manage parent functions (EXPERIMENTAL not implemented here)\n    instr_deque = deque([(addr, opcodes[addr]) for addr in opcodes])\n    while len(instr_deque):\n        instr_addr, instr_data = instr_deque.pop()\n\n        # Ignore instruction with associated function not found\n        if instr_data[\"f_addr\"] == -1:\n            continue\n\n        # Do not dataflow instructions with source registers in zero_registers\n        # because contain zero\n        if instr_data[\"gpr\"] in zero_registers:\n            registers_values[instr_data[\"register\"]].add(0x0)\n            continue\n\n        # Disable disassemble logging for unimplemented opcodes\n        with DisableLogs():\n            try:\n                # Initialize dependency graph machinery\n                mdis.dont_dis = [instr_addr + self.processor_features[\"instr_len\"]]\n                asmcfg = mdis.dis_multiblock(instr_data[\"f_addr\"])\n                ircfg = ir_arch.new_ircfg_from_asmcfg(asmcfg)\n                dg = DependencyGraph(ircfg)\n            except Exception as e:\n                # Disassembler can raises exception if a JMP address is register dependent,\n                # in that case the analysis fails..\n                # print(e)\n                # traceback.print_exc()\n                continue\n\n        # Collect function informations\n        try:\n            current_loc_key = next(iter(ircfg.getby_offset(instr_addr)))\n            assignblk_index = 0\n            current_block = ircfg.get_block(current_loc_key)\n            for assignblk_index, assignblk in enumerate(current_block):\n                if assignblk.instr.offset == instr_addr:\n                    break\n        except Exception as e:\n            # If the function graph does not contain the instruction or the disassembler cannot complete the\n            # task due to unimplemented instructions next(iter(...)) raises a fatal exception\n            # print(e)\n            # traceback.print_exc()\n            continue\n\n        # Recreate default CPU config registers state and general registers to look for\n        bits = self.bits\n        gp_registers = [ExprId(reg, bits) for reg in instr_data[\"gpr\"]]\n        init_ctx = {\n            ExprId(name.upper(), bits): ExprInt(value, bits)\n            for name, value in self.registers_values.items()\n        }\n\n        # Generate solutions\n        loops = 0\n        for sol_nb, sol in enumerate(\n            dg.get(current_block.loc_key, gp_registers, assignblk_index, set())\n        ):\n            # The solution contains a loop, we permit only a maximum of 10 solutions with loops...\n            if sol.has_loop:\n                loops += 1\n                if loops &gt; 10:\n                    break\n\n            # Emulate the blocks chain\n            results = sol.emul(ir_arch, ctx=init_ctx)\n\n            # Retrieve the solutions and translate it in a python expression\n            for reg_name, reg_value_expr in results.items():\n                try:\n                    translated_expr = py_transl.from_expr(reg_value_expr)\n                    evaluated_expr = eval(translated_expr)\n                    registers_values[instr_data[\"register\"]].add(evaluated_expr)\n\n                except NameError:\n                    # The expression depends on another register which can imply that the function is called\n                    # by another one which pass it the value\n\n                    # using parents function drastically slow down (block?) the analysis (EXPERIMENTAL not used here)\n                    # for f_parent in instr_data[\"f_parents\"]:\n                    #     instr_deque.append((instr_addr, {\"register\": instr_data[\"register\"],\n                    #                                      \"gpr\": instr_data[\"gpr\"],\n                    #                                      \"f_addr\": f_parent,\n                    #                                      \"f_parents\": []\n                    #                                     }))\n\n                    continue\n\n                except Exception as e:\n                    # Possible other exceptions due to MIASM incomplete internal implementation\n                    # print(e)\n                    # traceback.print_exc()\n                    continue\n\n    del vm\n    self.machine.memory.free_miasm_memory()\n    return registers_values\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.CPU.from_cpu_config","title":"<code>from_cpu_config(cpu_config, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a CPU starting from a YAML file descriptor</p> <p>Parameters:</p> Name Type Description Default <code>cpu_config</code> <p>the YAML file descriptor</p> required <code>**kwargs</code> <p>additional arguments</p> <code>{}</code> <p>Returns:</p> Type Description <p>a new CPU object</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>@classmethod\ndef from_cpu_config(cls, cpu_config, **kwargs):\n    \"\"\"Create a CPU starting from a YAML file descriptor\n\n    Args:\n        cpu_config: the YAML file descriptor\n        **kwargs: additional arguments\n\n    Returns:\n        a new CPU object\n    \"\"\"\n    return CPU(cpu_config)\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.CPU.parse_opcode","title":"<code>parse_opcode(buff, page_addr, offset)</code>","text":"<p>Parse an opcode</p> <p>Aimed to be overloaded by child classes</p> <p>Parameters:</p> Name Type Description Default <code>buff</code> <p>the buffer to parse</p> required <code>page_addr</code> <p>the address of the page</p> required <code>offset</code> <p>the offset of the opcode</p> required <p>Returns:</p> Type Description <p>the parsed opcode</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def parse_opcode(self, buff, page_addr, offset):\n    \"\"\"Parse an opcode\n\n    Aimed to be overloaded by child classes\n\n    Args:\n        buff: the buffer to parse\n        page_addr: the address of the page\n        offset: the offset of the opcode\n\n    Returns:\n        the parsed opcode\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.CPU.parse_opcodes_parallel","title":"<code>parse_opcodes_parallel(addresses, frame_size, pidx, **kwargs)</code>","text":"<p>Parse opcodes in parallel</p> <p>Every process sleep a random delay in order to desynchronise access to disk and maximixe the throuput</p> <p>Parameters:</p> Name Type Description Default <code>addresses</code> <p>the addresses to parse</p> required <code>frame_size</code> <p>the size of the frame</p> required <code>pidx</code> <p>the process index</p> required <code>**kwargs</code> <p>additional arguments</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>dictionnary of parsed opcodes</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def parse_opcodes_parallel(self, addresses, frame_size, pidx, **kwargs) -&gt; dict:\n    \"\"\"Parse opcodes in parallel\n\n    Every process sleep a random delay in order to desynchronise access to disk and maximixe the throuput\n\n    Args:\n        addresses: the addresses to parse\n        frame_size: the size of the frame\n        pidx: the process index\n        **kwargs: additional arguments\n\n    Returns:\n        dictionnary of parsed opcodes\n    \"\"\"\n    # Every process sleep a random delay in order to desincronize access to disk and maximixe the throuput\n    sleep(uniform(pidx, pidx + 1) // 1000)\n\n    opcodes = {}\n    mm = copy(self.machine.memory)\n    mm.reopen()\n\n    # Cicle over every frame\n    total_elems, iterator = addresses\n    for frame_addr in tqdm(\n        iterator, position=-pidx, total=total_elems, leave=False\n    ):\n        frame_buf = mm.get_data(\n            frame_addr, frame_size\n        )  # We parse memory in PAGE_SIZE chunks\n\n        for idx, opcode in enumerate(\n            iter_unpack(self.processor_features[\"opcode_unpack_fmt\"], frame_buf)\n        ):\n            opcode = opcode[0]\n            opcodes.update(\n                self.parse_opcode(\n                    opcode, frame_addr, idx * self.processor_features[\"instr_len\"]\n                )\n            )\n\n    return opcodes\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.CPUReg","title":"<code>CPUReg</code>","text":"<p>Represents a CPU register</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>class CPUReg:\n    \"\"\"Represents a CPU register\"\"\"\n\n    def is_valid(self, value) -&gt; bool:\n        \"\"\"Check if the value is valid for the register\n\n        Being a valid register is very specific to the architecture, so this function is aimed to be overloaded by child classes\n\n        Args:\n            value: the value to check\n\n        Returns:\n            True if the value is valid, False otherwise\n        \"\"\"\n        return True\n\n    def is_mmu_equivalent_to(self, other_reg):\n        \"\"\"Check if the register is equivalent to another register\n\n        Args:\n            other_reg: the other register to compare\n\n        See child classes for more details\n        \"\"\"\n        raise NotImplementedError\n\n    def __hash__(self):\n        \"\"\"Hash of the contained value from register\"\"\"\n        return hash(self.value)\n\n    def __eq__(self, other):\n        return self.value == other.value\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.CPUReg.__hash__","title":"<code>__hash__()</code>","text":"<p>Hash of the contained value from register</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def __hash__(self):\n    \"\"\"Hash of the contained value from register\"\"\"\n    return hash(self.value)\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.CPUReg.is_mmu_equivalent_to","title":"<code>is_mmu_equivalent_to(other_reg)</code>","text":"<p>Check if the register is equivalent to another register</p> <p>Parameters:</p> Name Type Description Default <code>other_reg</code> <p>the other register to compare</p> required <p>See child classes for more details</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def is_mmu_equivalent_to(self, other_reg):\n    \"\"\"Check if the register is equivalent to another register\n\n    Args:\n        other_reg: the other register to compare\n\n    See child classes for more details\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.CPUReg.is_valid","title":"<code>is_valid(value)</code>","text":"<p>Check if the value is valid for the register</p> <p>Being a valid register is very specific to the architecture, so this function is aimed to be overloaded by child classes</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <p>the value to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the value is valid, False otherwise</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def is_valid(self, value) -&gt; bool:\n    \"\"\"Check if the value is valid for the register\n\n    Being a valid register is very specific to the architecture, so this function is aimed to be overloaded by child classes\n\n    Args:\n        value: the value to check\n\n    Returns:\n        True if the value is valid, False otherwise\n    \"\"\"\n    return True\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.MMU","title":"<code>MMU</code>","text":"<p>Represents a generic MMU</p> <p>The MMU is the hardware device that converts the virtual addresses used by the processor to physical addresses. To accomplish this task, the MMU needs to be configured by using special system registers, while in-memory structures that maintain the virtual-to-physical mapping have to be defined and continuously updated by the operating system. When the MMU fails to resolve a requested virtual address, it raises an interrupt to signal the OS to update the in-memory related structures. It is important to note that the MMU demands strict conformity of the shape and topology of the in-memory structure to the ISA and MMU configuration requirements. Otherwise, it raises an exception and aborts the address translation. The translation process can involve up to two separate translations, both accomplished by the MMU: segmentation, which converts virtual to segmented addresses, and paging, which converts segmented addresses to physical ones. Some architectures use either one or the other, while others use both. In general, when the system boots, the MMU is virtually disabled and all the virtual addresses are identically transformed to physical ones. This allows the OS to start in a simplified memory environment and gives it time to properly configure and enable the MMU before spawning other processes. Since address translation is a performance bottleneck, the latest translated addresses are cached in a few but low- latency hardware structures called Translation Lookaside Buffers (TLBs). Before starting a translation, the MMU checks if TLBs contain an already resolved virtual address and, if so, it returns directly the corresponding physical addresses.</p> <p>Aimed to be inherited by child classes to represent different architectures</p> <p>Attributes:</p> Name Type Description <code>mmu_config</code> <p>the configuration of the MMU</p> <code>PAGE_SIZE</code> <p>the size of the page</p> <code>extract_bits</code> <p>the function to extract bits</p> <code>paging_unpack_format</code> <p>the format of the paging</p> <code>page_table_class</code> <p>the class of the page table</p> <code>radix_levels</code> <p>the levels of the radix tree</p> <code>top_prefix</code> <p>the top prefix of the radix tree</p> <code>entries_size</code> <p>the size of the entries</p> <code>map_ptr_entries_to_levels</code> <p>the mapping between pointer entries and levels</p> <code>map_datapages_entries_to_levels</code> <p>the mapping between data pages entries and levels</p> <code>map_level_to_table_size</code> <p>the mapping between levels and table sizes</p> <code>map_entries_to_shifts</code> <p>the mapping between entries and shifts</p> <code>map_reserved_entries_to_levels</code> <p>the mapping between reserved entries and levels</p> <code>machine</code> <p>the machine of the MMU</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>class MMU:\n    \"\"\"Represents a generic MMU\n\n    The MMU is the hardware device that converts the virtual addresses used by the processor to physical addresses.\n    To accomplish this task, the MMU needs to be configured by using special system registers, while in-memory\n    structures that maintain the virtual-to-physical mapping have to be defined and continuously updated by the\n    operating system.\n    When the MMU fails to resolve a requested virtual address, it raises an interrupt to signal the OS to update\n    the in-memory related structures.\n    It is important to note that the MMU demands strict conformity of the shape and topology of the in-memory structure\n    to the ISA and MMU configuration requirements. Otherwise, it raises an exception and aborts the address translation.\n    The translation process can involve up to two separate translations, both accomplished by the MMU: segmentation,\n    which converts virtual to segmented addresses, and paging, which converts segmented addresses to physical ones.\n    Some architectures use either one or the other, while others use both.\n    In general, when the system boots, the MMU is virtually disabled and all the virtual addresses are identically\n    transformed to physical ones. This allows the OS to start in a simplified memory environment and gives it time to\n    properly configure and enable the MMU before spawning other processes.\n    Since address translation is a performance bottleneck, the latest translated addresses are cached in a few but low-\n    latency hardware structures called Translation Lookaside Buffers (TLBs). Before starting a translation, the MMU checks\n    if TLBs contain an already resolved virtual address and, if so, it returns directly the corresponding physical addresses.\n\n    Aimed to be inherited by child classes to represent different architectures\n\n    Attributes:\n        mmu_config: the configuration of the MMU\n        PAGE_SIZE: the size of the page\n        extract_bits: the function to extract bits\n        paging_unpack_format: the format of the paging\n        page_table_class: the class of the page table\n        radix_levels: the levels of the radix tree\n        top_prefix: the top prefix of the radix tree\n        entries_size: the size of the entries\n        map_ptr_entries_to_levels: the mapping between pointer entries and levels\n        map_datapages_entries_to_levels: the mapping between data pages entries and levels\n        map_level_to_table_size: the mapping between levels and table sizes\n        map_entries_to_shifts: the mapping between entries and shifts\n        map_reserved_entries_to_levels: the mapping between reserved entries and levels\n        machine: the machine of the MMU\n    \"\"\"\n\n    machine = None\n\n    def __init__(self, mmu_config):\n        \"\"\"Initialize the MMU\n\n        Args:\n            mmu_config: the configuration of the MMU\n        \"\"\"\n        self.mmu_config = mmu_config\n\n    @staticmethod\n    def extract_bits_little(entry, pos, n):\n        \"\"\"Extract bits from an entry in little endian\n\n        Args:\n            entry: the entry to extract bits from\n            pos: the position of the bits\n            n: the number of bits to extract\n\n        Returns:\n            the extracted bits\n        \"\"\"\n        return (entry &gt;&gt; pos) &amp; ((1 &lt;&lt; n) - 1)\n\n    @staticmethod\n    def extract_bits_big(entry, pos, n):\n        \"\"\"Extract bits from an entry in big endian\n\n        Args:\n            entry: the entry to extract bits from\n            pos: the position of the bits\n            n: the number of bits to extract\n\n        Returns:\n            the extracted bits\n        \"\"\"\n        return (entry &gt;&gt; (32 - pos - n)) &amp; ((1 &lt;&lt; n) - 1)\n\n    @staticmethod\n    def extract_bits_big64(entry, pos, n):\n        \"\"\"Extract bits from an entry in big endian 64 bits\n\n        Args:\n            entry: the entry to extract bits from\n            pos: the position of the bits\n            n: the number of bits to extract\n\n        Returns:\n            the extracted bits\n        \"\"\"\n        return (entry &gt;&gt; (64 - pos - n)) &amp; ((1 &lt;&lt; n) - 1)\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.MMU.__init__","title":"<code>__init__(mmu_config)</code>","text":"<p>Initialize the MMU</p> <p>Parameters:</p> Name Type Description Default <code>mmu_config</code> <p>the configuration of the MMU</p> required Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def __init__(self, mmu_config):\n    \"\"\"Initialize the MMU\n\n    Args:\n        mmu_config: the configuration of the MMU\n    \"\"\"\n    self.mmu_config = mmu_config\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.MMU.extract_bits_big","title":"<code>extract_bits_big(entry, pos, n)</code>  <code>staticmethod</code>","text":"<p>Extract bits from an entry in big endian</p> <p>Parameters:</p> Name Type Description Default <code>entry</code> <p>the entry to extract bits from</p> required <code>pos</code> <p>the position of the bits</p> required <code>n</code> <p>the number of bits to extract</p> required <p>Returns:</p> Type Description <p>the extracted bits</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>@staticmethod\ndef extract_bits_big(entry, pos, n):\n    \"\"\"Extract bits from an entry in big endian\n\n    Args:\n        entry: the entry to extract bits from\n        pos: the position of the bits\n        n: the number of bits to extract\n\n    Returns:\n        the extracted bits\n    \"\"\"\n    return (entry &gt;&gt; (32 - pos - n)) &amp; ((1 &lt;&lt; n) - 1)\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.MMU.extract_bits_big64","title":"<code>extract_bits_big64(entry, pos, n)</code>  <code>staticmethod</code>","text":"<p>Extract bits from an entry in big endian 64 bits</p> <p>Parameters:</p> Name Type Description Default <code>entry</code> <p>the entry to extract bits from</p> required <code>pos</code> <p>the position of the bits</p> required <code>n</code> <p>the number of bits to extract</p> required <p>Returns:</p> Type Description <p>the extracted bits</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>@staticmethod\ndef extract_bits_big64(entry, pos, n):\n    \"\"\"Extract bits from an entry in big endian 64 bits\n\n    Args:\n        entry: the entry to extract bits from\n        pos: the position of the bits\n        n: the number of bits to extract\n\n    Returns:\n        the extracted bits\n    \"\"\"\n    return (entry &gt;&gt; (64 - pos - n)) &amp; ((1 &lt;&lt; n) - 1)\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.MMU.extract_bits_little","title":"<code>extract_bits_little(entry, pos, n)</code>  <code>staticmethod</code>","text":"<p>Extract bits from an entry in little endian</p> <p>Parameters:</p> Name Type Description Default <code>entry</code> <p>the entry to extract bits from</p> required <code>pos</code> <p>the position of the bits</p> required <code>n</code> <p>the number of bits to extract</p> required <p>Returns:</p> Type Description <p>the extracted bits</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>@staticmethod\ndef extract_bits_little(entry, pos, n):\n    \"\"\"Extract bits from an entry in little endian\n\n    Args:\n        entry: the entry to extract bits from\n        pos: the position of the bits\n        n: the number of bits to extract\n\n    Returns:\n        the extracted bits\n    \"\"\"\n    return (entry &gt;&gt; pos) &amp; ((1 &lt;&lt; n) - 1)\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.MMURadix","title":"<code>MMURadix</code>","text":"<p>             Bases: <code>MMU</code></p> <p>Represents a MMU that uses a Radix Tree</p> <p>Aimed to be inherited by child classes to represent different architectures</p> <p>Attributes:</p> Name Type Description <code>PAGE_SIZE</code> <p>the size of the page</p> <code>extract_bits</code> <p>the function to extract bits</p> <code>paging_unpack_format</code> <p>the format of the paging</p> <code>page_table_class</code> <p>the class of the page table</p> <code>radix_levels</code> <p>the levels of the radix tree</p> <code>top_prefix</code> <p>the top prefix of the radix tree</p> <code>entries_size</code> <p>the size of the entries</p> <code>map_ptr_entries_to_levels</code> <p>the mapping between pointer entries and levels</p> <code>map_datapages_entries_to_levels</code> <p>the mapping between data pages entries and levels</p> <code>map_level_to_table_size</code> <p>the mapping between levels and table sizes</p> <code>map_entries_to_shifts</code> <p>the mapping between entries and shifts</p> <code>map_reserved_entries_to_levels</code> <p>the mapping between reserved entries and levels</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>class MMURadix(MMU):\n    \"\"\"Represents a MMU that uses a Radix Tree\n\n    Aimed to be inherited by child classes to represent different architectures\n\n    Attributes:\n        PAGE_SIZE: the size of the page\n        extract_bits: the function to extract bits\n        paging_unpack_format: the format of the paging\n        page_table_class: the class of the page table\n        radix_levels: the levels of the radix tree\n        top_prefix: the top prefix of the radix tree\n        entries_size: the size of the entries\n        map_ptr_entries_to_levels: the mapping between pointer entries and levels\n        map_datapages_entries_to_levels: the mapping between data pages entries and levels\n        map_level_to_table_size: the mapping between levels and table sizes\n        map_entries_to_shifts: the mapping between entries and shifts\n        map_reserved_entries_to_levels: the mapping between reserved entries and levels\n    \"\"\"\n\n    PAGE_SIZE = 0\n    extract_bits = None\n    paging_unpack_format = \"\"\n    page_table_class = PageTable\n    radix_levels = {}\n    top_prefix = 0\n    entries_size = 0\n    map_ptr_entries_to_levels = {}\n    map_datapages_entries_to_levels = {}\n    map_level_to_table_size = {}\n    map_entries_to_shifts = {}\n    map_reserved_entries_to_levels = {}\n\n    def classify_entry(self, page_addr, entry):\n        \"\"\"Classify an entry\n\n        Aimed to be overloaded by child classes\n\n        Args:\n            page_addr: the address of the page\n            entry: the entry to classify\n\n        Returns:\n            the classified entry\n        \"\"\"\n        raise NotImplementedError\n\n    def derive_page_address(self, addr, mode=\"global\"):\n        \"\"\"Derive the addresses of pages containing the address\n\n        Args:\n            addr: the address to derive\n            mode: the mode to use\n\n        Returns:\n            the addresses of pages containing the address\n        \"\"\"\n        addrs = []\n        for lvl in range(self.radix_levels[mode] - 1, -1, -1):\n            for entry_class in self.map_datapages_entries_to_levels[mode][lvl]:\n                if entry_class is not None:\n                    shift = self.map_entries_to_shifts[mode][entry_class]\n                    addrs.append((lvl, (addr &gt;&gt; shift) &lt;&lt; shift))\n        return addrs\n\n    def parse_parallel_frame(\n        self, addresses, frame_size, pidx, mode=\"global\", **kwargs\n    ) -&gt; tuple:\n        \"\"\"Parse a frame in parallel\n\n        Every process sleep a random delay in order to desynchronise access to disk and maximixe the throuput\n\n        Args:\n            addresses: the addresses to parse\n            frame_size: the size of the frame\n            pidx: the process index\n            mode: the mode to use\n            **kwargs: additional arguments\n\n        Returns:\n            a tuple containing page tables, data pages and empty tables\n        \"\"\"\n        # Every process sleep a random delay in order to desynchronise access to disk and maximixe the throuput\n        sleep(uniform(pidx, pidx + 1) // 1000)\n\n        data_pages = []\n        empty_tables = []\n        page_tables = [{} for i in range(self.radix_levels[mode])]\n        mm = copy(self.machine.memory)\n        mm.reopen()\n\n        # Cicle over every frame\n        total_elems, iterator = addresses\n        for frame_addr in tqdm(\n            iterator, position=-pidx, total=total_elems, leave=False\n        ):\n            frame_buf = mm.get_data(frame_addr, frame_size)\n            invalids, pt_classes, table_obj = self.parse_frame(\n                frame_buf, frame_addr, frame_size\n            )\n\n            # It is a data page\n            if invalids or -2 in pt_classes:\n                data_pages.append(frame_addr)\n            elif -1 in pt_classes:\n                empty_tables.append(frame_addr)\n            else:\n                for pt_class in pt_classes:\n                    page_tables[pt_class][frame_addr] = table_obj\n\n        return page_tables, data_pages, empty_tables\n\n    def parse_frame(\n        self, frame_buf, frame_addr, frame_size, frame_level=-1, mode=\"global\"\n    ) -&gt; tuple:\n        \"\"\"Parse a frame\n\n        Args:\n            frame_buf: the buffer of the frame\n            frame_addr: the address of the frame\n            frame_size: the size of the frame\n            frame_level: the level of the frame\n            mode: the mode to use\n\n        Returns:\n            a tuple containing the number of invalids, the classes of the page tables and page table object\n        \"\"\"\n        frame_d = defaultdict(dict)\n        if frame_level &gt;= 0:\n            reseved_classes = self.machine.mmu.map_reserved_entries_to_levels[mode][\n                frame_level\n            ]\n            data_classes = self.machine.mmu.map_datapages_entries_to_levels[mode][\n                frame_level\n            ]\n            ptr_class = self.machine.mmu.map_ptr_entries_to_levels[mode][frame_level]\n            # frame_size = self.machine.mmu.map_level_to_table_size[mode][frame_level]\n\n        invalids = 0\n        empty_entries = 0\n        # Unpack records inside the frame\n        for entry_idx, entry in enumerate(\n            iter_unpack(self.paging_unpack_format, frame_buf)\n        ):\n            if (\n                frame_level &gt;= 0\n                and entry_idx * self.machine.mmu.entries_size &gt;= frame_size\n            ):\n                break\n\n            entry = entry[0]\n            # Classify the entry\n            entry_classes = self.classify_entry(frame_addr, entry)\n            # It's a data page\n            if entry_classes[0] is None:\n                if frame_level &gt;= 0:\n                    invalids += 1\n                    continue\n                else:\n                    break\n\n            # It's an empty page (data page or page table)\n            if entry_classes[0] is False:\n                empty_entries += 1\n                continue\n\n            # Add all records if scanning the memory or only the record of a particular level if it is creating a table to be print\n            if frame_level &lt; 0:\n                for entry_obj in entry_classes:\n                    entry_type = type(entry_obj)\n                    frame_d[entry_type][entry_idx] = entry_obj\n            else:\n                for entry_obj in entry_classes:\n                    entry_type = type(entry_obj)\n                    if (\n                        type(entry_obj) in data_classes\n                        or type(entry_obj) is ptr_class\n                        or type(entry_obj) in reseved_classes\n                    ):\n                        frame_d[entry_type][entry_idx] = entry_obj\n                        break\n                else:\n                    invalids += 1\n\n        # Classify the frame\n        pt_classes = self.classify_frame(\n            frame_d,\n            empty_entries,\n            int(frame_size // self.page_table_class.entry_size),\n            mode=mode,\n        )\n\n        if -1 in pt_classes or -2 in pt_classes:  # EMPTY or DATA\n            table_obj = None\n        else:\n            table_obj = self.page_table_class(\n                frame_addr, frame_size, frame_d, pt_classes\n            )\n        return invalids, pt_classes, table_obj\n\n    def classify_frame(\n        self,\n        frame_d,\n        empty_c,\n        entries_per_frame,\n        mode=\"global\",\n    ) -&gt; list:\n        \"\"\"Classify a frame\n\n        Args:\n            frame_d: the buffer of the frame\n            empty_c: the number of empty entries\n            entries_per_frame: the number of entries per frame\n            mode: the mode to use\n\n        Returns:\n            a list containing the classes of the page tables\n        \"\"\"\n        if empty_c == entries_per_frame:\n            return [-1]  # EMPTY\n\n        # For each level check if a table is a valid candidate\n        frame_classes = []\n        for level in range(self.radix_levels[mode]):\n            entries = empty_c\n            if self.map_ptr_entries_to_levels[mode][level] is not None:\n                entries += len(frame_d[self.map_ptr_entries_to_levels[mode][level]])\n            for data_class in self.map_datapages_entries_to_levels[mode][level]:\n                if data_class is not None:\n                    entries += len(frame_d[data_class])\n            for reserved_class in self.map_reserved_entries_to_levels[mode][level]:\n                entries += len(frame_d[reserved_class])\n            if entries == entries_per_frame:\n                frame_classes.append(level)\n\n        if not frame_classes:\n            return [-2]  # DATA\n        else:\n            return frame_classes\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.MMURadix.classify_entry","title":"<code>classify_entry(page_addr, entry)</code>","text":"<p>Classify an entry</p> <p>Aimed to be overloaded by child classes</p> <p>Parameters:</p> Name Type Description Default <code>page_addr</code> <p>the address of the page</p> required <code>entry</code> <p>the entry to classify</p> required <p>Returns:</p> Type Description <p>the classified entry</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def classify_entry(self, page_addr, entry):\n    \"\"\"Classify an entry\n\n    Aimed to be overloaded by child classes\n\n    Args:\n        page_addr: the address of the page\n        entry: the entry to classify\n\n    Returns:\n        the classified entry\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.MMURadix.classify_frame","title":"<code>classify_frame(frame_d, empty_c, entries_per_frame, mode='global')</code>","text":"<p>Classify a frame</p> <p>Parameters:</p> Name Type Description Default <code>frame_d</code> <p>the buffer of the frame</p> required <code>empty_c</code> <p>the number of empty entries</p> required <code>entries_per_frame</code> <p>the number of entries per frame</p> required <code>mode</code> <p>the mode to use</p> <code>'global'</code> <p>Returns:</p> Type Description <code>list</code> <p>a list containing the classes of the page tables</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def classify_frame(\n    self,\n    frame_d,\n    empty_c,\n    entries_per_frame,\n    mode=\"global\",\n) -&gt; list:\n    \"\"\"Classify a frame\n\n    Args:\n        frame_d: the buffer of the frame\n        empty_c: the number of empty entries\n        entries_per_frame: the number of entries per frame\n        mode: the mode to use\n\n    Returns:\n        a list containing the classes of the page tables\n    \"\"\"\n    if empty_c == entries_per_frame:\n        return [-1]  # EMPTY\n\n    # For each level check if a table is a valid candidate\n    frame_classes = []\n    for level in range(self.radix_levels[mode]):\n        entries = empty_c\n        if self.map_ptr_entries_to_levels[mode][level] is not None:\n            entries += len(frame_d[self.map_ptr_entries_to_levels[mode][level]])\n        for data_class in self.map_datapages_entries_to_levels[mode][level]:\n            if data_class is not None:\n                entries += len(frame_d[data_class])\n        for reserved_class in self.map_reserved_entries_to_levels[mode][level]:\n            entries += len(frame_d[reserved_class])\n        if entries == entries_per_frame:\n            frame_classes.append(level)\n\n    if not frame_classes:\n        return [-2]  # DATA\n    else:\n        return frame_classes\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.MMURadix.derive_page_address","title":"<code>derive_page_address(addr, mode='global')</code>","text":"<p>Derive the addresses of pages containing the address</p> <p>Parameters:</p> Name Type Description Default <code>addr</code> <p>the address to derive</p> required <code>mode</code> <p>the mode to use</p> <code>'global'</code> <p>Returns:</p> Type Description <p>the addresses of pages containing the address</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def derive_page_address(self, addr, mode=\"global\"):\n    \"\"\"Derive the addresses of pages containing the address\n\n    Args:\n        addr: the address to derive\n        mode: the mode to use\n\n    Returns:\n        the addresses of pages containing the address\n    \"\"\"\n    addrs = []\n    for lvl in range(self.radix_levels[mode] - 1, -1, -1):\n        for entry_class in self.map_datapages_entries_to_levels[mode][lvl]:\n            if entry_class is not None:\n                shift = self.map_entries_to_shifts[mode][entry_class]\n                addrs.append((lvl, (addr &gt;&gt; shift) &lt;&lt; shift))\n    return addrs\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.MMURadix.parse_frame","title":"<code>parse_frame(frame_buf, frame_addr, frame_size, frame_level=-1, mode='global')</code>","text":"<p>Parse a frame</p> <p>Parameters:</p> Name Type Description Default <code>frame_buf</code> <p>the buffer of the frame</p> required <code>frame_addr</code> <p>the address of the frame</p> required <code>frame_size</code> <p>the size of the frame</p> required <code>frame_level</code> <p>the level of the frame</p> <code>-1</code> <code>mode</code> <p>the mode to use</p> <code>'global'</code> <p>Returns:</p> Type Description <code>tuple</code> <p>a tuple containing the number of invalids, the classes of the page tables and page table object</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def parse_frame(\n    self, frame_buf, frame_addr, frame_size, frame_level=-1, mode=\"global\"\n) -&gt; tuple:\n    \"\"\"Parse a frame\n\n    Args:\n        frame_buf: the buffer of the frame\n        frame_addr: the address of the frame\n        frame_size: the size of the frame\n        frame_level: the level of the frame\n        mode: the mode to use\n\n    Returns:\n        a tuple containing the number of invalids, the classes of the page tables and page table object\n    \"\"\"\n    frame_d = defaultdict(dict)\n    if frame_level &gt;= 0:\n        reseved_classes = self.machine.mmu.map_reserved_entries_to_levels[mode][\n            frame_level\n        ]\n        data_classes = self.machine.mmu.map_datapages_entries_to_levels[mode][\n            frame_level\n        ]\n        ptr_class = self.machine.mmu.map_ptr_entries_to_levels[mode][frame_level]\n        # frame_size = self.machine.mmu.map_level_to_table_size[mode][frame_level]\n\n    invalids = 0\n    empty_entries = 0\n    # Unpack records inside the frame\n    for entry_idx, entry in enumerate(\n        iter_unpack(self.paging_unpack_format, frame_buf)\n    ):\n        if (\n            frame_level &gt;= 0\n            and entry_idx * self.machine.mmu.entries_size &gt;= frame_size\n        ):\n            break\n\n        entry = entry[0]\n        # Classify the entry\n        entry_classes = self.classify_entry(frame_addr, entry)\n        # It's a data page\n        if entry_classes[0] is None:\n            if frame_level &gt;= 0:\n                invalids += 1\n                continue\n            else:\n                break\n\n        # It's an empty page (data page or page table)\n        if entry_classes[0] is False:\n            empty_entries += 1\n            continue\n\n        # Add all records if scanning the memory or only the record of a particular level if it is creating a table to be print\n        if frame_level &lt; 0:\n            for entry_obj in entry_classes:\n                entry_type = type(entry_obj)\n                frame_d[entry_type][entry_idx] = entry_obj\n        else:\n            for entry_obj in entry_classes:\n                entry_type = type(entry_obj)\n                if (\n                    type(entry_obj) in data_classes\n                    or type(entry_obj) is ptr_class\n                    or type(entry_obj) in reseved_classes\n                ):\n                    frame_d[entry_type][entry_idx] = entry_obj\n                    break\n            else:\n                invalids += 1\n\n    # Classify the frame\n    pt_classes = self.classify_frame(\n        frame_d,\n        empty_entries,\n        int(frame_size // self.page_table_class.entry_size),\n        mode=mode,\n    )\n\n    if -1 in pt_classes or -2 in pt_classes:  # EMPTY or DATA\n        table_obj = None\n    else:\n        table_obj = self.page_table_class(\n            frame_addr, frame_size, frame_d, pt_classes\n        )\n    return invalids, pt_classes, table_obj\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.MMURadix.parse_parallel_frame","title":"<code>parse_parallel_frame(addresses, frame_size, pidx, mode='global', **kwargs)</code>","text":"<p>Parse a frame in parallel</p> <p>Every process sleep a random delay in order to desynchronise access to disk and maximixe the throuput</p> <p>Parameters:</p> Name Type Description Default <code>addresses</code> <p>the addresses to parse</p> required <code>frame_size</code> <p>the size of the frame</p> required <code>pidx</code> <p>the process index</p> required <code>mode</code> <p>the mode to use</p> <code>'global'</code> <code>**kwargs</code> <p>additional arguments</p> <code>{}</code> <p>Returns:</p> Type Description <code>tuple</code> <p>a tuple containing page tables, data pages and empty tables</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def parse_parallel_frame(\n    self, addresses, frame_size, pidx, mode=\"global\", **kwargs\n) -&gt; tuple:\n    \"\"\"Parse a frame in parallel\n\n    Every process sleep a random delay in order to desynchronise access to disk and maximixe the throuput\n\n    Args:\n        addresses: the addresses to parse\n        frame_size: the size of the frame\n        pidx: the process index\n        mode: the mode to use\n        **kwargs: additional arguments\n\n    Returns:\n        a tuple containing page tables, data pages and empty tables\n    \"\"\"\n    # Every process sleep a random delay in order to desynchronise access to disk and maximixe the throuput\n    sleep(uniform(pidx, pidx + 1) // 1000)\n\n    data_pages = []\n    empty_tables = []\n    page_tables = [{} for i in range(self.radix_levels[mode])]\n    mm = copy(self.machine.memory)\n    mm.reopen()\n\n    # Cicle over every frame\n    total_elems, iterator = addresses\n    for frame_addr in tqdm(\n        iterator, position=-pidx, total=total_elems, leave=False\n    ):\n        frame_buf = mm.get_data(frame_addr, frame_size)\n        invalids, pt_classes, table_obj = self.parse_frame(\n            frame_buf, frame_addr, frame_size\n        )\n\n        # It is a data page\n        if invalids or -2 in pt_classes:\n            data_pages.append(frame_addr)\n        elif -1 in pt_classes:\n            empty_tables.append(frame_addr)\n        else:\n            for pt_class in pt_classes:\n                page_tables[pt_class][frame_addr] = table_obj\n\n    return page_tables, data_pages, empty_tables\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.MMUShell","title":"<code>MMUShell</code>","text":"<p>             Bases: <code>Cmd</code></p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>class MMUShell(Cmd):\n    intro = \"MMUShell.   Type help or ? to list commands.\\n\"\n\n    def __init__(self, completekey=\"tab\", stdin=None, stdout=None, machine={}):\n        super(MMUShell, self).__init__(completekey, stdin, stdout)\n        self.machine = machine\n        self.prompt = \"[MMUShell \" + self.machine.cpu.architecture + \"]# \"\n        self.data = {}\n        self.gtruth = {}\n\n    def reload_data_from_file(self, data_filename):\n        # Load a previous session\n        logger.info(\"Loading previous session data...\")\n        try:\n            self.data = load(data_filename, compression=\"lzma\")\n        except Exception as e:\n            logger.fatal(\"Fatal error loading session data! Error:{}\".format(e))\n            import traceback\n\n            print(traceback.print_exc())\n            exit(1)\n\n    def load_gtruth(self, gtruth_fd):\n        try:\n            self.gtruth = Load(gtruth_fd)\n            gtruth_fd.close()\n        except Exception as e:\n            logger.fatal(\"Fatal error loading ground truth file! Error:{}\".format(e))\n            exit(1)\n\n    def do_exit(self, arg):\n        \"\"\"Exit :)\"\"\"\n        logger.info(\"Bye! :)\")\n        return True\n\n    def do_save_data(self, arg):\n        \"\"\"Save data in a compressed pickle file\"\"\"\n\n        if not len(arg):\n            logger.info(\"Use: save_data FILENAME\")\n            return\n\n        try:\n            logger.info(\"Saving data...\")\n            dump(self.data, arg, compression=\"lzma\")\n        except Exception as e:\n            logger.error(\"Error in session data. Error: {}\".format(e))\n            return\n\n    # def do_show_machine_config(self, arg):\n    #     \"\"\"Show the machine configuration\"\"\"\n    #     pprint(self.machine_config)\n\n    def do_ipython(self, arg):\n        \"\"\"Open an IPython shell\"\"\"\n        embed()\n\n    def emptyline(self):\n        pass\n\n    def parse_int(self, value):\n        if any([c not in \"0123456789abcdefxABCDEFX\" for c in value]):\n            raise ValueError\n        if value[:2].lower() == \"0x\":\n            return int(value, 16)\n        else:\n            return int(value, 10)\n\n    def radix_roots_from_data_page(\n        self, pg_lvl, pg_addr, rev_map_pages, rev_map_tables\n    ):\n        # For a page address pointed by tables of level 'level' find all the radix root of trees containing it\n\n        level_tables = set()\n        prev_level_tables = set()\n\n        # Collect all table at level 'pg_lvl' which point to that page\n        level_tables.update(rev_map_pages[pg_lvl][pg_addr])\n        logger.debug(\n            \"radix_roots_from_data_pages: level_tables found {} for pg_addr {}\".format(\n                len(level_tables), hex(pg_addr)\n            )\n        )\n\n        # Raise the tree in order to find the top table\n        for tree_lvl in range(pg_lvl - 1, -1, -1):\n            for table_addr in level_tables:\n                prev_level_tables.update(rev_map_tables[tree_lvl][table_addr])\n\n            level_tables = prev_level_tables\n            prev_level_tables = set()\n            logger.debug(\n                \"radix_roots_from_data_pages: level_tables found {} for pg_addr {}\".format(\n                    len(level_tables), hex(pg_addr)\n                )\n            )\n\n        return set(level_tables)\n\n    def physpace(\n        self,\n        addr,\n        page_tables,\n        empty_tables,\n        lvl=0,\n        uperms=(True,) * 6,\n        hierarchical=False,\n        mode=\"global\",\n        cache=defaultdict(dict),\n    ):\n        \"\"\"Recursively evaluate the consistency and return the kernel/user physical space addressed\"\"\"\n        pas = PAS()\n        data_classes = self.machine.mmu.map_datapages_entries_to_levels[mode][lvl]\n        logging.debug(f\"physpace() radix: {hex(addr)} Lvl: {lvl} Table: {hex(addr)}\")\n\n        # Leaf level\n        if lvl == self.machine.mmu.radix_levels[mode] - 1:\n            for data_class in data_classes:\n                for entry in page_tables[lvl][addr].entries[data_class].values():\n                    perms = entry.get_permissions()\n                    pas.space[perms][entry.address] = entry.size\n                    pas.space_size[perms] += entry.size\n\n            cache[lvl][addr] = (True, pas)\n            return True, pas\n\n        else:  # Superior levels\n            ptr_class = self.machine.mmu.map_ptr_entries_to_levels[mode][lvl]\n            if ptr_class in page_tables[lvl][addr].entries:\n                for entry in page_tables[lvl][addr].entries[ptr_class].values():\n                    if entry.address not in page_tables[lvl + 1]:\n                        if (\n                            entry.address not in empty_tables\n                        ):  # It is not an empty table!\n                            logging.debug(\n                                f\"physpace() radix: {hex(addr)} parent level: {lvl} table: {hex(entry.address)} invalid\"\n                            )\n                            cache[lvl][addr] = (False, None)\n                            return False, None\n                    else:\n                        if entry.address not in cache[lvl + 1]:\n                            low_cons, low_pas = self.physpace(\n                                entry.address,\n                                page_tables,\n                                empty_tables,\n                                lvl + 1,\n                                uperms=uperms,\n                                hierarchical=hierarchical,\n                                mode=mode,\n                                cache=cache,\n                            )\n                        else:\n                            low_cons, low_pas = cache[lvl + 1][entry.address]\n\n                        if not low_cons:\n                            logging.debug(\n                                f\"physpace() radix: {hex(addr)} parent level: {lvl} table: {hex(entry.address)} invalid\"\n                            )\n                            cache[lvl][addr] = (False, None)\n                            return False, None\n\n                        if hierarchical:\n                            pas.hierarchical_extend(low_pas, uperms)\n                        else:\n                            pas.hierarchical_extend(low_pas, (True,) * 6)\n\n            for data_class in data_classes:\n                if (\n                    data_class in page_tables[lvl][addr].entries\n                    and data_class is not None\n                ):\n                    for entry in page_tables[lvl][addr].entries[data_class].values():\n                        perms = entry.get_permissions()\n                        pas.space[perms][entry.address] = entry.size\n                        pas.space_size[perms] += entry.size\n\n            cache[lvl][addr] = (True, pas)\n            return True, pas\n\n    def resolve_vaddr(self, cr3, vaddr, mode=\"global\"):\n        # Return the paddr or -1\n\n        # Split in possible table resolution paths\n        for splitted_addr in self.machine.mmu.split_vaddr(vaddr):\n            current_table_addr = cr3\n            requested_steps = len(splitted_addr) - 1\n            resolution_steps = 0\n\n            for level_idx, idx_t in enumerate(splitted_addr[:-1]):\n                level_class, entry_idx = idx_t\n                # Missing valid table, no valid resolution path\n                if current_table_addr not in self.data.page_tables[\"global\"][level_idx]:\n                    logging.debug(\n                        f\"resolve_vaddr() Missing table {hex(current_table_addr)}\"\n                    )\n                    logging.debug(\"resolve_vaddr() RESOLUTION PATH FAILED! ########\")\n                    break\n\n                logging.debug(\n                    f\"resolve_vaddr(): Resolution path Lvl: {level_class} Table: {hex(current_table_addr)} Entry addr: {hex( current_table_addr + self.machine.mmu.page_table_class.entry_size * entry_idx)}\"\n                )\n                # Find valid entry in table\n                if (\n                    entry_idx\n                    in self.data.page_tables[\"global\"][level_idx][\n                        current_table_addr\n                    ].entries[level_class]\n                ):\n                    current_table_addr = (\n                        self.data.page_tables[\"global\"][level_idx][current_table_addr]\n                        .entries[level_class][entry_idx]\n                        .address\n                    )\n\n                    resolution_steps += 1\n\n                    # Each resolution path involves different number of steps (table to walk)\n                    if resolution_steps == requested_steps:\n                        return current_table_addr + splitted_addr[-1][1]\n                    else:\n                        continue\n                else:\n                    logging.debug(\"resolve_vaddr() RESOLUTION PATH FAILED! ########\")\n                    break\n        else:\n            return -1\n\n    def virtspace(\n        self,\n        addr,\n        lvl=0,\n        prefix=0,\n        uperms=(True,) * 6,\n        hierarchical=False,\n        mode=\"global\",\n        cache=defaultdict(dict),\n    ):\n        \"\"\"Recursively reconstruct virtual address space\"\"\"\n\n        virtspace = VAS()\n        data_classes = self.machine.mmu.map_datapages_entries_to_levels[mode][lvl]\n        ptr_class = self.machine.mmu.map_ptr_entries_to_levels[mode][lvl]\n        cache[lvl][addr] = defaultdict(portion.empty)\n\n        if lvl == self.machine.mmu.radix_levels[mode] - 1:\n            for data_class in data_classes:\n                shift = self.machine.mmu.map_entries_to_shifts[mode][data_class]\n                for entry_idx, entry in (\n                    self.data.page_tables[mode][lvl][addr].entries[data_class].items()\n                ):\n                    permissions = entry.get_permissions()\n                    virt_addr = prefix | (entry_idx &lt;&lt; shift)\n                    virtspace[permissions] |= portion.closedopen(\n                        virt_addr, virt_addr + entry.size\n                    )\n\n            cache[lvl][addr] = virtspace\n            return virtspace\n\n        else:\n            if ptr_class in self.data.page_tables[mode][lvl][addr].entries:\n                shift = self.machine.mmu.map_entries_to_shifts[mode][ptr_class]\n                for entry_idx, entry in (\n                    self.data.page_tables[mode][lvl][addr].entries[ptr_class].items()\n                ):\n                    if entry.address not in self.data.page_tables[mode][lvl + 1]:\n                        continue\n                    else:\n                        permissions = entry.get_permissions()\n\n                        if entry.address not in cache[lvl + 1]:\n                            virt_addr = prefix | (entry_idx &lt;&lt; shift)\n                            low_virts = self.virtspace(\n                                entry.address,\n                                lvl + 1,\n                                virt_addr,\n                                permissions,\n                                hierarchical=hierarchical,\n                                mode=mode,\n                                cache=cache,\n                            )\n                        else:\n                            low_virts = cache[lvl + 1][entry.address]\n\n                        if hierarchical:\n                            virtspace.hierarchical_extend(low_virts, uperms)\n                        else:\n                            virtspace.hierarchical_extend(low_virts, (True,) * 6)\n\n            for data_class in data_classes:\n                if (\n                    data_class in self.data.page_tables[mode][lvl][addr].entries\n                    and data_class is not None\n                ):\n                    shift = self.machine.mmu.map_entries_to_shifts[mode][data_class]\n                    for entry_idx, entry in (\n                        self.data.page_tables[mode][lvl][addr]\n                        .entries[data_class]\n                        .items()\n                    ):\n                        permissions = entry.get_permissions()\n                        virt_addr = prefix | (entry_idx &lt;&lt; shift)\n                        virtspace[permissions] |= portion.closedopen(\n                            virt_addr, virt_addr + entry.size\n                        )\n\n            cache[lvl][addr] = virtspace\n            return virtspace\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.MMUShell.do_exit","title":"<code>do_exit(arg)</code>","text":"<p>Exit :)</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def do_exit(self, arg):\n    \"\"\"Exit :)\"\"\"\n    logger.info(\"Bye! :)\")\n    return True\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.MMUShell.do_ipython","title":"<code>do_ipython(arg)</code>","text":"<p>Open an IPython shell</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def do_ipython(self, arg):\n    \"\"\"Open an IPython shell\"\"\"\n    embed()\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.MMUShell.do_save_data","title":"<code>do_save_data(arg)</code>","text":"<p>Save data in a compressed pickle file</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def do_save_data(self, arg):\n    \"\"\"Save data in a compressed pickle file\"\"\"\n\n    if not len(arg):\n        logger.info(\"Use: save_data FILENAME\")\n        return\n\n    try:\n        logger.info(\"Saving data...\")\n        dump(self.data, arg, compression=\"lzma\")\n    except Exception as e:\n        logger.error(\"Error in session data. Error: {}\".format(e))\n        return\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.MMUShell.physpace","title":"<code>physpace(addr, page_tables, empty_tables, lvl=0, uperms=(True) * 6, hierarchical=False, mode='global', cache=defaultdict(dict))</code>","text":"<p>Recursively evaluate the consistency and return the kernel/user physical space addressed</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def physpace(\n    self,\n    addr,\n    page_tables,\n    empty_tables,\n    lvl=0,\n    uperms=(True,) * 6,\n    hierarchical=False,\n    mode=\"global\",\n    cache=defaultdict(dict),\n):\n    \"\"\"Recursively evaluate the consistency and return the kernel/user physical space addressed\"\"\"\n    pas = PAS()\n    data_classes = self.machine.mmu.map_datapages_entries_to_levels[mode][lvl]\n    logging.debug(f\"physpace() radix: {hex(addr)} Lvl: {lvl} Table: {hex(addr)}\")\n\n    # Leaf level\n    if lvl == self.machine.mmu.radix_levels[mode] - 1:\n        for data_class in data_classes:\n            for entry in page_tables[lvl][addr].entries[data_class].values():\n                perms = entry.get_permissions()\n                pas.space[perms][entry.address] = entry.size\n                pas.space_size[perms] += entry.size\n\n        cache[lvl][addr] = (True, pas)\n        return True, pas\n\n    else:  # Superior levels\n        ptr_class = self.machine.mmu.map_ptr_entries_to_levels[mode][lvl]\n        if ptr_class in page_tables[lvl][addr].entries:\n            for entry in page_tables[lvl][addr].entries[ptr_class].values():\n                if entry.address not in page_tables[lvl + 1]:\n                    if (\n                        entry.address not in empty_tables\n                    ):  # It is not an empty table!\n                        logging.debug(\n                            f\"physpace() radix: {hex(addr)} parent level: {lvl} table: {hex(entry.address)} invalid\"\n                        )\n                        cache[lvl][addr] = (False, None)\n                        return False, None\n                else:\n                    if entry.address not in cache[lvl + 1]:\n                        low_cons, low_pas = self.physpace(\n                            entry.address,\n                            page_tables,\n                            empty_tables,\n                            lvl + 1,\n                            uperms=uperms,\n                            hierarchical=hierarchical,\n                            mode=mode,\n                            cache=cache,\n                        )\n                    else:\n                        low_cons, low_pas = cache[lvl + 1][entry.address]\n\n                    if not low_cons:\n                        logging.debug(\n                            f\"physpace() radix: {hex(addr)} parent level: {lvl} table: {hex(entry.address)} invalid\"\n                        )\n                        cache[lvl][addr] = (False, None)\n                        return False, None\n\n                    if hierarchical:\n                        pas.hierarchical_extend(low_pas, uperms)\n                    else:\n                        pas.hierarchical_extend(low_pas, (True,) * 6)\n\n        for data_class in data_classes:\n            if (\n                data_class in page_tables[lvl][addr].entries\n                and data_class is not None\n            ):\n                for entry in page_tables[lvl][addr].entries[data_class].values():\n                    perms = entry.get_permissions()\n                    pas.space[perms][entry.address] = entry.size\n                    pas.space_size[perms] += entry.size\n\n        cache[lvl][addr] = (True, pas)\n        return True, pas\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.MMUShell.virtspace","title":"<code>virtspace(addr, lvl=0, prefix=0, uperms=(True) * 6, hierarchical=False, mode='global', cache=defaultdict(dict))</code>","text":"<p>Recursively reconstruct virtual address space</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def virtspace(\n    self,\n    addr,\n    lvl=0,\n    prefix=0,\n    uperms=(True,) * 6,\n    hierarchical=False,\n    mode=\"global\",\n    cache=defaultdict(dict),\n):\n    \"\"\"Recursively reconstruct virtual address space\"\"\"\n\n    virtspace = VAS()\n    data_classes = self.machine.mmu.map_datapages_entries_to_levels[mode][lvl]\n    ptr_class = self.machine.mmu.map_ptr_entries_to_levels[mode][lvl]\n    cache[lvl][addr] = defaultdict(portion.empty)\n\n    if lvl == self.machine.mmu.radix_levels[mode] - 1:\n        for data_class in data_classes:\n            shift = self.machine.mmu.map_entries_to_shifts[mode][data_class]\n            for entry_idx, entry in (\n                self.data.page_tables[mode][lvl][addr].entries[data_class].items()\n            ):\n                permissions = entry.get_permissions()\n                virt_addr = prefix | (entry_idx &lt;&lt; shift)\n                virtspace[permissions] |= portion.closedopen(\n                    virt_addr, virt_addr + entry.size\n                )\n\n        cache[lvl][addr] = virtspace\n        return virtspace\n\n    else:\n        if ptr_class in self.data.page_tables[mode][lvl][addr].entries:\n            shift = self.machine.mmu.map_entries_to_shifts[mode][ptr_class]\n            for entry_idx, entry in (\n                self.data.page_tables[mode][lvl][addr].entries[ptr_class].items()\n            ):\n                if entry.address not in self.data.page_tables[mode][lvl + 1]:\n                    continue\n                else:\n                    permissions = entry.get_permissions()\n\n                    if entry.address not in cache[lvl + 1]:\n                        virt_addr = prefix | (entry_idx &lt;&lt; shift)\n                        low_virts = self.virtspace(\n                            entry.address,\n                            lvl + 1,\n                            virt_addr,\n                            permissions,\n                            hierarchical=hierarchical,\n                            mode=mode,\n                            cache=cache,\n                        )\n                    else:\n                        low_virts = cache[lvl + 1][entry.address]\n\n                    if hierarchical:\n                        virtspace.hierarchical_extend(low_virts, uperms)\n                    else:\n                        virtspace.hierarchical_extend(low_virts, (True,) * 6)\n\n        for data_class in data_classes:\n            if (\n                data_class in self.data.page_tables[mode][lvl][addr].entries\n                and data_class is not None\n            ):\n                shift = self.machine.mmu.map_entries_to_shifts[mode][data_class]\n                for entry_idx, entry in (\n                    self.data.page_tables[mode][lvl][addr]\n                    .entries[data_class]\n                    .items()\n                ):\n                    permissions = entry.get_permissions()\n                    virt_addr = prefix | (entry_idx &lt;&lt; shift)\n                    virtspace[permissions] |= portion.closedopen(\n                        virt_addr, virt_addr + entry.size\n                    )\n\n        cache[lvl][addr] = virtspace\n        return virtspace\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.Machine","title":"<code>Machine</code>","text":"<p>Represents a generic machine</p> <p>A machine is composed by a CPU, a MMU and a memory. It is able to parse the memory in parallel and to extract the dataflow of the registers.</p> <p>Attributes:</p> Name Type Description <code>cpu</code> <p>the CPU of the machine</p> <code>mmu</code> <p>the MMU of the machine</p> <code>memory</code> <p>the memory of the machine</p> <code>gtruth</code> <p>the ground truth of the machine</p> <code>data</code> <p>the data of the machine</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>class Machine:\n    \"\"\"Represents a generic machine\n\n    A machine is composed by a CPU, a MMU and a memory. It is able to parse the memory in parallel and to extract the dataflow of the registers.\n\n    Attributes:\n        cpu: the CPU of the machine\n        mmu: the MMU of the machine\n        memory: the memory of the machine\n        gtruth: the ground truth of the machine\n        data: the data of the machine\n    \"\"\"\n\n    @classmethod\n    def from_machine_config(cls, machine_config, **kwargs):\n        \"\"\"Create a machine starting from a YAML file descriptor\n\n        Args:\n            machine_config: the YAML file descriptor\n            **kwargs: additional arguments\n\n        Returns:\n            a new Machine object\n        \"\"\"\n        # Check no intersection between memory regions\n        ram_portion = portion.empty()\n        for region_dict in machine_config[\"memspace\"][\"ram\"]:\n            region_portion = portion.closed(region_dict[\"start\"], region_dict[\"end\"])\n            if not ram_portion.intersection(region_portion).empty:\n                logger.fatal(\"RAM regions overlapping!\")\n                exit(1)\n            ram_portion = ram_portion.union(region_portion)\n\n        # Module to use\n        architecture_module = importlib.import_module(\n            \"architectures.\" + machine_config[\"cpu\"][\"architecture\"]\n        )\n\n        # Create CPU\n        cpu = architecture_module.CPU.from_cpu_config(machine_config[\"cpu\"])\n\n        # Create MMU\n        try:\n            mmu_class = getattr(\n                architecture_module, machine_config[\"mmu\"][\"mode\"].upper()\n            )\n        except AttributeError:\n            logger.fatal(\"Unknown MMU mode!\")\n            exit(1)\n        mmu = mmu_class(machine_config[\"mmu\"])\n\n        # Create RAM\n        memory = architecture_module.PhysicalMemory(machine_config[\"memspace\"])\n\n        return architecture_module.Machine(cpu, mmu, memory, **kwargs)\n\n    def __init__(self, cpu, mmu, memory, **kwargs):\n        \"\"\"Initialize the Machine\n\n        Args:\n            cpu: the CPU of the machine\n            mmu: the MMU of the machine\n            memory: the memory of the machine\n            **kwargs: additional arguments\n        \"\"\"\n        self.cpu = cpu\n        self.mmu = mmu\n        self.memory = memory\n        self.gtruth = {}\n        self.data = None\n        self.cpu.machine = self\n        self.mmu.machine = self\n        self.memory.machine = self\n\n    def get_miasm_machine(self):\n        \"\"\"Get the Miasm machine\n\n        Aimed to be overloaded by child classes\n\n        Returns:\n            the Miasm machine\n        \"\"\"\n        return None\n\n    def __del__(self):\n        self.memory.close()\n\n    def apply_parallel(\n        self, frame_size, parallel_func, iterators=None, max_address=-1, **kwargs\n    ) -&gt; list:\n        \"\"\"Run parallel_func using multiple core to frame_size chunks of RAM or iterators arguments\n\n        Only used in child classes for parsing memory\n\n        Args:\n            frame_size: the size of the frame to parse\n            parallel_func: the function to run in parallel\n            iterators: the iterators to use\n            max_address: the maximum address to parse\n            **kwargs: additional arguments\n\n        Returns:\n            a list of the results of parallel_func\n        \"\"\"\n\n        # Prepare the pool\n        logger.info(\"Parsing memory...\")\n        cpus = mp.cpu_count()\n        pool = mp.Pool(cpus, initializer=tqdm.set_lock, initargs=(mp.Lock(),))\n\n        if iterators is None:\n            # Create iterators for parallel execution\n            _, addresses_iterators = self.memory.get_addresses(\n                frame_size, cpus=cpus, max_address=max_address\n            )\n        else:\n            addresses_iterators = iterators\n\n        # GO!\n        parsing_results_async = [\n            pool.apply_async(\n                parallel_func, args=(addresses_iterator, frame_size, pidx), kwds=kwargs\n            )\n            for pidx, addresses_iterator in enumerate(addresses_iterators)\n        ]\n        pool.close()\n        pool.join()\n\n        print(\"\\n\")  # Workaround for tqdm\n\n        return parsing_results_async\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.Machine.__init__","title":"<code>__init__(cpu, mmu, memory, **kwargs)</code>","text":"<p>Initialize the Machine</p> <p>Parameters:</p> Name Type Description Default <code>cpu</code> <p>the CPU of the machine</p> required <code>mmu</code> <p>the MMU of the machine</p> required <code>memory</code> <p>the memory of the machine</p> required <code>**kwargs</code> <p>additional arguments</p> <code>{}</code> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def __init__(self, cpu, mmu, memory, **kwargs):\n    \"\"\"Initialize the Machine\n\n    Args:\n        cpu: the CPU of the machine\n        mmu: the MMU of the machine\n        memory: the memory of the machine\n        **kwargs: additional arguments\n    \"\"\"\n    self.cpu = cpu\n    self.mmu = mmu\n    self.memory = memory\n    self.gtruth = {}\n    self.data = None\n    self.cpu.machine = self\n    self.mmu.machine = self\n    self.memory.machine = self\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.Machine.apply_parallel","title":"<code>apply_parallel(frame_size, parallel_func, iterators=None, max_address=-1, **kwargs)</code>","text":"<p>Run parallel_func using multiple core to frame_size chunks of RAM or iterators arguments</p> <p>Only used in child classes for parsing memory</p> <p>Parameters:</p> Name Type Description Default <code>frame_size</code> <p>the size of the frame to parse</p> required <code>parallel_func</code> <p>the function to run in parallel</p> required <code>iterators</code> <p>the iterators to use</p> <code>None</code> <code>max_address</code> <p>the maximum address to parse</p> <code>-1</code> <code>**kwargs</code> <p>additional arguments</p> <code>{}</code> <p>Returns:</p> Type Description <code>list</code> <p>a list of the results of parallel_func</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def apply_parallel(\n    self, frame_size, parallel_func, iterators=None, max_address=-1, **kwargs\n) -&gt; list:\n    \"\"\"Run parallel_func using multiple core to frame_size chunks of RAM or iterators arguments\n\n    Only used in child classes for parsing memory\n\n    Args:\n        frame_size: the size of the frame to parse\n        parallel_func: the function to run in parallel\n        iterators: the iterators to use\n        max_address: the maximum address to parse\n        **kwargs: additional arguments\n\n    Returns:\n        a list of the results of parallel_func\n    \"\"\"\n\n    # Prepare the pool\n    logger.info(\"Parsing memory...\")\n    cpus = mp.cpu_count()\n    pool = mp.Pool(cpus, initializer=tqdm.set_lock, initargs=(mp.Lock(),))\n\n    if iterators is None:\n        # Create iterators for parallel execution\n        _, addresses_iterators = self.memory.get_addresses(\n            frame_size, cpus=cpus, max_address=max_address\n        )\n    else:\n        addresses_iterators = iterators\n\n    # GO!\n    parsing_results_async = [\n        pool.apply_async(\n            parallel_func, args=(addresses_iterator, frame_size, pidx), kwds=kwargs\n        )\n        for pidx, addresses_iterator in enumerate(addresses_iterators)\n    ]\n    pool.close()\n    pool.join()\n\n    print(\"\\n\")  # Workaround for tqdm\n\n    return parsing_results_async\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.Machine.from_machine_config","title":"<code>from_machine_config(machine_config, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a machine starting from a YAML file descriptor</p> <p>Parameters:</p> Name Type Description Default <code>machine_config</code> <p>the YAML file descriptor</p> required <code>**kwargs</code> <p>additional arguments</p> <code>{}</code> <p>Returns:</p> Type Description <p>a new Machine object</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>@classmethod\ndef from_machine_config(cls, machine_config, **kwargs):\n    \"\"\"Create a machine starting from a YAML file descriptor\n\n    Args:\n        machine_config: the YAML file descriptor\n        **kwargs: additional arguments\n\n    Returns:\n        a new Machine object\n    \"\"\"\n    # Check no intersection between memory regions\n    ram_portion = portion.empty()\n    for region_dict in machine_config[\"memspace\"][\"ram\"]:\n        region_portion = portion.closed(region_dict[\"start\"], region_dict[\"end\"])\n        if not ram_portion.intersection(region_portion).empty:\n            logger.fatal(\"RAM regions overlapping!\")\n            exit(1)\n        ram_portion = ram_portion.union(region_portion)\n\n    # Module to use\n    architecture_module = importlib.import_module(\n        \"architectures.\" + machine_config[\"cpu\"][\"architecture\"]\n    )\n\n    # Create CPU\n    cpu = architecture_module.CPU.from_cpu_config(machine_config[\"cpu\"])\n\n    # Create MMU\n    try:\n        mmu_class = getattr(\n            architecture_module, machine_config[\"mmu\"][\"mode\"].upper()\n        )\n    except AttributeError:\n        logger.fatal(\"Unknown MMU mode!\")\n        exit(1)\n    mmu = mmu_class(machine_config[\"mmu\"])\n\n    # Create RAM\n    memory = architecture_module.PhysicalMemory(machine_config[\"memspace\"])\n\n    return architecture_module.Machine(cpu, mmu, memory, **kwargs)\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.Machine.get_miasm_machine","title":"<code>get_miasm_machine()</code>","text":"<p>Get the Miasm machine</p> <p>Aimed to be overloaded by child classes</p> <p>Returns:</p> Type Description <p>the Miasm machine</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def get_miasm_machine(self):\n    \"\"\"Get the Miasm machine\n\n    Aimed to be overloaded by child classes\n\n    Returns:\n        the Miasm machine\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PAS","title":"<code>PAS</code>  <code>dataclass</code>","text":"<p>Represents a Physical Address Space</p> <p>The Physical Address Space (PAS) is a hierarchical data structure that represents the SAS of the physical memory. The PAS is composed of a set of entries, each one representing a set of contiguous physical addresses with the same permissions. The PAS is organized in a hierarchical way, where each entry is identified by a set of permissions and contains a set of intervals of contiguous physical addresses.</p> <p>Attributes:</p> Name Type Description <code>space</code> <code>Dict</code> <p>the space of the PAS</p> <code>space_size</code> <code>Dict</code> <p>the size of the space</p> <p>Note: those attributes are initialized as defaultdicts to avoid the need of checking if a key is present before accessing it</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>@dataclass\nclass PAS:\n    \"\"\"Represents a Physical Address Space\n\n    The Physical Address Space (PAS) is a hierarchical data structure that represents the SAS of the physical memory.\n    The PAS is composed of a set of entries, each one representing a set of contiguous physical addresses with the same permissions.\n    The PAS is organized in a hierarchical way, where each entry is identified by a set of permissions and contains a set of intervals of contiguous physical addresses.\n\n    Attributes:\n        space: the space of the PAS\n        space_size: the size of the space\n\n    Note: those attributes are initialized as defaultdicts to avoid the need of checking if a key is present before accessing it\n    \"\"\"\n\n    space: Dict = field(default_factory=lambda: defaultdict(dict))\n    space_size: Dict = field(default_factory=lambda: defaultdict(int))\n\n    def hierarchical_extend(self, other, uperms):\n        \"\"\"Extend this PAS with another PAS\n\n        Args:\n            other: the other PAS to extend with\n            uperms: the permissions to use\n        \"\"\"\n        for perm in other.space:\n            new_perm = []\n            for i in range(6):\n                new_perm.append(perm[i] and uperms[i])\n            new_perm = tuple(new_perm)\n            self.space[new_perm].update(other.space[perm])\n            self.space_size[new_perm] += other.space_size[perm]\n\n    def __contains__(self, key):\n        \"\"\"Check if a key is present in the PAS\n\n        Args:\n            key: the key to check\n\n        Returns:\n            True if the key is present, False otherwise\n        \"\"\"\n        for addresses in self.space.values():\n            for address in addresses:\n                if address &lt;= key &lt; address + addresses[address]:\n                    return True\n        return False\n\n    def is_in_kernel_space(self, key):\n        \"\"\"Check if a key is in the kernel space\n\n        Args:\n            key: the key to check\n\n        Returns:\n            True if the key is in the kernel space, False otherwise\n        \"\"\"\n        for perms, addresses in self.space.items():\n            if perms[0] or perms[1] or perms[2]:\n                for address in addresses:\n                    if address &lt;= key &lt; address + addresses[address]:\n                        return True\n        return False\n\n    def is_in_kernel_x_space(self, key):\n        \"\"\"Check if a key is in the kernel executable space\n\n        Args:\n            key: the key to check\n\n        Returns:\n            True if the key is in the kernel executable space, False otherwise\n        \"\"\"\n        for perms, addresses in self.space.items():\n            if perms[0] and perms[2]:\n                for address in addresses:\n                    if address &lt;= key &lt; address + addresses[address]:\n                        return True\n        return False\n\n    def is_in_user_space(self, key):\n        \"\"\"Check if a key is in the user space\n\n        Args:\n            key: the key to check\n\n        Returns:\n            True if the key is in the user space, False otherwise\n        \"\"\"\n        for perms, addresses in self.space.items():\n            if not (perms[0] or perms[1] or perms[2]):\n                for address in addresses:\n                    if address &lt;= key &lt; address + addresses[address]:\n                        return True\n        return False\n\n    def __repr__(self):\n        \"\"\"String representation of the PAS\"\"\"\n        ret = \"\"\n        for perm in self.space:\n            symb = lambda x, s: s if x else \"-\"\n            ret += \"{}{}{} {}{}{}: {}\\n\".format(\n                symb(perm[0], \"R\"),\n                symb(perm[1], \"W\"),\n                symb(perm[2], \"X\"),\n                symb(perm[3], \"R\"),\n                symb(perm[4], \"W\"),\n                symb(perm[5], \"X\"),\n                self.space_size[perm],\n            )\n        return ret\n\n    def get_kernel_size(self):\n        \"\"\"Get the size of the kernel space\"\"\"\n        size = 0\n        for perm in self.space:\n            if not (perm[3] or perm[4] or perm[5]):\n                size += self.space_size[perm]\n        return size\n\n    def get_user_size(self):\n        \"\"\"Get the size of the user space\"\"\"\n        size = 0\n        for perm in self.space:\n            if perm[3] or perm[4] or perm[5]:\n                size += self.space_size[perm]\n        return size\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PAS.__contains__","title":"<code>__contains__(key)</code>","text":"<p>Check if a key is present in the PAS</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <p>the key to check</p> required <p>Returns:</p> Type Description <p>True if the key is present, False otherwise</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def __contains__(self, key):\n    \"\"\"Check if a key is present in the PAS\n\n    Args:\n        key: the key to check\n\n    Returns:\n        True if the key is present, False otherwise\n    \"\"\"\n    for addresses in self.space.values():\n        for address in addresses:\n            if address &lt;= key &lt; address + addresses[address]:\n                return True\n    return False\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PAS.__repr__","title":"<code>__repr__()</code>","text":"<p>String representation of the PAS</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def __repr__(self):\n    \"\"\"String representation of the PAS\"\"\"\n    ret = \"\"\n    for perm in self.space:\n        symb = lambda x, s: s if x else \"-\"\n        ret += \"{}{}{} {}{}{}: {}\\n\".format(\n            symb(perm[0], \"R\"),\n            symb(perm[1], \"W\"),\n            symb(perm[2], \"X\"),\n            symb(perm[3], \"R\"),\n            symb(perm[4], \"W\"),\n            symb(perm[5], \"X\"),\n            self.space_size[perm],\n        )\n    return ret\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PAS.get_kernel_size","title":"<code>get_kernel_size()</code>","text":"<p>Get the size of the kernel space</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def get_kernel_size(self):\n    \"\"\"Get the size of the kernel space\"\"\"\n    size = 0\n    for perm in self.space:\n        if not (perm[3] or perm[4] or perm[5]):\n            size += self.space_size[perm]\n    return size\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PAS.get_user_size","title":"<code>get_user_size()</code>","text":"<p>Get the size of the user space</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def get_user_size(self):\n    \"\"\"Get the size of the user space\"\"\"\n    size = 0\n    for perm in self.space:\n        if perm[3] or perm[4] or perm[5]:\n            size += self.space_size[perm]\n    return size\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PAS.hierarchical_extend","title":"<code>hierarchical_extend(other, uperms)</code>","text":"<p>Extend this PAS with another PAS</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>the other PAS to extend with</p> required <code>uperms</code> <p>the permissions to use</p> required Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def hierarchical_extend(self, other, uperms):\n    \"\"\"Extend this PAS with another PAS\n\n    Args:\n        other: the other PAS to extend with\n        uperms: the permissions to use\n    \"\"\"\n    for perm in other.space:\n        new_perm = []\n        for i in range(6):\n            new_perm.append(perm[i] and uperms[i])\n        new_perm = tuple(new_perm)\n        self.space[new_perm].update(other.space[perm])\n        self.space_size[new_perm] += other.space_size[perm]\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PAS.is_in_kernel_space","title":"<code>is_in_kernel_space(key)</code>","text":"<p>Check if a key is in the kernel space</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <p>the key to check</p> required <p>Returns:</p> Type Description <p>True if the key is in the kernel space, False otherwise</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def is_in_kernel_space(self, key):\n    \"\"\"Check if a key is in the kernel space\n\n    Args:\n        key: the key to check\n\n    Returns:\n        True if the key is in the kernel space, False otherwise\n    \"\"\"\n    for perms, addresses in self.space.items():\n        if perms[0] or perms[1] or perms[2]:\n            for address in addresses:\n                if address &lt;= key &lt; address + addresses[address]:\n                    return True\n    return False\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PAS.is_in_kernel_x_space","title":"<code>is_in_kernel_x_space(key)</code>","text":"<p>Check if a key is in the kernel executable space</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <p>the key to check</p> required <p>Returns:</p> Type Description <p>True if the key is in the kernel executable space, False otherwise</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def is_in_kernel_x_space(self, key):\n    \"\"\"Check if a key is in the kernel executable space\n\n    Args:\n        key: the key to check\n\n    Returns:\n        True if the key is in the kernel executable space, False otherwise\n    \"\"\"\n    for perms, addresses in self.space.items():\n        if perms[0] and perms[2]:\n            for address in addresses:\n                if address &lt;= key &lt; address + addresses[address]:\n                    return True\n    return False\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PAS.is_in_user_space","title":"<code>is_in_user_space(key)</code>","text":"<p>Check if a key is in the user space</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <p>the key to check</p> required <p>Returns:</p> Type Description <p>True if the key is in the user space, False otherwise</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def is_in_user_space(self, key):\n    \"\"\"Check if a key is in the user space\n\n    Args:\n        key: the key to check\n\n    Returns:\n        True if the key is in the user space, False otherwise\n    \"\"\"\n    for perms, addresses in self.space.items():\n        if not (perms[0] or perms[1] or perms[2]):\n            for address in addresses:\n                if address &lt;= key &lt; address + addresses[address]:\n                    return True\n    return False\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PageTable","title":"<code>PageTable</code>","text":"<p>Represents a Page Table</p> <p>A page table is the data structure used by a virtual memory system in a computer operating system to store the mapping between virtual addresses and physical addresses.</p> <p>Aimed to be inherited by child classes to represent different architectures</p> <p>Attributes:</p> Name Type Description <code>address</code> <p>the address of the page table</p> <code>size</code> <p>the size of the page table</p> <code>entries</code> <p>the entries of the page table</p> <code>levels</code> <p>the levels of the page table</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>class PageTable:\n    \"\"\"Represents a Page Table\n\n    A page table is the data structure used by a virtual memory system in a computer operating system to store the mapping between virtual addresses and physical addresses.\n\n    Aimed to be inherited by child classes to represent different architectures\n\n    Attributes:\n        address: the address of the page table\n        size: the size of the page table\n        entries: the entries of the page table\n        levels: the levels of the page table\n    \"\"\"\n\n    entry_size = 0\n\n    def __init__(self, address, size, entries, levels, *args):\n        \"\"\"Initialize the Page Table\n\n        Args:\n            address: the address of the page table\n            size: the size of the page table\n            entries: the entries of the page table\n            levels: the levels of the page table\n            *args: additional arguments\n        \"\"\"\n        self.address = address\n        self.size = size\n        self.entries = entries\n        self.levels = levels\n\n    def apply_on_entries(self, f: function, args):\n        \"\"\"Run a function to all the entries of the page table.\n\n        The provided function should take an entry and the arguments as input and return the result of the operation.\n\n        Args:\n            f: the function to apply\n            args: the arguments to pass to the function\n\n        Returns:\n            a list with the results of the function applied to all the entries\n        \"\"\"\n        res = []\n        for entry in self.entries:\n            res.append(f(entry, args))\n        return res\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PageTable.__init__","title":"<code>__init__(address, size, entries, levels, *args)</code>","text":"<p>Initialize the Page Table</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <p>the address of the page table</p> required <code>size</code> <p>the size of the page table</p> required <code>entries</code> <p>the entries of the page table</p> required <code>levels</code> <p>the levels of the page table</p> required <code>*args</code> <p>additional arguments</p> <code>()</code> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def __init__(self, address, size, entries, levels, *args):\n    \"\"\"Initialize the Page Table\n\n    Args:\n        address: the address of the page table\n        size: the size of the page table\n        entries: the entries of the page table\n        levels: the levels of the page table\n        *args: additional arguments\n    \"\"\"\n    self.address = address\n    self.size = size\n    self.entries = entries\n    self.levels = levels\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PageTable.apply_on_entries","title":"<code>apply_on_entries(f, args)</code>","text":"<p>Run a function to all the entries of the page table.</p> <p>The provided function should take an entry and the arguments as input and return the result of the operation.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <code>function</code> <p>the function to apply</p> required <code>args</code> <p>the arguments to pass to the function</p> required <p>Returns:</p> Type Description <p>a list with the results of the function applied to all the entries</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def apply_on_entries(self, f: function, args):\n    \"\"\"Run a function to all the entries of the page table.\n\n    The provided function should take an entry and the arguments as input and return the result of the operation.\n\n    Args:\n        f: the function to apply\n        args: the arguments to pass to the function\n\n    Returns:\n        a list with the results of the function applied to all the entries\n    \"\"\"\n    res = []\n    for entry in self.entries:\n        res.append(f(entry, args))\n    return res\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PhysicalMemory","title":"<code>PhysicalMemory</code>","text":"<p>Represents the physical memory of a machine</p> <p>The physical memory is composed by a set of memory regions, each one representing a set of contiguous physical addresses with the same permissions.</p> <p>Attributes:</p> Name Type Description <code>_is_opened</code> <p>a flag to check if the memory is opened</p> <code>_miasm_vm</code> <p>the Miasm VM</p> <code>_memregions</code> <p>the memory regions</p> <code>_memsize</code> <p>the size of the memory</p> <code>physpace</code> <p>the physical space</p> <code>raw_configuration</code> <p>the raw configuration of the memory</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>class PhysicalMemory:\n    \"\"\"Represents the physical memory of a machine\n\n    The physical memory is composed by a set of memory regions, each one representing a set of contiguous physical addresses with the same permissions.\n\n    Attributes:\n        _is_opened: a flag to check if the memory is opened\n        _miasm_vm: the Miasm VM\n        _memregions: the memory regions\n        _memsize: the size of the memory\n        physpace: the physical space\n        raw_configuration: the raw configuration of the memory\n    \"\"\"\n\n    machine = None\n\n    def __deepcopy__(self, memo):\n        \"\"\"Deepcopy the PhysicalMemory object\"\"\"\n        return PhysicalMemory(self.raw_configuration)\n\n    def __copy__(self):\n        \"\"\"Copy the PhysicalMemory object\"\"\"\n        return PhysicalMemory(self.raw_configuration)\n\n    def __getstate__(self):\n        \"\"\"Get the state of the PhysicalMemory object\"\"\"\n        self.close()\n        if self._miasm_vm:\n            del self._miasm_vm\n            self._miasm_vm = None\n        state = deepcopy(self.__dict__)\n        self.reopen()\n        return state\n\n    def __setstate__(self, state):\n        \"\"\"Set the state of the PhysicalMemory object\"\"\"\n        self.__dict__.update(state)\n        self.reopen()\n\n    def __init__(self, regions_defs):\n        \"\"\"Initialize the PhysicalMemory\n\n        Args:\n            regions_defs: the regions definitions\n        \"\"\"\n        self._is_opened = False\n        self._miasm_vm = None\n        self._memregions = []\n        self._memsize = 0\n        self.physpace = {\"ram\": portion.empty(), \"not_ram\": portion.empty()}\n        self.raw_configuration = regions_defs\n\n        # Load dump RAM files\n        try:\n            for region_def in regions_defs[\"ram\"]:\n                # Load the dump file for a memory region\n                fd = open(region_def[\"dumpfile\"], \"rb\")\n                mm = mmap(fd.fileno(), 0, MAP_SHARED, PROT_READ)\n                mm.madvise(MADV_HUGEPAGE)\n                self._memsize += len(mm)\n                region_size = len(mm)\n\n                if region_size != region_def[\"end\"] - region_def[\"start\"] + 1:\n                    raise IOError(\n                        \"Declared size {} is different from real size {} for: {}\".format(\n                            region_def[\"end\"] - region_def[\"start\"] + 1,\n                            region_size,\n                            region_def[\"dumpfile\"],\n                        )\n                    )\n\n                self._memregions.append(\n                    {\n                        \"filename\": region_def[\"dumpfile\"],\n                        \"fd\": fd,\n                        \"mmap\": mm,\n                        \"size\": region_size,\n                        \"start\": region_def[\"start\"],\n                        \"end\": region_def[\"end\"],\n                    }\n                )\n                self.physpace[\"ram\"] |= portion.closed(\n                    region_def[\"start\"], region_def[\"end\"]\n                )\n\n            self._memregions.sort(key=lambda x: x[\"start\"])\n            self._is_opened = True\n\n        except Exception as e:\n            self.close()\n            raise IOError(\"Error in opening dump files! Error: {}\".format(e))\n\n        # Load not RAM regions\n        for region_def in regions_defs.get(\"not_ram\", []):\n            self.physpace[\"not_ram\"] |= portion.closed(\n                region_def[\"start\"], region_def[\"end\"]\n            )\n        self.physpace[\"not_valid_regions\"] = self.physpace[\"not_ram\"].difference(\n            self.physpace[\"ram\"]\n        )\n        self.physpace[\"defined_regions\"] = (\n            self.physpace[\"not_ram\"] | self.physpace[\"ram\"]\n        )\n\n    def __del__(self):\n        self.close()\n\n    def __len__(self):\n        \"\"\"Get the size of the memory\"\"\"\n        return self._memsize\n\n    def __contains__(self, key):\n        \"\"\"Check if a key is in the memory\"\"\"\n        if not isinstance(key, int):\n            raise TypeError\n        return key in self.physpace[\"ram\"]\n\n    def close(self):\n        \"\"\"Close the memory\"\"\"\n        for region in self._memregions:\n            try:\n                if region[\"mmap\"] is not None:\n                    region[\"mmap\"].close()\n                    del region[\"mmap\"]\n                    region[\"mmap\"] = None\n                if region[\"fd\"] is not None:\n                    region[\"fd\"].close()\n                    del region[\"fd\"]\n                    region[\"fd\"] = None\n            except Exception:\n                continue\n        self._is_opened = False\n\n    def reopen(self):\n        \"\"\"Reopen the memory\"\"\"\n        for region in self._memregions:\n            region[\"fd\"] = open(region[\"filename\"], \"rb\")\n            region[\"mmap\"] = mmap(region[\"fd\"].fileno(), 0, MAP_SHARED, PROT_READ)\n            region[\"mmap\"].madvise(MADV_HUGEPAGE)\n        self._is_opened = True\n\n    def get_data(self, start, size):\n        \"\"\"Get data from the memory\"\"\"\n        for region in self._memregions:\n            if region[\"start\"] &lt;= start &lt;= region[\"end\"]:\n                return region[\"mmap\"][\n                    start - region[\"start\"] : start - region[\"start\"] + size\n                ]\n        return bytearray()\n\n    def get_addresses(self, size, align_offset=0, cpus=1, max_address=-1):\n        \"\"\"Get the addresses of the memory\n\n        Return a list contains tuples (for a total of cpus tuples).\n        Each tuple contains the len of the iterator, and an iterator over part of all the addresses aligned to align_offset and distanced by size present in RAM regions.\n\n        Args:\n            size: the size of the addresses\n            align_offset: the alignment offset\n            cpus: the number of cpus\n            max_address: the maximum address\n\n        Returns:\n            a tuple containing the total elements and the addresses\n        \"\"\"\n        if size == 0:\n            return 0, []\n\n        ranges = []\n        multi_ranges = [[] for cid in range(cpus)]\n        for region in self._memregions:\n            region_start = region[\"start\"]\n            region_end = region[\"end\"]\n\n            if region_start &gt;= max_address &gt; 0:\n                continue\n\n            if align_offset &gt; region[\"size\"]:\n                continue\n\n            if 0 &lt; max_address &lt; region_end:\n                chunk_end = max_address\n            else:\n                chunk_end = region_end\n\n            original_r = range(region_start + align_offset, chunk_end + 1, size)\n\n            if cpus == 1:\n                ranges.append(original_r)\n            else:\n                # Split the iterator over the region in cpus iterators\n                range_size = len(original_r) // cpus * size\n                if range_size &lt;= size:\n                    range_size = size\n                    vcpus = len(original_r) // size\n                else:\n                    vcpus = cpus\n\n                first_elem = region_start + align_offset\n                multi_ranges[0].append(\n                    range(first_elem, region_start + range_size, size)\n                )\n\n                prev_last = region_start + range_size\n                for i in range(1, vcpus - 1):\n                    r = (prev_last - align_offset - region_start) % size\n                    if r == 0:\n                        first_elem = prev_last\n                    else:\n                        first_elem = prev_last + (size - r)\n\n                    last_elem = (i + 1) * range_size + region_start\n                    multi_ranges[i].append(range(first_elem, last_elem, size))\n\n                    prev_last = last_elem\n\n                r = (prev_last - align_offset - region_start) % size\n                if r == 0:\n                    first_elem = prev_last\n                else:\n                    first_elem = prev_last + (size - r)\n\n                if first_elem &gt; chunk_end:\n                    continue\n                multi_ranges[vcpus - 1].append(range(first_elem, chunk_end + 1, size))\n\n        if cpus == 1:\n            total_elems = sum([len(x) for x in ranges])\n            return total_elems, [total_elems, chain(*ranges)]\n        else:\n            total_elems = 0\n            for cid in range(cpus):\n                elems_in_iter = sum([len(x) for x in multi_ranges[cid]])\n                total_elems += elems_in_iter\n                multi_ranges[cid] = (elems_in_iter, chain(*multi_ranges[cid]))\n            return total_elems, multi_ranges\n\n    def get_miasm_vmmngr(self):\n        \"\"\"Load each RAM file in a MIASM virtual memory region\n\n        Returns:\n            the Miasm VM\n        \"\"\"\n        if self._miasm_vm is not None:\n            return self._miasm_vm\n\n        vm = Vm()\n        for region_def in self._memregions:\n            vm.add_memory_page(\n                region_def[\"start\"],\n                PAGE_READ | PAGE_WRITE | PAGE_EXEC,\n                region_def[\"fd\"].read(),\n                region_def[\"filename\"],\n            )\n            region_def[\"fd\"].seek(0)\n        self._miasm_vm = vm\n        return self._miasm_vm\n\n    def get_memregions(self):\n        \"\"\"Get the memory regions\"\"\"\n        return self._memregions\n\n    def free_miasm_memory(self):\n        \"\"\"Free the Miasm memory\"\"\"\n        if self._miasm_vm:\n            self._miasm_vm = None\n            gc.collect()\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PhysicalMemory.__contains__","title":"<code>__contains__(key)</code>","text":"<p>Check if a key is in the memory</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def __contains__(self, key):\n    \"\"\"Check if a key is in the memory\"\"\"\n    if not isinstance(key, int):\n        raise TypeError\n    return key in self.physpace[\"ram\"]\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PhysicalMemory.__copy__","title":"<code>__copy__()</code>","text":"<p>Copy the PhysicalMemory object</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def __copy__(self):\n    \"\"\"Copy the PhysicalMemory object\"\"\"\n    return PhysicalMemory(self.raw_configuration)\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PhysicalMemory.__deepcopy__","title":"<code>__deepcopy__(memo)</code>","text":"<p>Deepcopy the PhysicalMemory object</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def __deepcopy__(self, memo):\n    \"\"\"Deepcopy the PhysicalMemory object\"\"\"\n    return PhysicalMemory(self.raw_configuration)\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PhysicalMemory.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Get the state of the PhysicalMemory object</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def __getstate__(self):\n    \"\"\"Get the state of the PhysicalMemory object\"\"\"\n    self.close()\n    if self._miasm_vm:\n        del self._miasm_vm\n        self._miasm_vm = None\n    state = deepcopy(self.__dict__)\n    self.reopen()\n    return state\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PhysicalMemory.__init__","title":"<code>__init__(regions_defs)</code>","text":"<p>Initialize the PhysicalMemory</p> <p>Parameters:</p> Name Type Description Default <code>regions_defs</code> <p>the regions definitions</p> required Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def __init__(self, regions_defs):\n    \"\"\"Initialize the PhysicalMemory\n\n    Args:\n        regions_defs: the regions definitions\n    \"\"\"\n    self._is_opened = False\n    self._miasm_vm = None\n    self._memregions = []\n    self._memsize = 0\n    self.physpace = {\"ram\": portion.empty(), \"not_ram\": portion.empty()}\n    self.raw_configuration = regions_defs\n\n    # Load dump RAM files\n    try:\n        for region_def in regions_defs[\"ram\"]:\n            # Load the dump file for a memory region\n            fd = open(region_def[\"dumpfile\"], \"rb\")\n            mm = mmap(fd.fileno(), 0, MAP_SHARED, PROT_READ)\n            mm.madvise(MADV_HUGEPAGE)\n            self._memsize += len(mm)\n            region_size = len(mm)\n\n            if region_size != region_def[\"end\"] - region_def[\"start\"] + 1:\n                raise IOError(\n                    \"Declared size {} is different from real size {} for: {}\".format(\n                        region_def[\"end\"] - region_def[\"start\"] + 1,\n                        region_size,\n                        region_def[\"dumpfile\"],\n                    )\n                )\n\n            self._memregions.append(\n                {\n                    \"filename\": region_def[\"dumpfile\"],\n                    \"fd\": fd,\n                    \"mmap\": mm,\n                    \"size\": region_size,\n                    \"start\": region_def[\"start\"],\n                    \"end\": region_def[\"end\"],\n                }\n            )\n            self.physpace[\"ram\"] |= portion.closed(\n                region_def[\"start\"], region_def[\"end\"]\n            )\n\n        self._memregions.sort(key=lambda x: x[\"start\"])\n        self._is_opened = True\n\n    except Exception as e:\n        self.close()\n        raise IOError(\"Error in opening dump files! Error: {}\".format(e))\n\n    # Load not RAM regions\n    for region_def in regions_defs.get(\"not_ram\", []):\n        self.physpace[\"not_ram\"] |= portion.closed(\n            region_def[\"start\"], region_def[\"end\"]\n        )\n    self.physpace[\"not_valid_regions\"] = self.physpace[\"not_ram\"].difference(\n        self.physpace[\"ram\"]\n    )\n    self.physpace[\"defined_regions\"] = (\n        self.physpace[\"not_ram\"] | self.physpace[\"ram\"]\n    )\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PhysicalMemory.__len__","title":"<code>__len__()</code>","text":"<p>Get the size of the memory</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def __len__(self):\n    \"\"\"Get the size of the memory\"\"\"\n    return self._memsize\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PhysicalMemory.__setstate__","title":"<code>__setstate__(state)</code>","text":"<p>Set the state of the PhysicalMemory object</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def __setstate__(self, state):\n    \"\"\"Set the state of the PhysicalMemory object\"\"\"\n    self.__dict__.update(state)\n    self.reopen()\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PhysicalMemory.close","title":"<code>close()</code>","text":"<p>Close the memory</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def close(self):\n    \"\"\"Close the memory\"\"\"\n    for region in self._memregions:\n        try:\n            if region[\"mmap\"] is not None:\n                region[\"mmap\"].close()\n                del region[\"mmap\"]\n                region[\"mmap\"] = None\n            if region[\"fd\"] is not None:\n                region[\"fd\"].close()\n                del region[\"fd\"]\n                region[\"fd\"] = None\n        except Exception:\n            continue\n    self._is_opened = False\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PhysicalMemory.free_miasm_memory","title":"<code>free_miasm_memory()</code>","text":"<p>Free the Miasm memory</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def free_miasm_memory(self):\n    \"\"\"Free the Miasm memory\"\"\"\n    if self._miasm_vm:\n        self._miasm_vm = None\n        gc.collect()\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PhysicalMemory.get_addresses","title":"<code>get_addresses(size, align_offset=0, cpus=1, max_address=-1)</code>","text":"<p>Get the addresses of the memory</p> <p>Return a list contains tuples (for a total of cpus tuples). Each tuple contains the len of the iterator, and an iterator over part of all the addresses aligned to align_offset and distanced by size present in RAM regions.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <p>the size of the addresses</p> required <code>align_offset</code> <p>the alignment offset</p> <code>0</code> <code>cpus</code> <p>the number of cpus</p> <code>1</code> <code>max_address</code> <p>the maximum address</p> <code>-1</code> <p>Returns:</p> Type Description <p>a tuple containing the total elements and the addresses</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def get_addresses(self, size, align_offset=0, cpus=1, max_address=-1):\n    \"\"\"Get the addresses of the memory\n\n    Return a list contains tuples (for a total of cpus tuples).\n    Each tuple contains the len of the iterator, and an iterator over part of all the addresses aligned to align_offset and distanced by size present in RAM regions.\n\n    Args:\n        size: the size of the addresses\n        align_offset: the alignment offset\n        cpus: the number of cpus\n        max_address: the maximum address\n\n    Returns:\n        a tuple containing the total elements and the addresses\n    \"\"\"\n    if size == 0:\n        return 0, []\n\n    ranges = []\n    multi_ranges = [[] for cid in range(cpus)]\n    for region in self._memregions:\n        region_start = region[\"start\"]\n        region_end = region[\"end\"]\n\n        if region_start &gt;= max_address &gt; 0:\n            continue\n\n        if align_offset &gt; region[\"size\"]:\n            continue\n\n        if 0 &lt; max_address &lt; region_end:\n            chunk_end = max_address\n        else:\n            chunk_end = region_end\n\n        original_r = range(region_start + align_offset, chunk_end + 1, size)\n\n        if cpus == 1:\n            ranges.append(original_r)\n        else:\n            # Split the iterator over the region in cpus iterators\n            range_size = len(original_r) // cpus * size\n            if range_size &lt;= size:\n                range_size = size\n                vcpus = len(original_r) // size\n            else:\n                vcpus = cpus\n\n            first_elem = region_start + align_offset\n            multi_ranges[0].append(\n                range(first_elem, region_start + range_size, size)\n            )\n\n            prev_last = region_start + range_size\n            for i in range(1, vcpus - 1):\n                r = (prev_last - align_offset - region_start) % size\n                if r == 0:\n                    first_elem = prev_last\n                else:\n                    first_elem = prev_last + (size - r)\n\n                last_elem = (i + 1) * range_size + region_start\n                multi_ranges[i].append(range(first_elem, last_elem, size))\n\n                prev_last = last_elem\n\n            r = (prev_last - align_offset - region_start) % size\n            if r == 0:\n                first_elem = prev_last\n            else:\n                first_elem = prev_last + (size - r)\n\n            if first_elem &gt; chunk_end:\n                continue\n            multi_ranges[vcpus - 1].append(range(first_elem, chunk_end + 1, size))\n\n    if cpus == 1:\n        total_elems = sum([len(x) for x in ranges])\n        return total_elems, [total_elems, chain(*ranges)]\n    else:\n        total_elems = 0\n        for cid in range(cpus):\n            elems_in_iter = sum([len(x) for x in multi_ranges[cid]])\n            total_elems += elems_in_iter\n            multi_ranges[cid] = (elems_in_iter, chain(*multi_ranges[cid]))\n        return total_elems, multi_ranges\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PhysicalMemory.get_data","title":"<code>get_data(start, size)</code>","text":"<p>Get data from the memory</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def get_data(self, start, size):\n    \"\"\"Get data from the memory\"\"\"\n    for region in self._memregions:\n        if region[\"start\"] &lt;= start &lt;= region[\"end\"]:\n            return region[\"mmap\"][\n                start - region[\"start\"] : start - region[\"start\"] + size\n            ]\n    return bytearray()\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PhysicalMemory.get_memregions","title":"<code>get_memregions()</code>","text":"<p>Get the memory regions</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def get_memregions(self):\n    \"\"\"Get the memory regions\"\"\"\n    return self._memregions\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PhysicalMemory.get_miasm_vmmngr","title":"<code>get_miasm_vmmngr()</code>","text":"<p>Load each RAM file in a MIASM virtual memory region</p> <p>Returns:</p> Type Description <p>the Miasm VM</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def get_miasm_vmmngr(self):\n    \"\"\"Load each RAM file in a MIASM virtual memory region\n\n    Returns:\n        the Miasm VM\n    \"\"\"\n    if self._miasm_vm is not None:\n        return self._miasm_vm\n\n    vm = Vm()\n    for region_def in self._memregions:\n        vm.add_memory_page(\n            region_def[\"start\"],\n            PAGE_READ | PAGE_WRITE | PAGE_EXEC,\n            region_def[\"fd\"].read(),\n            region_def[\"filename\"],\n        )\n        region_def[\"fd\"].seek(0)\n    self._miasm_vm = vm\n    return self._miasm_vm\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.PhysicalMemory.reopen","title":"<code>reopen()</code>","text":"<p>Reopen the memory</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def reopen(self):\n    \"\"\"Reopen the memory\"\"\"\n    for region in self._memregions:\n        region[\"fd\"] = open(region[\"filename\"], \"rb\")\n        region[\"mmap\"] = mmap(region[\"fd\"].fileno(), 0, MAP_SHARED, PROT_READ)\n        region[\"mmap\"].madvise(MADV_HUGEPAGE)\n    self._is_opened = True\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.RadixTree","title":"<code>RadixTree</code>","text":"<p>Represents a Radix Tree</p> <p>Radix trees maintain a hierarchical representation of the SAS. Each tree is composed by N-1 levels of directory tables, each containing entries that either point to tables of the lower level or to a physical memory page (huge pages), whose size depends on the level itself. The final level is composed of page tables that point only to same-size physical memory pages. The tree root is the physical address of the directory table of Level 0 and it identifies uniquely the SAS and, consequently, the process to which it is assigned. This address is stored in a special system register (here generically called RADIX_ROOT) by the operating system and it is used by the MMU to locate the radix tree when it starts a new translation. The translation performed by the MMU starts from the root table pointed by the address contained in RADIX_ROOT: the MMU then divides the segmented address into two parts: a prefix and a page offset. The prefix part is divided into a series of N chunks that represent the hierarchical sequence of indexes to be used to locate the entry inside a table of the corresponding level. This process ends when an entry points to a physical page. At this point, the MMU returns the concatenation of the page offset extracted by the segmented address to the physical page address found in the last page table entry.</p> <p>Aimed to be inherited by child classes to represent different architectures</p> <p>Attributes:</p> Name Type Description <code>top_table</code> <p>the address of the top table</p> <code>init_level</code> <p>the initial level of the radix tree</p> <code>pas</code> <p>the Physical Address Space</p> <code>vas</code> <p>the Virtual Address Space</p> <code>kernel</code> <p>if the kernel space is enabled</p> <code>user</code> <p>if the user space is enabled</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>class RadixTree:\n    \"\"\"Represents a Radix Tree\n\n    Radix trees maintain a hierarchical representation of the SAS. Each tree is composed by N-1 levels of\n    directory tables, each containing entries that either point to tables of the lower level or to a physical\n    memory page (huge pages), whose size depends on the level itself.\n    The final level is composed of page tables that point only to same-size physical memory pages.\n    The tree root is the physical address of the directory table of Level 0 and it identifies uniquely the SAS\n    and, consequently, the process to which it is assigned. This address is stored in a special system register\n    (here generically called RADIX_ROOT) by the operating system and it is used by the MMU to locate the radix\n    tree when it starts a new translation.\n    The translation performed by the MMU starts from the root table pointed by the address contained in RADIX_ROOT:\n    the MMU then divides the segmented address into two parts: a prefix and a page offset.\n    The prefix part is divided into a series of N chunks that represent the hierarchical sequence of indexes to be\n    used to locate the entry inside a table of the corresponding level. This process ends when an entry points to\n    a physical page. At this point, the MMU returns the concatenation of the page offset extracted by the segmented\n    address to the physical page address found in the last page table entry.\n\n    Aimed to be inherited by child classes to represent different architectures\n\n    Attributes:\n        top_table: the address of the top table\n        init_level: the initial level of the radix tree\n        pas: the Physical Address Space\n        vas: the Virtual Address Space\n        kernel: if the kernel space is enabled\n        user: if the user space is enabled\n    \"\"\"\n\n    labels = [\n        \"Radix address\",\n        \"First level\",\n        \"Kernel size (Bytes)\",\n        \"User size (Bytes)\",\n    ]\n    addr_fmt = \"0x{:016x}\"\n\n    def __init__(self, top_table, init_level, pas, vas, kernel=True, user=True):\n        \"\"\"Initialize the Radix Tree\n\n        Args:\n            top_table: the address of the top table\n            init_level: the initial level of the radix tree\n            pas: the Physical Address Space\n            vas: the Virtual Address Space\n            kernel: if the kernel space is enabled\n            user: if the user space is enabled\n        \"\"\"\n        self.top_table = top_table\n        self.init_level = init_level\n        self.pas = pas\n        self.vas = vas\n        self.kernel = kernel\n        self.user = user\n\n    def __repr__(self):\n        \"\"\"String representation of the Radix Tree\"\"\"\n        e_resume = self.entry_resume_stringified()\n        return str(\n            [self.labels[i] + \": \" + str(e_resume[i]) for i in range(len(self.labels))]\n        )\n\n    def entry_resume(self) -&gt; list:\n        \"\"\"Get the resume of the Radix Tree\n\n        Returns:\n            a list with the resume of the Radix Tree\n        \"\"\"\n        return [\n            self.top_table,\n            self.init_level,\n            self.pas.get_kernel_size(),\n            self.pas.get_user_size(),\n        ]\n\n    def entry_resume_stringified(self) -&gt; list:\n        \"\"\"Get the resume of the Radix Tree as string\n\n        Returns:\n            a list with the resume of the Radix Tree as string\n        \"\"\"\n        res = self.entry_resume()\n        res[0] = self.addr_fmt.format(res[0])\n        for idx, r in enumerate(res[1:], start=1):\n            res[idx] = str(r)\n        return res\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.RadixTree.__init__","title":"<code>__init__(top_table, init_level, pas, vas, kernel=True, user=True)</code>","text":"<p>Initialize the Radix Tree</p> <p>Parameters:</p> Name Type Description Default <code>top_table</code> <p>the address of the top table</p> required <code>init_level</code> <p>the initial level of the radix tree</p> required <code>pas</code> <p>the Physical Address Space</p> required <code>vas</code> <p>the Virtual Address Space</p> required <code>kernel</code> <p>if the kernel space is enabled</p> <code>True</code> <code>user</code> <p>if the user space is enabled</p> <code>True</code> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def __init__(self, top_table, init_level, pas, vas, kernel=True, user=True):\n    \"\"\"Initialize the Radix Tree\n\n    Args:\n        top_table: the address of the top table\n        init_level: the initial level of the radix tree\n        pas: the Physical Address Space\n        vas: the Virtual Address Space\n        kernel: if the kernel space is enabled\n        user: if the user space is enabled\n    \"\"\"\n    self.top_table = top_table\n    self.init_level = init_level\n    self.pas = pas\n    self.vas = vas\n    self.kernel = kernel\n    self.user = user\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.RadixTree.__repr__","title":"<code>__repr__()</code>","text":"<p>String representation of the Radix Tree</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def __repr__(self):\n    \"\"\"String representation of the Radix Tree\"\"\"\n    e_resume = self.entry_resume_stringified()\n    return str(\n        [self.labels[i] + \": \" + str(e_resume[i]) for i in range(len(self.labels))]\n    )\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.RadixTree.entry_resume","title":"<code>entry_resume()</code>","text":"<p>Get the resume of the Radix Tree</p> <p>Returns:</p> Type Description <code>list</code> <p>a list with the resume of the Radix Tree</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def entry_resume(self) -&gt; list:\n    \"\"\"Get the resume of the Radix Tree\n\n    Returns:\n        a list with the resume of the Radix Tree\n    \"\"\"\n    return [\n        self.top_table,\n        self.init_level,\n        self.pas.get_kernel_size(),\n        self.pas.get_user_size(),\n    ]\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.RadixTree.entry_resume_stringified","title":"<code>entry_resume_stringified()</code>","text":"<p>Get the resume of the Radix Tree as string</p> <p>Returns:</p> Type Description <code>list</code> <p>a list with the resume of the Radix Tree as string</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def entry_resume_stringified(self) -&gt; list:\n    \"\"\"Get the resume of the Radix Tree as string\n\n    Returns:\n        a list with the resume of the Radix Tree as string\n    \"\"\"\n    res = self.entry_resume()\n    res[0] = self.addr_fmt.format(res[0])\n    for idx, r in enumerate(res[1:], start=1):\n        res[idx] = str(r)\n    return res\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.TableEntry","title":"<code>TableEntry</code>","text":"<p>Represents a table Page Table Entry</p> <p>It holds the mapping between a virtual address of a page and the address of a physical frame. There is also auxiliary information about the page such as a present bit, a dirty or modified bit, address space or process ID information, amongst others.</p> <p>Aimed to be inherited by child classes to represent different architectures</p> <p>Attributes:</p> Name Type Description <code>address</code> <p>the virtual address of the page</p> <code>flags</code> <p>the flags of the page</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>class TableEntry:\n    \"\"\"Represents a table Page Table Entry\n\n    It holds the mapping between a virtual address of a page and the address of a physical frame.\n    There is also auxiliary information about the page such as a present bit, a dirty or modified bit, address space or process ID information, amongst others.\n\n    Aimed to be inherited by child classes to represent different architectures\n\n    Attributes:\n        address: the virtual address of the page\n        flags: the flags of the page\n    \"\"\"\n\n    def __init__(self, address, flags, *args):\n        \"\"\"Initialize the Table Entry\n\n        Args:\n            address: the virtual address of the page\n            flags: the flags of the page\n            *args: additional arguments\n        \"\"\"\n        self.address = address\n        self.flags = flags\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.TableEntry.__init__","title":"<code>__init__(address, flags, *args)</code>","text":"<p>Initialize the Table Entry</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <p>the virtual address of the page</p> required <code>flags</code> <p>the flags of the page</p> required <code>*args</code> <p>additional arguments</p> <code>()</code> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def __init__(self, address, flags, *args):\n    \"\"\"Initialize the Table Entry\n\n    Args:\n        address: the virtual address of the page\n        flags: the flags of the page\n        *args: additional arguments\n    \"\"\"\n    self.address = address\n    self.flags = flags\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.VAS","title":"<code>VAS</code>","text":"<p>             Bases: <code>defaultdict</code></p> <p>Represents a Virtual Address Space</p> <p>The Virtual Address Space (VAS) is a hierarchical data structure that represents the SAS of a process. The VAS is composed of a set of entries, each one representing a set of contiguous virtual addresses with the same permissions. The VAS is organized in a hierarchical way, where each entry is identified by a set of permissions and contains a set of intervals of contiguous virtual addresses.</p> <p>Aimed to be inherited by child classes to represent different architectures</p> <p>Attributes:</p> Name Type Description <code>default_factory</code> <p>the default interval for the VAS</p> <p>Note: the default_factory is initialized as an empty interval to avoid the need of checking if a key is present before accessing it</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>class VAS(defaultdict):\n    \"\"\"Represents a Virtual Address Space\n\n    The Virtual Address Space (VAS) is a hierarchical data structure that represents the SAS of a process.\n    The VAS is composed of a set of entries, each one representing a set of contiguous virtual addresses\n    with the same permissions. The VAS is organized in a hierarchical way, where each entry is identified by\n    a set of permissions and contains a set of intervals of contiguous virtual addresses.\n\n    Aimed to be inherited by child classes to represent different architectures\n\n    Attributes:\n        default_factory: the default interval for the VAS\n\n    Note: the default_factory is initialized as an empty interval to avoid the need of checking if a key is present before accessing it\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super(VAS, self).__init__()\n        self.default_factory = portion.empty\n\n    def __repr__(self):\n        \"\"\"String representation of the VAS\"\"\"\n        s = \"\"\n        for k in self:\n            k_str = perms_bool_to_string(*k)\n            s += k_str + \"\\n\"\n            for interval in self[k]:\n                s += f\"\\t[{hex(interval.lower)}, {hex(interval.upper)}]\\n\"\n        return s\n\n    def hierarchical_extend(self, other, uperms):\n        \"\"\"Extend this VAS with another VAS\n\n        Args:\n            other: the other VAS to extend with\n            uperms: the permissions to use\n        \"\"\"\n        for perm in other:\n            new_perm = []\n            for i in range(6):\n                new_perm.append(perm[i] and uperms[i])\n            new_perm = tuple(new_perm)\n            self[new_perm] |= other[perm]\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.VAS.__repr__","title":"<code>__repr__()</code>","text":"<p>String representation of the VAS</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def __repr__(self):\n    \"\"\"String representation of the VAS\"\"\"\n    s = \"\"\n    for k in self:\n        k_str = perms_bool_to_string(*k)\n        s += k_str + \"\\n\"\n        for interval in self[k]:\n            s += f\"\\t[{hex(interval.lower)}, {hex(interval.upper)}]\\n\"\n    return s\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.VAS.hierarchical_extend","title":"<code>hierarchical_extend(other, uperms)</code>","text":"<p>Extend this VAS with another VAS</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <p>the other VAS to extend with</p> required <code>uperms</code> <p>the permissions to use</p> required Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def hierarchical_extend(self, other, uperms):\n    \"\"\"Extend this VAS with another VAS\n\n    Args:\n        other: the other VAS to extend with\n        uperms: the permissions to use\n    \"\"\"\n    for perm in other:\n        new_perm = []\n        for i in range(6):\n            new_perm.append(perm[i] and uperms[i])\n        new_perm = tuple(new_perm)\n        self[new_perm] |= other[perm]\n</code></pre>"},{"location":"reference/architectures/generic/#mmushell.architectures.generic.perms_bool_to_string","title":"<code>perms_bool_to_string(kr, kw, kx, r, w, x)</code>","text":"<p>Convert a set of permissions from boolean to string</p> <p>Parameters:</p> Name Type Description Default <code>kr</code> <p>read permission for the kernel</p> required <code>kw</code> <p>write permission for the kernel</p> required <code>kx</code> <p>execute permission for the kernel</p> required <code>r</code> <p>read permission for the user</p> required <code>w</code> <p>write permission for the user</p> required <code>x</code> <p>execute permission for the user</p> required <p>Returns:</p> Type Description <p>a string with the permissions</p> Source code in <code>mmushell/architectures/generic.py</code> <pre><code>def perms_bool_to_string(kr, kw, kx, r, w, x):\n    \"\"\"Convert a set of permissions from boolean to string\n\n    Args:\n        kr: read permission for the kernel\n        kw: write permission for the kernel\n        kx: execute permission for the kernel\n        r: read permission for the user\n        w: write permission for the user\n        x: execute permission for the user\n\n    Returns:\n        a string with the permissions\n    \"\"\"\n    perm_s = \"R\" if kr else \"-\"\n    perm_s += \"W\" if kw else \"-\"\n    perm_s += \"X\" if kx else \"-\"\n    perm_s += \"r\" if r else \"-\"\n    perm_s += \"w\" if w else \"-\"\n    perm_s += \"x\" if x else \"-\"\n    return perm_s\n</code></pre>"},{"location":"reference/architectures/intel/","title":"Intel","text":""},{"location":"reference/architectures/intel/#intel","title":"intel","text":""},{"location":"reference/architectures/intel/#mmushell.architectures.intel.MMUShell","title":"<code>MMUShell</code>","text":"<p>             Bases: <code>MMUShell</code></p> Source code in <code>mmushell/architectures/intel.py</code> <pre><code>class MMUShell(MMUShellDefault):\n    def __init__(self, completekey=\"tab\", stdin=None, stdout=None, machine={}):\n        super(MMUShell, self).__init__(completekey, stdin, stdout, machine)\n\n        if not self.data:\n            self.data = Data(\n                is_mem_parsed=False,\n                is_radix_found=False,\n                page_tables={\n                    \"global\": [\n                        {} for i in range(self.machine.mmu.radix_levels[\"global\"])\n                    ]\n                },\n                data_pages=[],\n                empty_tables=[],\n                reverse_map_tables=[\n                    defaultdict(set)\n                    for i in range(self.machine.mmu.radix_levels[\"global\"])\n                ],\n                reverse_map_pages=[\n                    defaultdict(set)\n                    for i in range(self.machine.mmu.radix_levels[\"global\"])\n                ],\n                idts=[],\n                cr3s={},\n            )\n\n    def do_parse_memory(self, args):\n        \"\"\"Find MMU tables and IDTs\"\"\"\n        if self.data.is_mem_parsed:\n            logger.warning(\"Memory already parsed\")\n            return\n\n        if type(self.machine.mmu) is IA32:\n            self.parse_memory_ia32()\n        elif type(self.machine.mmu) is PAE:\n            self.parse_memory_pae()\n        elif type(self.machine.mmu) is IA64:\n            self.parse_memory_ia64()\n        else:\n            logging.fatal(\"OOPS... MMU class unkown!\")\n            exit(-1)\n        self.data.is_mem_parsed = True\n\n    def do_show_idt(self, args):\n        \"\"\"Show the IDT at a chosen address. Usage: show_idt ADDRESS\"\"\"\n        args = args.split()\n        if len(args) &lt; 1:\n            logger.warning(\"Missing table address\")\n            return\n\n        try:\n            addr = self.parse_int(args[0])\n        except ValueError:\n            logger.warning(\"Invalid table address\")\n            return\n\n        print(self.machine.cpu.parse_idt(addr))\n\n    def do_show_table(self, args):\n        \"\"\"Show an MMU table at a chosen address. Usage: show_table ADDRESS [level]\"\"\"\n        args = args.split()\n        if len(args) &lt; 1:\n            logger.warning(\"Missing table address\")\n            return\n\n        try:\n            addr = self.parse_int(args[0])\n        except ValueError:\n            logger.warning(\"Invalid table address\")\n            return\n\n        if addr not in self.machine.memory:\n            logger.warning(\"Table not in RAM range\")\n            return\n\n        lvl = -1\n        if len(args) &gt; 1:\n            try:\n                lvl = self.parse_int(args[1])\n                if lvl &gt; (self.machine.mmu.radix_levels[\"global\"] - 1):\n                    raise ValueError\n            except ValueError:\n                logger.warning(\n                    \"Level must be an integer between 0 and {}\".format(\n                        str(self.machine.mmu.radix_levels[\"global\"] - 1)\n                    )\n                )\n                return\n\n        if lvl == -1:\n            table_size = self.machine.mmu.PAGE_SIZE\n        else:\n            table_size = self.machine.mmu.map_level_to_table_size[\"global\"][lvl]\n        table_buff = self.machine.memory.get_data(addr, table_size)\n        invalids, pt_classes, table_obj = self.machine.mmu.parse_frame(\n            table_buff, addr, table_size, lvl\n        )\n        print(table_obj)\n        print(f\"Invalid entries: {invalids} Table levels: {pt_classes}\")\n\n    def parse_memory_ia32(self):\n        # Due to the impossibility to differentiate among data and page table (PT) in a simple way,\n        # we first look for PDs and then only to PTs pointed by PDs, otherwise memory consumption is unmanageable...\n\n        # Look for only PD, then use that to find only PT\n        logger.info(\"Look for page directories..\")\n        self.machine.mmu.classify_entry = self.machine.mmu.classify_entry_pd_only\n        parallel_results = self.machine.apply_parallel(\n            self.machine.mmu.PAGE_SIZE, self.machine.mmu.parse_parallel_frame\n        )\n\n        logger.info(\"Reaggregate threads data...\")\n        for result in parallel_results:\n            page_tables, data_pages, empty_tables = result.get()\n\n            self.data.page_tables[\"global\"][0].update(page_tables[0])\n            self.data.data_pages.extend(data_pages)\n            self.data.empty_tables.extend(empty_tables)\n\n        logger.info(\"Collect page tables...\")\n        # Collect all PT addresses pointed by PD\n        pt_candidates = set()\n        for pd_obj in self.data.page_tables[\"global\"][0].values():\n            for entry_obj in pd_obj.entries[PDE32].values():\n                pt_candidates.add(entry_obj.address)\n        pt_candidates = list(pt_candidates)\n        pt_candidates.sort()\n        self.machine.mmu.classify_entry = self.machine.mmu.classify_entry_pt_only\n\n        # Workaround to reduce thread memory consumption\n        data = self.data\n        self.data = None\n\n        iterators = [\n            (len(y), y)\n            for y in [list(x) for x in divide(mp.cpu_count(), pt_candidates)]\n        ]\n        parsing_results_async = self.machine.apply_parallel(\n            self.machine.mmu.PAGE_SIZE,\n            self.machine.mmu.parse_parallel_frame,\n            iterators=iterators,\n        )\n\n        # Restore previous data and set classify_entry to full version\n        self.data = data\n        self.machine.mmu.classify_entry = self.machine.mmu.classify_entry_full\n\n        # Reaggregate data\n        logger.info(\"Reaggregate threads data...\")\n        for result in parsing_results_async:\n            page_tables, data_pages, empty_tables = result.get()\n            self.data.page_tables[\"global\"][1].update(page_tables[1])\n            self.data.data_pages.extend(data_pages)\n            self.data.empty_tables.extend(empty_tables)\n\n        # Remove PT from data pages (in the first phase the alogrith has classified PT as data pages, now that\n        # we know which PT is a true one, they must be removed from data pages)\n        self.data.data_pages = set(self.data.data_pages)\n        self.data.data_pages.difference_update(\n            self.data.page_tables[\"global\"][1].keys()\n        )\n        self.data.empty_tables = set(self.data.empty_tables)\n\n        logger.info(\"Reduce false positives...\")\n        # Remove all tables which point to inexistent table of lower level\n        for lvl in range(self.machine.mmu.radix_levels[\"global\"] - 1):\n            ptr_class = self.machine.mmu.map_ptr_entries_to_levels[\"global\"][lvl]\n\n            referenced_nxt = []\n            for table_addr in list(self.data.page_tables[\"global\"][lvl].keys()):\n                for entry_obj in (\n                    self.data.page_tables[\"global\"][lvl][table_addr]\n                    .entries[ptr_class]\n                    .values()\n                ):\n                    if (\n                        entry_obj.address\n                        not in self.data.page_tables[\"global\"][lvl + 1]\n                        and entry_obj.address not in self.data.empty_tables\n                    ):\n                        # Remove the table\n                        self.data.page_tables[\"global\"][lvl].pop(table_addr)\n                        break\n\n                    else:\n                        referenced_nxt.append(entry_obj.address)\n\n            # Remove table not referenced by upper levels\n            referenced_nxt = set(referenced_nxt)\n            for table_addr in set(\n                self.data.page_tables[\"global\"][lvl + 1].keys()\n            ).difference(referenced_nxt):\n                self.data.page_tables[\"global\"][lvl + 1].pop(table_addr)\n\n        logger.info(\"Fill reverse maps...\")\n        for lvl in range(0, self.machine.mmu.radix_levels[\"global\"]):\n            ptr_class = self.machine.mmu.map_ptr_entries_to_levels[\"global\"][lvl]\n            page_class = self.machine.mmu.map_datapages_entries_to_levels[\"global\"][\n                lvl\n            ][\n                0\n            ]  # Trick! Only one dataclass per level\n            for table_addr, table_obj in self.data.page_tables[\"global\"][lvl].items():\n                for entry_obj in table_obj.entries[ptr_class].values():\n                    self.data.reverse_map_tables[lvl][entry_obj.address].add(\n                        table_obj.address\n                    )\n                for entry_obj in table_obj.entries[page_class].values():\n                    self.data.reverse_map_pages[lvl][entry_obj.address].add(\n                        table_obj.address\n                    )\n\n        logger.info(\"Look for interrupt tables...\")\n        self.data.idts = self.machine.cpu.find_idt_tables()\n\n    def parse_memory_pae(self):\n        # It uses the same function of IA64 but with a custom parse_parallel_frame\n        self.parse_memory_ia64()\n\n    def parse_memory_ia64(self):\n        logger.info(\"Look for paging tables...\")\n        parallel_results = self.machine.apply_parallel(\n            self.machine.mmu.PAGE_SIZE, self.machine.mmu.parse_parallel_frame\n        )\n        logger.info(\"Reaggregate threads data...\")\n        for result in parallel_results:\n            page_tables, data_pages, empty_tables = result.get()\n\n            for level in range(self.machine.mmu.radix_levels[\"global\"]):\n                self.data.page_tables[\"global\"][level].update(page_tables[level])\n\n            self.data.data_pages.extend(data_pages)\n            self.data.empty_tables.extend(empty_tables)\n\n        self.data.data_pages = set(self.data.data_pages)\n        self.data.empty_tables = set(self.data.empty_tables)\n\n        logger.info(\"Reduce false positives...\")\n        # Remove all tables which point to inexistent table of lower level\n        for lvl in range(self.machine.mmu.radix_levels[\"global\"] - 1):\n            ptr_class = self.machine.mmu.map_ptr_entries_to_levels[\"global\"][lvl]\n\n            referenced_nxt = []\n            for table_addr in list(self.data.page_tables[\"global\"][lvl].keys()):\n                for entry_obj in (\n                    self.data.page_tables[\"global\"][lvl][table_addr]\n                    .entries[ptr_class]\n                    .values()\n                ):\n                    if (\n                        entry_obj.address\n                        not in self.data.page_tables[\"global\"][lvl + 1]\n                        and entry_obj.address not in self.data.empty_tables\n                    ):\n                        # Remove the table\n                        self.data.page_tables[\"global\"][lvl].pop(table_addr)\n                        break\n\n                    else:\n                        referenced_nxt.append(entry_obj.address)\n\n            # Remove table not referenced by upper levels\n            referenced_nxt = set(referenced_nxt)\n            for table_addr in set(\n                self.data.page_tables[\"global\"][lvl + 1].keys()\n            ).difference(referenced_nxt):\n                self.data.page_tables[\"global\"][lvl + 1].pop(table_addr)\n\n        logger.info(\"Fill reverse maps...\")\n        for lvl in range(0, self.machine.mmu.radix_levels[\"global\"]):\n            ptr_class = self.machine.mmu.map_ptr_entries_to_levels[\"global\"][lvl]\n            page_class = self.machine.mmu.map_datapages_entries_to_levels[\"global\"][\n                lvl\n            ][\n                0\n            ]  # Trick! Only one dataclass per level\n            for table_addr, table_obj in self.data.page_tables[\"global\"][lvl].items():\n                for entry_obj in table_obj.entries[ptr_class].values():\n                    self.data.reverse_map_tables[lvl][entry_obj.address].add(\n                        table_obj.address\n                    )\n                for entry_obj in table_obj.entries[page_class].values():\n                    self.data.reverse_map_pages[lvl][entry_obj.address].add(\n                        table_obj.address\n                    )\n\n        logger.info(\"Look for interrupt tables...\")\n        self.data.idts = self.machine.cpu.find_idt_tables()\n\n    def do_show_idtrs(self, args):\n        \"\"\"Show IDT tables founds\"\"\"\n        if not self.data.is_radix_found:\n            logging.info(\"Please, find them first!\")\n            return\n\n        table = PrettyTable()\n        table.field_names = [\"Address\", \"Size\"]\n        for idt in self.data.idts:\n            table.add_row([hex(idt.address), idt.size])\n        print(table)\n\n    def do_find_radix_trees(self, args):\n        \"\"\"Reconstruct radix trees\"\"\"\n\n        # Some table level was not found...\n        if not len(self.data.page_tables[\"global\"][0]):\n            logger.warning(\"OOPS... no tables in first level... Wrong MMU mode?\")\n            return\n\n        cr3s = {}\n        # No valid IDT found\n        if not self.data.idts:\n            logger.warning(\"No valid IDTs found, collect all valid CR3s...\")\n\n            # Start from page tables of lower level and derive upper level tables (aka CR3)\n            # Filter for self-referencing CR3 (euristic) does not work with microkernels or SMAP/SMEP\n            cr3_candidates = []\n            already_explored = set()\n            for page_addr in tqdm(self.data.data_pages.union(self.data.empty_tables)):\n                derived_addresses = self.machine.mmu.derive_page_address(page_addr)\n                for derived_address in derived_addresses:\n                    if derived_address in already_explored:\n                        continue\n                    lvl, addr = derived_address\n                    cr3_candidates.extend(\n                        self.radix_roots_from_data_page(\n                            lvl,\n                            addr,\n                            self.data.reverse_map_pages,\n                            self.data.reverse_map_tables,\n                        )\n                    )\n                    already_explored.add(derived_address)\n            cr3_candidates = list(\n                set(cr3_candidates).intersection(\n                    self.data.page_tables[\"global\"][0].keys()\n                )\n            )\n\n            # Refine dataset and use a fake IDT table\n            cr3s = {-1: {}}\n\n            logger.info(\"Filter candidates...\")\n            for cr3 in tqdm(cr3_candidates):\n                # Obtain radix tree infos\n                consistency, pas = self.physpace(\n                    cr3,\n                    self.data.page_tables[\"global\"],\n                    self.data.empty_tables,\n                    hierarchical=True,\n                )\n\n                # Only consistent trees are valid\n                if not consistency:\n                    continue\n\n                # Esclude empty trees\n                if pas.get_kernel_size() == pas.get_user_size() == 0:\n                    continue\n\n                vas = self.virtspace(\n                    cr3, 0, self.machine.mmu.top_prefix, hierarchical=True\n                )\n                cr3s[-1][cr3] = RadixTree(cr3, 0, pas, vas)\n\n            self.data.cr3s = cr3s\n            self.data.is_radix_found = True\n            return\n\n        for idt_obj in self.data.idts:  # Cycle on all IDT found\n            cr3_candidates = set()\n            cr3s[idt_obj.address] = {}\n\n            # We cannot filter radix trees root on the basis that the pointed tree is able to address its top table\n            # this assumption is not valid for microkernels!\n\n            # Collect all possible CR3: a valid CR3 must be able to address the IDT\n            logger.info(\"Collect all valids CR3s...\")\n            idt_pg_addresses = self.machine.mmu.derive_page_address(\n                idt_obj.address &gt;&gt; 12 &lt;&lt; 12\n            )\n\n            for level, addr in idt_pg_addresses:\n                cr3_candidates.update(\n                    self.radix_roots_from_data_page(\n                        level,\n                        addr,\n                        self.data.reverse_map_pages,\n                        self.data.reverse_map_tables,\n                    )\n                )\n            cr3_candidates = list(\n                cr3_candidates.intersection(self.data.page_tables[\"global\"][0].keys())\n            )\n            logger.info(\n                \"Number of possible CR3s for IDT located at {}:{}\".format(\n                    hex(idt_obj.address), len(cr3_candidates)\n                )\n            )\n\n            # Collect the page containig each virtual addresses defined inside interrupt handlers\n            handlers_pages = set()\n            for handler in idt_obj.entries:\n                # Task Entry does not point to interrupt hanlder\n                if isinstance(handler, IDTTaskEntry32):\n                    continue\n\n                # Ignore handler unused\n                if not handler.p:\n                    continue\n\n                handlers_pages.add(handler.offset &gt;&gt; 12 &lt;&lt; 12)\n\n            # Try to resolve interrupt virtual addresses and count the number of unresolved interrupt handlers\n            cr3s_for_idt = []\n            for cr3_candidate in cr3_candidates:\n                errors = 0\n                for vaddr in handlers_pages:\n                    paddr = self.resolve_vaddr(cr3_candidate, vaddr)\n                    if paddr == -1:\n                        logging.debug(\n                            f\"find_radix_trees(): {hex(cr3_candidate)} failed to solve {hex(vaddr)}\"\n                        )\n                        errors += 1\n\n                cr3s_for_idt.append([cr3_candidate, errors])\n\n            # At least one CR3 must be found...\n            if not cr3s_for_idt:\n                continue\n\n            # Save only CR3s which resolv the max number of addresses\n            cr3s_for_idt.sort(key=lambda x: (x[1], x[0]))\n            max_value = cr3s_for_idt[0][1]\n            logger.debug(\n                \"Interrupt pages: {}, Maximum pages resolved: {}\".format(\n                    len(handlers_pages), len(handlers_pages) - max_value\n                )\n            )\n\n            # Consider only CR3 which resolve the maximum number of interrupt pages\n            for cr3 in cr3s_for_idt:\n                if max_value != cr3[1]:\n                    break\n\n                # Extract an approximation of the kernel and user physical address space\n                consistency, pas = self.physpace(\n                    cr3[0],\n                    self.data.page_tables[\"global\"],\n                    self.data.empty_tables,\n                    hierarchical=True,\n                )\n\n                # Only consistent trees are valid\n                if not consistency:\n                    continue\n\n                # Esclude empty trees\n                if pas.get_kernel_size() == pas.get_user_size() == 0:\n                    continue\n\n                vas = self.virtspace(\n                    cr3[0], 0, self.machine.mmu.top_prefix, hierarchical=True\n                )\n                cr3s[idt_obj.address][cr3[0]] = RadixTree(cr3[0], 0, pas, vas)\n\n        self.data.cr3s = cr3s\n        self.data.is_radix_found = True\n\n    def do_show_radix_trees(self, args):\n        \"\"\"Show radix trees found able to address a chosen IDT table. Usage: show_radix_trees PHY_IDT_ADDRESS\"\"\"\n        if not self.data.is_radix_found:\n            logging.info(\"Please, find them first!\")\n            return\n\n        # Check if the IDT requested is in the list of IDT found\n        args = args.split()\n        if len(args) &lt; 1:\n            logging.warning(\"Missing IDT\")\n            return\n        idt_addr = self.parse_int(args[0])\n\n        if not self.data.idts:\n            logging.info(\"No IDT found by MMUShell\")\n            idt_addr = -1\n        else:\n            for idt in self.data.idts:\n                if idt_addr == idt.address:\n                    break\n            else:\n                logging.warning(\"IDT requested not in IDT found!\")\n                return\n\n        # Show results\n        labels = [\n            \"Radix address\",\n            \"First level\",\n            \"Kernel size (Bytes)\",\n            \"User size (Bytes)\",\n        ]\n        table = PrettyTable()\n        table.field_names = labels\n        for cr3 in self.data.cr3s[idt_addr].values():\n            table.add_row(cr3.entry_resume_stringified())\n        table.sortby = \"Radix address\"\n        print(table)\n</code></pre>"},{"location":"reference/architectures/intel/#mmushell.architectures.intel.MMUShell.do_find_radix_trees","title":"<code>do_find_radix_trees(args)</code>","text":"<p>Reconstruct radix trees</p> Source code in <code>mmushell/architectures/intel.py</code> <pre><code>def do_find_radix_trees(self, args):\n    \"\"\"Reconstruct radix trees\"\"\"\n\n    # Some table level was not found...\n    if not len(self.data.page_tables[\"global\"][0]):\n        logger.warning(\"OOPS... no tables in first level... Wrong MMU mode?\")\n        return\n\n    cr3s = {}\n    # No valid IDT found\n    if not self.data.idts:\n        logger.warning(\"No valid IDTs found, collect all valid CR3s...\")\n\n        # Start from page tables of lower level and derive upper level tables (aka CR3)\n        # Filter for self-referencing CR3 (euristic) does not work with microkernels or SMAP/SMEP\n        cr3_candidates = []\n        already_explored = set()\n        for page_addr in tqdm(self.data.data_pages.union(self.data.empty_tables)):\n            derived_addresses = self.machine.mmu.derive_page_address(page_addr)\n            for derived_address in derived_addresses:\n                if derived_address in already_explored:\n                    continue\n                lvl, addr = derived_address\n                cr3_candidates.extend(\n                    self.radix_roots_from_data_page(\n                        lvl,\n                        addr,\n                        self.data.reverse_map_pages,\n                        self.data.reverse_map_tables,\n                    )\n                )\n                already_explored.add(derived_address)\n        cr3_candidates = list(\n            set(cr3_candidates).intersection(\n                self.data.page_tables[\"global\"][0].keys()\n            )\n        )\n\n        # Refine dataset and use a fake IDT table\n        cr3s = {-1: {}}\n\n        logger.info(\"Filter candidates...\")\n        for cr3 in tqdm(cr3_candidates):\n            # Obtain radix tree infos\n            consistency, pas = self.physpace(\n                cr3,\n                self.data.page_tables[\"global\"],\n                self.data.empty_tables,\n                hierarchical=True,\n            )\n\n            # Only consistent trees are valid\n            if not consistency:\n                continue\n\n            # Esclude empty trees\n            if pas.get_kernel_size() == pas.get_user_size() == 0:\n                continue\n\n            vas = self.virtspace(\n                cr3, 0, self.machine.mmu.top_prefix, hierarchical=True\n            )\n            cr3s[-1][cr3] = RadixTree(cr3, 0, pas, vas)\n\n        self.data.cr3s = cr3s\n        self.data.is_radix_found = True\n        return\n\n    for idt_obj in self.data.idts:  # Cycle on all IDT found\n        cr3_candidates = set()\n        cr3s[idt_obj.address] = {}\n\n        # We cannot filter radix trees root on the basis that the pointed tree is able to address its top table\n        # this assumption is not valid for microkernels!\n\n        # Collect all possible CR3: a valid CR3 must be able to address the IDT\n        logger.info(\"Collect all valids CR3s...\")\n        idt_pg_addresses = self.machine.mmu.derive_page_address(\n            idt_obj.address &gt;&gt; 12 &lt;&lt; 12\n        )\n\n        for level, addr in idt_pg_addresses:\n            cr3_candidates.update(\n                self.radix_roots_from_data_page(\n                    level,\n                    addr,\n                    self.data.reverse_map_pages,\n                    self.data.reverse_map_tables,\n                )\n            )\n        cr3_candidates = list(\n            cr3_candidates.intersection(self.data.page_tables[\"global\"][0].keys())\n        )\n        logger.info(\n            \"Number of possible CR3s for IDT located at {}:{}\".format(\n                hex(idt_obj.address), len(cr3_candidates)\n            )\n        )\n\n        # Collect the page containig each virtual addresses defined inside interrupt handlers\n        handlers_pages = set()\n        for handler in idt_obj.entries:\n            # Task Entry does not point to interrupt hanlder\n            if isinstance(handler, IDTTaskEntry32):\n                continue\n\n            # Ignore handler unused\n            if not handler.p:\n                continue\n\n            handlers_pages.add(handler.offset &gt;&gt; 12 &lt;&lt; 12)\n\n        # Try to resolve interrupt virtual addresses and count the number of unresolved interrupt handlers\n        cr3s_for_idt = []\n        for cr3_candidate in cr3_candidates:\n            errors = 0\n            for vaddr in handlers_pages:\n                paddr = self.resolve_vaddr(cr3_candidate, vaddr)\n                if paddr == -1:\n                    logging.debug(\n                        f\"find_radix_trees(): {hex(cr3_candidate)} failed to solve {hex(vaddr)}\"\n                    )\n                    errors += 1\n\n            cr3s_for_idt.append([cr3_candidate, errors])\n\n        # At least one CR3 must be found...\n        if not cr3s_for_idt:\n            continue\n\n        # Save only CR3s which resolv the max number of addresses\n        cr3s_for_idt.sort(key=lambda x: (x[1], x[0]))\n        max_value = cr3s_for_idt[0][1]\n        logger.debug(\n            \"Interrupt pages: {}, Maximum pages resolved: {}\".format(\n                len(handlers_pages), len(handlers_pages) - max_value\n            )\n        )\n\n        # Consider only CR3 which resolve the maximum number of interrupt pages\n        for cr3 in cr3s_for_idt:\n            if max_value != cr3[1]:\n                break\n\n            # Extract an approximation of the kernel and user physical address space\n            consistency, pas = self.physpace(\n                cr3[0],\n                self.data.page_tables[\"global\"],\n                self.data.empty_tables,\n                hierarchical=True,\n            )\n\n            # Only consistent trees are valid\n            if not consistency:\n                continue\n\n            # Esclude empty trees\n            if pas.get_kernel_size() == pas.get_user_size() == 0:\n                continue\n\n            vas = self.virtspace(\n                cr3[0], 0, self.machine.mmu.top_prefix, hierarchical=True\n            )\n            cr3s[idt_obj.address][cr3[0]] = RadixTree(cr3[0], 0, pas, vas)\n\n    self.data.cr3s = cr3s\n    self.data.is_radix_found = True\n</code></pre>"},{"location":"reference/architectures/intel/#mmushell.architectures.intel.MMUShell.do_parse_memory","title":"<code>do_parse_memory(args)</code>","text":"<p>Find MMU tables and IDTs</p> Source code in <code>mmushell/architectures/intel.py</code> <pre><code>def do_parse_memory(self, args):\n    \"\"\"Find MMU tables and IDTs\"\"\"\n    if self.data.is_mem_parsed:\n        logger.warning(\"Memory already parsed\")\n        return\n\n    if type(self.machine.mmu) is IA32:\n        self.parse_memory_ia32()\n    elif type(self.machine.mmu) is PAE:\n        self.parse_memory_pae()\n    elif type(self.machine.mmu) is IA64:\n        self.parse_memory_ia64()\n    else:\n        logging.fatal(\"OOPS... MMU class unkown!\")\n        exit(-1)\n    self.data.is_mem_parsed = True\n</code></pre>"},{"location":"reference/architectures/intel/#mmushell.architectures.intel.MMUShell.do_show_idt","title":"<code>do_show_idt(args)</code>","text":"<p>Show the IDT at a chosen address. Usage: show_idt ADDRESS</p> Source code in <code>mmushell/architectures/intel.py</code> <pre><code>def do_show_idt(self, args):\n    \"\"\"Show the IDT at a chosen address. Usage: show_idt ADDRESS\"\"\"\n    args = args.split()\n    if len(args) &lt; 1:\n        logger.warning(\"Missing table address\")\n        return\n\n    try:\n        addr = self.parse_int(args[0])\n    except ValueError:\n        logger.warning(\"Invalid table address\")\n        return\n\n    print(self.machine.cpu.parse_idt(addr))\n</code></pre>"},{"location":"reference/architectures/intel/#mmushell.architectures.intel.MMUShell.do_show_idtrs","title":"<code>do_show_idtrs(args)</code>","text":"<p>Show IDT tables founds</p> Source code in <code>mmushell/architectures/intel.py</code> <pre><code>def do_show_idtrs(self, args):\n    \"\"\"Show IDT tables founds\"\"\"\n    if not self.data.is_radix_found:\n        logging.info(\"Please, find them first!\")\n        return\n\n    table = PrettyTable()\n    table.field_names = [\"Address\", \"Size\"]\n    for idt in self.data.idts:\n        table.add_row([hex(idt.address), idt.size])\n    print(table)\n</code></pre>"},{"location":"reference/architectures/intel/#mmushell.architectures.intel.MMUShell.do_show_radix_trees","title":"<code>do_show_radix_trees(args)</code>","text":"<p>Show radix trees found able to address a chosen IDT table. Usage: show_radix_trees PHY_IDT_ADDRESS</p> Source code in <code>mmushell/architectures/intel.py</code> <pre><code>def do_show_radix_trees(self, args):\n    \"\"\"Show radix trees found able to address a chosen IDT table. Usage: show_radix_trees PHY_IDT_ADDRESS\"\"\"\n    if not self.data.is_radix_found:\n        logging.info(\"Please, find them first!\")\n        return\n\n    # Check if the IDT requested is in the list of IDT found\n    args = args.split()\n    if len(args) &lt; 1:\n        logging.warning(\"Missing IDT\")\n        return\n    idt_addr = self.parse_int(args[0])\n\n    if not self.data.idts:\n        logging.info(\"No IDT found by MMUShell\")\n        idt_addr = -1\n    else:\n        for idt in self.data.idts:\n            if idt_addr == idt.address:\n                break\n        else:\n            logging.warning(\"IDT requested not in IDT found!\")\n            return\n\n    # Show results\n    labels = [\n        \"Radix address\",\n        \"First level\",\n        \"Kernel size (Bytes)\",\n        \"User size (Bytes)\",\n    ]\n    table = PrettyTable()\n    table.field_names = labels\n    for cr3 in self.data.cr3s[idt_addr].values():\n        table.add_row(cr3.entry_resume_stringified())\n    table.sortby = \"Radix address\"\n    print(table)\n</code></pre>"},{"location":"reference/architectures/intel/#mmushell.architectures.intel.MMUShell.do_show_table","title":"<code>do_show_table(args)</code>","text":"<p>Show an MMU table at a chosen address. Usage: show_table ADDRESS [level]</p> Source code in <code>mmushell/architectures/intel.py</code> <pre><code>def do_show_table(self, args):\n    \"\"\"Show an MMU table at a chosen address. Usage: show_table ADDRESS [level]\"\"\"\n    args = args.split()\n    if len(args) &lt; 1:\n        logger.warning(\"Missing table address\")\n        return\n\n    try:\n        addr = self.parse_int(args[0])\n    except ValueError:\n        logger.warning(\"Invalid table address\")\n        return\n\n    if addr not in self.machine.memory:\n        logger.warning(\"Table not in RAM range\")\n        return\n\n    lvl = -1\n    if len(args) &gt; 1:\n        try:\n            lvl = self.parse_int(args[1])\n            if lvl &gt; (self.machine.mmu.radix_levels[\"global\"] - 1):\n                raise ValueError\n        except ValueError:\n            logger.warning(\n                \"Level must be an integer between 0 and {}\".format(\n                    str(self.machine.mmu.radix_levels[\"global\"] - 1)\n                )\n            )\n            return\n\n    if lvl == -1:\n        table_size = self.machine.mmu.PAGE_SIZE\n    else:\n        table_size = self.machine.mmu.map_level_to_table_size[\"global\"][lvl]\n    table_buff = self.machine.memory.get_data(addr, table_size)\n    invalids, pt_classes, table_obj = self.machine.mmu.parse_frame(\n        table_buff, addr, table_size, lvl\n    )\n    print(table_obj)\n    print(f\"Invalid entries: {invalids} Table levels: {pt_classes}\")\n</code></pre>"},{"location":"reference/architectures/intel/#mmushell.architectures.intel.MMUShellGTruth","title":"<code>MMUShellGTruth</code>","text":"<p>             Bases: <code>MMUShell</code></p> Source code in <code>mmushell/architectures/intel.py</code> <pre><code>class MMUShellGTruth(MMUShell):\n    def do_show_idtrs_gtruth(self, args):\n        \"\"\"Compare IDTs found with the ground truth\"\"\"\n        if not self.data.is_mem_parsed:\n            logging.info(\"Please, find them first!\")\n            return\n\n        # We need to use a CR3 to translate the IDTR in virtual address, we use the last CR3 defined\n        cr3_class = self.machine.mmu.cr3_class\n\n        # Filter CR3 for valid one and the find the last used one\n        keys = list(self.gtruth[\"CR3\"].keys())\n        keys.sort(key=lambda x: self.gtruth[\"CR3\"][x][1], reverse=True)\n\n        for cr3 in keys:\n            cr3_obj = cr3_class(cr3)\n\n            # Validate CR3\n            if cr3_obj.address not in self.data.page_tables[\"global\"][0]:\n                continue\n            consistency, pas = self.physpace(\n                cr3_obj.address,\n                self.data.page_tables[\"global\"],\n                self.data.empty_tables,\n                hierarchical=True,\n            )\n            if not consistency or (\n                not pas.get_kernel_size() and not pas.get_user_size()\n            ):\n                continue\n            else:\n                valid_cr3_obj = cr3_obj\n                break\n        else:\n            logging.warning(\"OOPS.. no valid CR3 found\")\n            return\n\n        # Collect all found physical addresses\n        idts = [x.address for x in self.data.idts]\n\n        # Resolve the IDT virtual address\n        table = PrettyTable()\n        table.field_names = [\n            \"Virtual address\",\n            \"Physical address\",\n            \"Found\",\n            \"First seen\",\n            \"Last seen\",\n        ]\n\n        tp = 0\n        unresolved = 0\n        keys = list(self.gtruth[\"IDTR\"].keys())\n        keys.sort(key=lambda x: self.gtruth[\"IDTR\"][x][1])\n        for idtr in keys:\n            idtr_obj = IDTR(idtr)\n\n            paddr = self.resolve_vaddr(valid_cr3_obj.address, idtr_obj.address)\n            # Not solved by the CR3...\n            if paddr == -1:\n                unresolved += 1\n                table.add_row(\n                    [\n                        hex(idtr_obj.address),\n                        \"?\",\n                        \"?\",\n                        self.gtruth[\"IDTR\"][idtr_obj.value][0],\n                        self.gtruth[\"IDTR\"][idtr_obj.value][1],\n                    ]\n                )\n            else:\n                if paddr in idts:\n                    tp += 1\n                    found = \"X\"\n                else:\n                    found = \"\"\n                table.add_row(\n                    [\n                        hex(idtr_obj.address),\n                        hex(paddr),\n                        found,\n                        self.gtruth[\"IDTR\"][idtr_obj.value][0],\n                        self.gtruth[\"IDTR\"][idtr_obj.value][1],\n                    ]\n                )\n\n        print(f\"Use CR3 address: {hex(valid_cr3_obj.address)}\")\n        print(table)\n        print(f\"TP:{tp} FP:{len(idts) - tp} Unresolved: {unresolved}\")\n\n        # Export results for next analysis\n        if len(args) == 2 and args[1] == \"export\":\n            from pickle import dump as dump_p\n\n            with open(\"dump.mmu\", \"wb\") as f:\n                results = [{\"cr3\": tp} for tp in sorted(tps)]\n                dump_p(results, f)\n\n    def do_show_radix_trees_gtruth(self, args):\n        \"\"\"Compare radix trees found able to address a chosen IDT table with the ground truth. Usage: show_radix_trees_gtruth PHY_IDT_ADDRESS\"\"\"\n        if not self.data.is_radix_found:\n            logging.info(\"Please, find them first!\")\n            return\n\n        # Check if the IDT requested is in the list of IDT found\n        args = args.split()\n        if len(args) &lt; 1:\n            logging.warning(\"Missing IDT\")\n            return\n        idt_addr = self.parse_int(args[0])\n        if idt_addr not in self.machine.memory:\n            logging.warning(\"IDT address not in RAM\")\n            return\n\n        if not self.data.idts:\n            # If no valid IDT has been found by MMUShell, it parses and uses the IDT\n            # address pass by the user as filter to identify TP radix trees\n            logging.info(\"No IDT found by MMUShell\")\n\n            # Parse IDT\n            idt = self.machine.cpu.parse_idt(idt_addr)\n            if not len(idt):\n                logging.warning(\"No IDT at address\")\n                return\n        else:\n            for idt in self.data.idts:\n                if idt_addr == idt.address:\n                    break\n            else:\n                logging.warning(\"IDT requested not in IDT found!\")\n                return\n\n        # Collect all valid CR3\n        latest_idt_va_used = IDTR(\n            sorted(\n                list(self.gtruth[\"IDTR\"].keys()),\n                key=lambda x: self.gtruth[\"IDTR\"][x][1],\n            )[-1]\n        )\n        idts = {}\n        cr3_errors = defaultdict(list)\n\n        for cr3 in self.gtruth[\"CR3\"]:\n            cr3_obj = self.machine.mmu.cr3_class(cr3)\n            if cr3_obj.address not in self.data.page_tables[\"global\"][0]:\n                continue\n            consistency, pas = self.physpace(\n                cr3_obj.address,\n                self.data.page_tables[\"global\"],\n                self.data.empty_tables,\n                hierarchical=True,\n            )\n            if not consistency or (\n                not pas.get_kernel_size() and not pas.get_user_size()\n            ):\n                continue\n\n            # Check if they are able to address the IDT table\n            derived_addresses = self.machine.mmu.derive_page_address(\n                idt_addr &gt;&gt; 12 &lt;&lt; 12\n            )\n            if not any([x[1] in pas for x in derived_addresses]):\n                continue  # Trick! Only one dataclass per level\n\n            # Check if the CR3 is able to resolve the latest IDTR value used\n            # (we check this for simplicity instead of the VA associated with the selected IDT)\n            idt_phys = self.resolve_vaddr(cr3_obj.address, latest_idt_va_used.address)\n            if idt_phys == -1 or idt_phys not in self.machine.memory:\n                continue\n\n            # Collect interrupt VA for resolved IDR\n            if idt_phys not in idts:\n                vas_interrupts = set()\n                idt_obj = self.machine.cpu.parse_idt(idt_phys)\n                for handler in idt_obj.entries:\n                    if isinstance(handler, IDTTaskEntry32) or not handler.p:\n                        continue\n                    vas_interrupts.add(handler.offset &gt;&gt; 12 &lt;&lt; 12)\n                idts[idt_phys] = vas_interrupts\n\n            # Check how much IDT interrupt VA is able to resolve\n            errors = 0\n            for va in idts[idt_phys]:\n                if self.resolve_vaddr(cr3_obj.address, va) == -1:\n                    errors += 1\n            cr3_errors[errors].append(cr3_obj)\n\n        # Use only CR3 with the minimum number of errors\n        valid_cr3s = {}\n        for cr3_obj in cr3_errors[sorted(list(cr3_errors.keys()))[0]]:\n            valid_cr3s[cr3_obj.address] = cr3_obj\n\n        # Use fake IDT address if no IDT are found\n        if not self.data.idts:\n            idt_addr = -1\n\n        # True positives, false negatives, false positives\n        tps = set(valid_cr3s.keys()).intersection(set(self.data.cr3s[idt_addr].keys()))\n        fns = set(valid_cr3s.keys()).difference(set(self.data.cr3s[idt_addr].keys()))\n        fps = set(self.data.cr3s[idt_addr].keys()).difference(set(valid_cr3s.keys()))\n\n        # Show results\n        table = PrettyTable()\n        table.field_names = [\"Address\", \"Found\", \"First seen\", \"Last seen\"]\n        for tp in sorted(tps):\n            table.add_row(\n                [\n                    hex(tp),\n                    \"X\",\n                    self.gtruth[\"CR3\"][valid_cr3s[tp].value][0],\n                    self.gtruth[\"CR3\"][valid_cr3s[tp].value][1],\n                ]\n            )\n\n        for fn in sorted(fns):\n            table.add_row(\n                [\n                    hex(fn),\n                    \"\",\n                    self.gtruth[\"CR3\"][valid_cr3s[fn].value][0],\n                    self.gtruth[\"CR3\"][valid_cr3s[fn].value][1],\n                ]\n            )\n\n        for fp in sorted(fps):\n            table.add_row([hex(fp), \"False positive\", \"\", \"\"])\n\n        print(table)\n        print(f\"TP:{len(tps)} FN:{len(fns)} FP:{len(fps)}\")\n\n        # Export results for next analysis\n        if len(args) == 2 and args[1] == \"export\":\n            from pickle import dump as dump_p\n\n            with open(\"dump.mmu\", \"wb\") as f:\n                results = [{\"cr3\": tp} for tp in sorted(tps)]\n                dump_p(results, f)\n</code></pre>"},{"location":"reference/architectures/intel/#mmushell.architectures.intel.MMUShellGTruth.do_show_idtrs_gtruth","title":"<code>do_show_idtrs_gtruth(args)</code>","text":"<p>Compare IDTs found with the ground truth</p> Source code in <code>mmushell/architectures/intel.py</code> <pre><code>def do_show_idtrs_gtruth(self, args):\n    \"\"\"Compare IDTs found with the ground truth\"\"\"\n    if not self.data.is_mem_parsed:\n        logging.info(\"Please, find them first!\")\n        return\n\n    # We need to use a CR3 to translate the IDTR in virtual address, we use the last CR3 defined\n    cr3_class = self.machine.mmu.cr3_class\n\n    # Filter CR3 for valid one and the find the last used one\n    keys = list(self.gtruth[\"CR3\"].keys())\n    keys.sort(key=lambda x: self.gtruth[\"CR3\"][x][1], reverse=True)\n\n    for cr3 in keys:\n        cr3_obj = cr3_class(cr3)\n\n        # Validate CR3\n        if cr3_obj.address not in self.data.page_tables[\"global\"][0]:\n            continue\n        consistency, pas = self.physpace(\n            cr3_obj.address,\n            self.data.page_tables[\"global\"],\n            self.data.empty_tables,\n            hierarchical=True,\n        )\n        if not consistency or (\n            not pas.get_kernel_size() and not pas.get_user_size()\n        ):\n            continue\n        else:\n            valid_cr3_obj = cr3_obj\n            break\n    else:\n        logging.warning(\"OOPS.. no valid CR3 found\")\n        return\n\n    # Collect all found physical addresses\n    idts = [x.address for x in self.data.idts]\n\n    # Resolve the IDT virtual address\n    table = PrettyTable()\n    table.field_names = [\n        \"Virtual address\",\n        \"Physical address\",\n        \"Found\",\n        \"First seen\",\n        \"Last seen\",\n    ]\n\n    tp = 0\n    unresolved = 0\n    keys = list(self.gtruth[\"IDTR\"].keys())\n    keys.sort(key=lambda x: self.gtruth[\"IDTR\"][x][1])\n    for idtr in keys:\n        idtr_obj = IDTR(idtr)\n\n        paddr = self.resolve_vaddr(valid_cr3_obj.address, idtr_obj.address)\n        # Not solved by the CR3...\n        if paddr == -1:\n            unresolved += 1\n            table.add_row(\n                [\n                    hex(idtr_obj.address),\n                    \"?\",\n                    \"?\",\n                    self.gtruth[\"IDTR\"][idtr_obj.value][0],\n                    self.gtruth[\"IDTR\"][idtr_obj.value][1],\n                ]\n            )\n        else:\n            if paddr in idts:\n                tp += 1\n                found = \"X\"\n            else:\n                found = \"\"\n            table.add_row(\n                [\n                    hex(idtr_obj.address),\n                    hex(paddr),\n                    found,\n                    self.gtruth[\"IDTR\"][idtr_obj.value][0],\n                    self.gtruth[\"IDTR\"][idtr_obj.value][1],\n                ]\n            )\n\n    print(f\"Use CR3 address: {hex(valid_cr3_obj.address)}\")\n    print(table)\n    print(f\"TP:{tp} FP:{len(idts) - tp} Unresolved: {unresolved}\")\n\n    # Export results for next analysis\n    if len(args) == 2 and args[1] == \"export\":\n        from pickle import dump as dump_p\n\n        with open(\"dump.mmu\", \"wb\") as f:\n            results = [{\"cr3\": tp} for tp in sorted(tps)]\n            dump_p(results, f)\n</code></pre>"},{"location":"reference/architectures/intel/#mmushell.architectures.intel.MMUShellGTruth.do_show_radix_trees_gtruth","title":"<code>do_show_radix_trees_gtruth(args)</code>","text":"<p>Compare radix trees found able to address a chosen IDT table with the ground truth. Usage: show_radix_trees_gtruth PHY_IDT_ADDRESS</p> Source code in <code>mmushell/architectures/intel.py</code> <pre><code>def do_show_radix_trees_gtruth(self, args):\n    \"\"\"Compare radix trees found able to address a chosen IDT table with the ground truth. Usage: show_radix_trees_gtruth PHY_IDT_ADDRESS\"\"\"\n    if not self.data.is_radix_found:\n        logging.info(\"Please, find them first!\")\n        return\n\n    # Check if the IDT requested is in the list of IDT found\n    args = args.split()\n    if len(args) &lt; 1:\n        logging.warning(\"Missing IDT\")\n        return\n    idt_addr = self.parse_int(args[0])\n    if idt_addr not in self.machine.memory:\n        logging.warning(\"IDT address not in RAM\")\n        return\n\n    if not self.data.idts:\n        # If no valid IDT has been found by MMUShell, it parses and uses the IDT\n        # address pass by the user as filter to identify TP radix trees\n        logging.info(\"No IDT found by MMUShell\")\n\n        # Parse IDT\n        idt = self.machine.cpu.parse_idt(idt_addr)\n        if not len(idt):\n            logging.warning(\"No IDT at address\")\n            return\n    else:\n        for idt in self.data.idts:\n            if idt_addr == idt.address:\n                break\n        else:\n            logging.warning(\"IDT requested not in IDT found!\")\n            return\n\n    # Collect all valid CR3\n    latest_idt_va_used = IDTR(\n        sorted(\n            list(self.gtruth[\"IDTR\"].keys()),\n            key=lambda x: self.gtruth[\"IDTR\"][x][1],\n        )[-1]\n    )\n    idts = {}\n    cr3_errors = defaultdict(list)\n\n    for cr3 in self.gtruth[\"CR3\"]:\n        cr3_obj = self.machine.mmu.cr3_class(cr3)\n        if cr3_obj.address not in self.data.page_tables[\"global\"][0]:\n            continue\n        consistency, pas = self.physpace(\n            cr3_obj.address,\n            self.data.page_tables[\"global\"],\n            self.data.empty_tables,\n            hierarchical=True,\n        )\n        if not consistency or (\n            not pas.get_kernel_size() and not pas.get_user_size()\n        ):\n            continue\n\n        # Check if they are able to address the IDT table\n        derived_addresses = self.machine.mmu.derive_page_address(\n            idt_addr &gt;&gt; 12 &lt;&lt; 12\n        )\n        if not any([x[1] in pas for x in derived_addresses]):\n            continue  # Trick! Only one dataclass per level\n\n        # Check if the CR3 is able to resolve the latest IDTR value used\n        # (we check this for simplicity instead of the VA associated with the selected IDT)\n        idt_phys = self.resolve_vaddr(cr3_obj.address, latest_idt_va_used.address)\n        if idt_phys == -1 or idt_phys not in self.machine.memory:\n            continue\n\n        # Collect interrupt VA for resolved IDR\n        if idt_phys not in idts:\n            vas_interrupts = set()\n            idt_obj = self.machine.cpu.parse_idt(idt_phys)\n            for handler in idt_obj.entries:\n                if isinstance(handler, IDTTaskEntry32) or not handler.p:\n                    continue\n                vas_interrupts.add(handler.offset &gt;&gt; 12 &lt;&lt; 12)\n            idts[idt_phys] = vas_interrupts\n\n        # Check how much IDT interrupt VA is able to resolve\n        errors = 0\n        for va in idts[idt_phys]:\n            if self.resolve_vaddr(cr3_obj.address, va) == -1:\n                errors += 1\n        cr3_errors[errors].append(cr3_obj)\n\n    # Use only CR3 with the minimum number of errors\n    valid_cr3s = {}\n    for cr3_obj in cr3_errors[sorted(list(cr3_errors.keys()))[0]]:\n        valid_cr3s[cr3_obj.address] = cr3_obj\n\n    # Use fake IDT address if no IDT are found\n    if not self.data.idts:\n        idt_addr = -1\n\n    # True positives, false negatives, false positives\n    tps = set(valid_cr3s.keys()).intersection(set(self.data.cr3s[idt_addr].keys()))\n    fns = set(valid_cr3s.keys()).difference(set(self.data.cr3s[idt_addr].keys()))\n    fps = set(self.data.cr3s[idt_addr].keys()).difference(set(valid_cr3s.keys()))\n\n    # Show results\n    table = PrettyTable()\n    table.field_names = [\"Address\", \"Found\", \"First seen\", \"Last seen\"]\n    for tp in sorted(tps):\n        table.add_row(\n            [\n                hex(tp),\n                \"X\",\n                self.gtruth[\"CR3\"][valid_cr3s[tp].value][0],\n                self.gtruth[\"CR3\"][valid_cr3s[tp].value][1],\n            ]\n        )\n\n    for fn in sorted(fns):\n        table.add_row(\n            [\n                hex(fn),\n                \"\",\n                self.gtruth[\"CR3\"][valid_cr3s[fn].value][0],\n                self.gtruth[\"CR3\"][valid_cr3s[fn].value][1],\n            ]\n        )\n\n    for fp in sorted(fps):\n        table.add_row([hex(fp), \"False positive\", \"\", \"\"])\n\n    print(table)\n    print(f\"TP:{len(tps)} FN:{len(fns)} FP:{len(fps)}\")\n\n    # Export results for next analysis\n    if len(args) == 2 and args[1] == \"export\":\n        from pickle import dump as dump_p\n\n        with open(\"dump.mmu\", \"wb\") as f:\n            results = [{\"cr3\": tp} for tp in sorted(tps)]\n            dump_p(results, f)\n</code></pre>"},{"location":"reference/architectures/mips/","title":"MIPS","text":""},{"location":"reference/architectures/mips/#mips","title":"MIPS","text":""},{"location":"reference/architectures/mips/#mmushell.architectures.mips.MMUShell","title":"<code>MMUShell</code>","text":"<p>             Bases: <code>MMUShell</code></p> Source code in <code>mmushell/architectures/mips.py</code> <pre><code>class MMUShell(MMUShellDefault):\n    def __init__(self, completekey=\"tab\", stdin=None, stdout=None, machine={}):\n        super(MMUShell, self).__init__(completekey, stdin, stdout, machine)\n\n        if not self.data:\n            self.data = Data(\n                is_mem_parsed=False,\n                is_registers_found=False,\n                opcodes={},\n                regs_values={},\n            )\n\n    def do_parse_memory(self, args):\n        \"\"\"Find MMU related opcodes in dump\"\"\"\n        if self.data.is_mem_parsed:\n            logger.warning(\"Memory already parsed\")\n            return\n\n        self.parse_memory()\n        self.data.is_mem_parsed = True\n\n    def parse_memory(self):\n        logger.info(\"Look for opcodes related to MMU setup...\")\n        parallel_results = self.machine.apply_parallel(\n            self.machine.mmu.PAGE_SIZE,\n            self.machine.cpu.parse_opcodes_parallel,\n            max_address=self.machine.cpu.processor_features[\"kern_code_phys_end\"],\n        )\n\n        opcodes = {}\n        logger.info(\"Reaggregate threads data...\")\n        for result in parallel_results:\n            opcodes.update(result.get())\n\n        self.data.opcodes = opcodes\n\n    def do_find_registers_values(self, arg):\n        \"\"\"Find and execute MMU related functions inside the memory dump in order to extract MMU registers values\"\"\"\n\n        if not self.data.is_mem_parsed:\n            logging.warning(\"First parse the dump!\")\n            return\n\n        if self.data.is_registers_found:\n            logging.warning(\"Registers already searched\")\n            return\n\n        logging.info(\"This analysis could be extremely slow!\")\n        logging.info(\"Use heuristics to find function addresses...\")\n        self.machine.cpu.identify_functions_start(self.data.opcodes)\n\n        logging.info(\"Identify register values using data flow analysis...\")\n\n        # We use data flow analysis and merge the results\n        dataflow_values = self.machine.cpu.find_registers_values_dataflow(\n            self.data.opcodes, zero_registers=[\"ZERO\"]\n        )\n\n        filtered_values = defaultdict(set)\n        for register, values in dataflow_values.items():\n            for value in values:\n                reg_obj = CPURegMIPS.get_register_obj(register, value)\n                if reg_obj.valid:\n                    filtered_values[register].add(reg_obj)\n\n        # Add default values\n        for register, value in self.machine.cpu.registers_values.items():\n            if (\n                register\n                not in self.machine.cpu.processor_features[\n                    \"opcode_to_mmu_regs\"\n                ].values()\n            ):\n                continue\n\n            reg_obj = CPURegMIPS.get_register_obj(register, value)\n            if reg_obj.valid and all(\n                [not reg_obj.is_mmu_equivalent_to(x) for x in filtered_values[register]]\n            ):\n                filtered_values[register].add(reg_obj)\n\n        self.data.regs_values = filtered_values\n        self.data.is_registers_found = True\n\n    def do_show_registers(self, args):\n        \"\"\"Show recovered registers values\"\"\"\n        if not self.data.is_registers_found:\n            logging.info(\"Please, find them first!\")\n            return\n\n        for registers in sorted(self.data.regs_values.keys()):\n            for register in self.data.regs_values[registers]:\n                print(register)\n</code></pre>"},{"location":"reference/architectures/mips/#mmushell.architectures.mips.MMUShell.do_find_registers_values","title":"<code>do_find_registers_values(arg)</code>","text":"<p>Find and execute MMU related functions inside the memory dump in order to extract MMU registers values</p> Source code in <code>mmushell/architectures/mips.py</code> <pre><code>def do_find_registers_values(self, arg):\n    \"\"\"Find and execute MMU related functions inside the memory dump in order to extract MMU registers values\"\"\"\n\n    if not self.data.is_mem_parsed:\n        logging.warning(\"First parse the dump!\")\n        return\n\n    if self.data.is_registers_found:\n        logging.warning(\"Registers already searched\")\n        return\n\n    logging.info(\"This analysis could be extremely slow!\")\n    logging.info(\"Use heuristics to find function addresses...\")\n    self.machine.cpu.identify_functions_start(self.data.opcodes)\n\n    logging.info(\"Identify register values using data flow analysis...\")\n\n    # We use data flow analysis and merge the results\n    dataflow_values = self.machine.cpu.find_registers_values_dataflow(\n        self.data.opcodes, zero_registers=[\"ZERO\"]\n    )\n\n    filtered_values = defaultdict(set)\n    for register, values in dataflow_values.items():\n        for value in values:\n            reg_obj = CPURegMIPS.get_register_obj(register, value)\n            if reg_obj.valid:\n                filtered_values[register].add(reg_obj)\n\n    # Add default values\n    for register, value in self.machine.cpu.registers_values.items():\n        if (\n            register\n            not in self.machine.cpu.processor_features[\n                \"opcode_to_mmu_regs\"\n            ].values()\n        ):\n            continue\n\n        reg_obj = CPURegMIPS.get_register_obj(register, value)\n        if reg_obj.valid and all(\n            [not reg_obj.is_mmu_equivalent_to(x) for x in filtered_values[register]]\n        ):\n            filtered_values[register].add(reg_obj)\n\n    self.data.regs_values = filtered_values\n    self.data.is_registers_found = True\n</code></pre>"},{"location":"reference/architectures/mips/#mmushell.architectures.mips.MMUShell.do_parse_memory","title":"<code>do_parse_memory(args)</code>","text":"<p>Find MMU related opcodes in dump</p> Source code in <code>mmushell/architectures/mips.py</code> <pre><code>def do_parse_memory(self, args):\n    \"\"\"Find MMU related opcodes in dump\"\"\"\n    if self.data.is_mem_parsed:\n        logger.warning(\"Memory already parsed\")\n        return\n\n    self.parse_memory()\n    self.data.is_mem_parsed = True\n</code></pre>"},{"location":"reference/architectures/mips/#mmushell.architectures.mips.MMUShell.do_show_registers","title":"<code>do_show_registers(args)</code>","text":"<p>Show recovered registers values</p> Source code in <code>mmushell/architectures/mips.py</code> <pre><code>def do_show_registers(self, args):\n    \"\"\"Show recovered registers values\"\"\"\n    if not self.data.is_registers_found:\n        logging.info(\"Please, find them first!\")\n        return\n\n    for registers in sorted(self.data.regs_values.keys()):\n        for register in self.data.regs_values[registers]:\n            print(register)\n</code></pre>"},{"location":"reference/architectures/mips/#mmushell.architectures.mips.MMUShellGTruth","title":"<code>MMUShellGTruth</code>","text":"<p>             Bases: <code>MMUShell</code></p> Source code in <code>mmushell/architectures/mips.py</code> <pre><code>class MMUShellGTruth(MMUShell):\n    def do_show_registers_gtruth(self, args):\n        \"\"\"Show recovered registers values and compare them with the ground truth\"\"\"\n        if not self.data.is_registers_found:\n            logging.info(\"Please, find them first!\")\n            return\n\n        # Collect ground truth values as last register values loaded or default ones\n        mmu_regs = self.machine.cpu.processor_features[\"opcode_to_mmu_regs\"].values()\n        gvalues = {}\n        for reg_name in mmu_regs:\n            if reg_name in self.gtruth:\n                last_reg_value = sorted(\n                    self.gtruth[reg_name].keys(),\n                    key=lambda x: self.gtruth[reg_name][x][1],\n                )[-1]\n                gvalues[reg_name] = CPURegMIPS.get_register_obj(\n                    reg_name, last_reg_value\n                )\n            elif reg_name in self.machine.cpu.registers_values:\n                gvalues[reg_name] = CPURegMIPS.get_register_obj(\n                    reg_name, self.machine.cpu.registers_values[reg_name]\n                )\n\n        tps = defaultdict(list)\n        fps = defaultdict(list)\n        fns = {}\n\n        tps_count = 0\n        fps_count = 0\n\n        # Check between value recovered with dataflow analisys\n        for register, register_obj in gvalues.items():\n            tmp_fps = []\n            tmp_fps_count = 0\n            for found_value in self.data.regs_values[register]:\n                if register_obj.is_mmu_equivalent_to(found_value):\n                    # Count only one TP per register\n                    if register not in tps:\n                        tps_count += 1\n                    tps[register].append(found_value)\n                else:\n                    # Count only FP not equivalent among them\n                    if all(\n                        [not found_value.is_mmu_equivalent_to(x) for x in fps[register]]\n                    ):\n                        tmp_fps_count += 1\n                    tmp_fps.append(found_value)\n\n            # Add false negatives\n            if register not in tps:\n                fns[register] = register_obj\n            else:  # Add false positives only if it is not a false negative\n                fps[register] = tmp_fps\n                fps_count += tmp_fps_count\n\n        print(\"\\nTrue positives\")\n        pprint(tps)\n\n        print(\"\\nFalse positives\")\n        pprint(fps)\n\n        print(\"\\nFalse negatives\")\n        pprint(fns)\n        print(f\"\\nTP:{tps_count}, FP:{fps_count}, FN:{len(fns)}\")\n</code></pre>"},{"location":"reference/architectures/mips/#mmushell.architectures.mips.MMUShellGTruth.do_show_registers_gtruth","title":"<code>do_show_registers_gtruth(args)</code>","text":"<p>Show recovered registers values and compare them with the ground truth</p> Source code in <code>mmushell/architectures/mips.py</code> <pre><code>def do_show_registers_gtruth(self, args):\n    \"\"\"Show recovered registers values and compare them with the ground truth\"\"\"\n    if not self.data.is_registers_found:\n        logging.info(\"Please, find them first!\")\n        return\n\n    # Collect ground truth values as last register values loaded or default ones\n    mmu_regs = self.machine.cpu.processor_features[\"opcode_to_mmu_regs\"].values()\n    gvalues = {}\n    for reg_name in mmu_regs:\n        if reg_name in self.gtruth:\n            last_reg_value = sorted(\n                self.gtruth[reg_name].keys(),\n                key=lambda x: self.gtruth[reg_name][x][1],\n            )[-1]\n            gvalues[reg_name] = CPURegMIPS.get_register_obj(\n                reg_name, last_reg_value\n            )\n        elif reg_name in self.machine.cpu.registers_values:\n            gvalues[reg_name] = CPURegMIPS.get_register_obj(\n                reg_name, self.machine.cpu.registers_values[reg_name]\n            )\n\n    tps = defaultdict(list)\n    fps = defaultdict(list)\n    fns = {}\n\n    tps_count = 0\n    fps_count = 0\n\n    # Check between value recovered with dataflow analisys\n    for register, register_obj in gvalues.items():\n        tmp_fps = []\n        tmp_fps_count = 0\n        for found_value in self.data.regs_values[register]:\n            if register_obj.is_mmu_equivalent_to(found_value):\n                # Count only one TP per register\n                if register not in tps:\n                    tps_count += 1\n                tps[register].append(found_value)\n            else:\n                # Count only FP not equivalent among them\n                if all(\n                    [not found_value.is_mmu_equivalent_to(x) for x in fps[register]]\n                ):\n                    tmp_fps_count += 1\n                tmp_fps.append(found_value)\n\n        # Add false negatives\n        if register not in tps:\n            fns[register] = register_obj\n        else:  # Add false positives only if it is not a false negative\n            fps[register] = tmp_fps\n            fps_count += tmp_fps_count\n\n    print(\"\\nTrue positives\")\n    pprint(tps)\n\n    print(\"\\nFalse positives\")\n    pprint(fps)\n\n    print(\"\\nFalse negatives\")\n    pprint(fns)\n    print(f\"\\nTP:{tps_count}, FP:{fps_count}, FN:{len(fns)}\")\n</code></pre>"},{"location":"reference/architectures/ppc/","title":"PowerPC","text":""},{"location":"reference/architectures/ppc/#powerpc","title":"PowerPC","text":""},{"location":"reference/architectures/ppc/#mmushell.architectures.ppc.MMUShell","title":"<code>MMUShell</code>","text":"<p>             Bases: <code>MMUShell</code></p> Source code in <code>mmushell/architectures/ppc.py</code> <pre><code>class MMUShell(MMUShellDefault):\n    def __init__(self, completekey=\"tab\", stdin=None, stdout=None, machine={}):\n        super(MMUShell, self).__init__(completekey, stdin, stdout, machine)\n\n        if not self.data:\n            self.data = Data(\n                is_mem_parsed=False,\n                is_registers_found=False,\n                opcodes={},\n                regs_values={},\n                htables={},\n            )\n\n    def do_parse_memory(self, args):\n        \"\"\"Parse memory to find opcode MMU related and hash tables\"\"\"\n        if self.data.is_mem_parsed:\n            logger.warning(\"Memory already parsed\")\n            return\n\n        self.parse_memory()\n        self.data.is_mem_parsed = True\n\n    def parse_memory(self):\n        # Collect opcodes and hash table of the minium size\n        (\n            fragments,\n            self.data.opcodes,\n        ) = self.machine.mmu.collect_htable_framents_opcodes()\n\n        # Glue hash table\n        htables = self.machine.mmu.glue_htable_fragments(fragments)\n\n        # Filtering results\n        self.data.htables = self.machine.mmu.filter_htables(htables)\n\n    def do_show_hashtables(self, args):\n        \"\"\"Show hash tables found\"\"\"\n        if not self.data.is_mem_parsed:\n            logger.warning(\"Please, parse the memory first\")\n            return\n\n        table = PrettyTable()\n        table.field_names = [\"Address\", \"Size\"]\n\n        for size in sorted(self.data.htables.keys()):\n            for htable in self.data.htables[size]:\n                table.add_row([hex(htable.address), hex(size)])\n\n        print(table)\n\n    def do_find_registers_values(self, arg):\n        \"\"\"Find and execute MMU related functions inside the memory dump in order to extract MMU registers values\"\"\"\n\n        if not self.data.is_mem_parsed:\n            logging.warning(\"First parse the dump!\")\n            return\n\n        if self.data.is_registers_found:\n            logging.warning(\"Registers already searched\")\n            return\n\n        logging.info(\"This analysis could be extremely slow!\")\n        logging.info(\"Use heuristics to find function addresses...\")\n        self.machine.cpu.identify_functions_start(self.data.opcodes)\n\n        logging.info(\"Identify register values using data flow analysis...\")\n\n        # We use data flow analysis and merge the results\n        dataflow_values = self.machine.cpu.find_registers_values_dataflow(\n            self.data.opcodes, zero_registers=[\"ZERO\"]\n        )\n\n        filtered_values = defaultdict(set)\n        for register, values in dataflow_values.items():\n            for value in values:\n                reg_obj = CPURegPPC.get_register_obj(register, value)\n                if reg_obj.valid:\n                    filtered_values[register].add(reg_obj)\n\n        # Add default values\n        for register, value in self.machine.cpu.registers_values.items():\n            if (\n                register\n                not in self.machine.cpu.processor_features[\n                    \"opcode_to_mmu_regs\"\n                ].values()\n            ):\n                continue\n\n            reg_obj = CPURegPPC.get_register_obj(register, value)\n            if reg_obj.valid and all(\n                [not reg_obj.is_mmu_equivalent_to(x) for x in filtered_values[register]]\n            ):\n                filtered_values[register].add(reg_obj)\n\n        self.data.regs_values = filtered_values\n        self.data.is_registers_found = True\n\n    def do_show_registers(self, args):\n        \"\"\"Show registers values found\"\"\"\n        if not self.data.is_registers_found:\n            logging.info(\"Please, find them first!\")\n            return\n\n        for registers in sorted(self.data.regs_values.keys()):\n            for register in self.data.regs_values[registers]:\n                print(register)\n\n    def do_show_hashtable(self, arg):\n        \"Parse a Hash Table of a given size\"\n        \"Usage: show_hashtable ADDRESS size\"\n\n        arg = arg.split()\n        if len(arg) &lt; 2:\n            logging.error(\"Missing parameter\")\n            return\n\n        try:\n            address = self.parse_int(arg[0])\n            size = self.parse_int(arg[1])\n        except ValueError:\n            logging.error(\"Invalid format\")\n            return\n\n        if address is None:\n            logging.error(\"Invalid address format\")\n            return\n\n        if address not in self.machine.memory:\n            logging.error(\"Address not in memory address space\")\n            return\n\n        valid_sizes = [\n            65536,\n            131072,\n            262144,\n            524288,\n            1048576,\n            2097152,\n            4194304,\n            8388608,\n            16777216,\n            33554432,\n        ]\n        if size not in valid_sizes:\n            logging.error(f\"Invalid order table. Valid sizes are {valid_sizes}\")\n            return\n\n        frame_buf = self.machine.memory.get_data(address, size)\n        table = self.machine.mmu.parse_hash_table(frame_buf, size, address)\n        if table is None:\n            logging.warning(\"Table not present or malformed\")\n        else:\n            print(table)\n</code></pre>"},{"location":"reference/architectures/ppc/#mmushell.architectures.ppc.MMUShell.do_find_registers_values","title":"<code>do_find_registers_values(arg)</code>","text":"<p>Find and execute MMU related functions inside the memory dump in order to extract MMU registers values</p> Source code in <code>mmushell/architectures/ppc.py</code> <pre><code>def do_find_registers_values(self, arg):\n    \"\"\"Find and execute MMU related functions inside the memory dump in order to extract MMU registers values\"\"\"\n\n    if not self.data.is_mem_parsed:\n        logging.warning(\"First parse the dump!\")\n        return\n\n    if self.data.is_registers_found:\n        logging.warning(\"Registers already searched\")\n        return\n\n    logging.info(\"This analysis could be extremely slow!\")\n    logging.info(\"Use heuristics to find function addresses...\")\n    self.machine.cpu.identify_functions_start(self.data.opcodes)\n\n    logging.info(\"Identify register values using data flow analysis...\")\n\n    # We use data flow analysis and merge the results\n    dataflow_values = self.machine.cpu.find_registers_values_dataflow(\n        self.data.opcodes, zero_registers=[\"ZERO\"]\n    )\n\n    filtered_values = defaultdict(set)\n    for register, values in dataflow_values.items():\n        for value in values:\n            reg_obj = CPURegPPC.get_register_obj(register, value)\n            if reg_obj.valid:\n                filtered_values[register].add(reg_obj)\n\n    # Add default values\n    for register, value in self.machine.cpu.registers_values.items():\n        if (\n            register\n            not in self.machine.cpu.processor_features[\n                \"opcode_to_mmu_regs\"\n            ].values()\n        ):\n            continue\n\n        reg_obj = CPURegPPC.get_register_obj(register, value)\n        if reg_obj.valid and all(\n            [not reg_obj.is_mmu_equivalent_to(x) for x in filtered_values[register]]\n        ):\n            filtered_values[register].add(reg_obj)\n\n    self.data.regs_values = filtered_values\n    self.data.is_registers_found = True\n</code></pre>"},{"location":"reference/architectures/ppc/#mmushell.architectures.ppc.MMUShell.do_parse_memory","title":"<code>do_parse_memory(args)</code>","text":"<p>Parse memory to find opcode MMU related and hash tables</p> Source code in <code>mmushell/architectures/ppc.py</code> <pre><code>def do_parse_memory(self, args):\n    \"\"\"Parse memory to find opcode MMU related and hash tables\"\"\"\n    if self.data.is_mem_parsed:\n        logger.warning(\"Memory already parsed\")\n        return\n\n    self.parse_memory()\n    self.data.is_mem_parsed = True\n</code></pre>"},{"location":"reference/architectures/ppc/#mmushell.architectures.ppc.MMUShell.do_show_hashtable","title":"<code>do_show_hashtable(arg)</code>","text":"<p>Parse a Hash Table of a given size</p> Source code in <code>mmushell/architectures/ppc.py</code> <pre><code>def do_show_hashtable(self, arg):\n    \"Parse a Hash Table of a given size\"\n    \"Usage: show_hashtable ADDRESS size\"\n\n    arg = arg.split()\n    if len(arg) &lt; 2:\n        logging.error(\"Missing parameter\")\n        return\n\n    try:\n        address = self.parse_int(arg[0])\n        size = self.parse_int(arg[1])\n    except ValueError:\n        logging.error(\"Invalid format\")\n        return\n\n    if address is None:\n        logging.error(\"Invalid address format\")\n        return\n\n    if address not in self.machine.memory:\n        logging.error(\"Address not in memory address space\")\n        return\n\n    valid_sizes = [\n        65536,\n        131072,\n        262144,\n        524288,\n        1048576,\n        2097152,\n        4194304,\n        8388608,\n        16777216,\n        33554432,\n    ]\n    if size not in valid_sizes:\n        logging.error(f\"Invalid order table. Valid sizes are {valid_sizes}\")\n        return\n\n    frame_buf = self.machine.memory.get_data(address, size)\n    table = self.machine.mmu.parse_hash_table(frame_buf, size, address)\n    if table is None:\n        logging.warning(\"Table not present or malformed\")\n    else:\n        print(table)\n</code></pre>"},{"location":"reference/architectures/ppc/#mmushell.architectures.ppc.MMUShell.do_show_hashtables","title":"<code>do_show_hashtables(args)</code>","text":"<p>Show hash tables found</p> Source code in <code>mmushell/architectures/ppc.py</code> <pre><code>def do_show_hashtables(self, args):\n    \"\"\"Show hash tables found\"\"\"\n    if not self.data.is_mem_parsed:\n        logger.warning(\"Please, parse the memory first\")\n        return\n\n    table = PrettyTable()\n    table.field_names = [\"Address\", \"Size\"]\n\n    for size in sorted(self.data.htables.keys()):\n        for htable in self.data.htables[size]:\n            table.add_row([hex(htable.address), hex(size)])\n\n    print(table)\n</code></pre>"},{"location":"reference/architectures/ppc/#mmushell.architectures.ppc.MMUShell.do_show_registers","title":"<code>do_show_registers(args)</code>","text":"<p>Show registers values found</p> Source code in <code>mmushell/architectures/ppc.py</code> <pre><code>def do_show_registers(self, args):\n    \"\"\"Show registers values found\"\"\"\n    if not self.data.is_registers_found:\n        logging.info(\"Please, find them first!\")\n        return\n\n    for registers in sorted(self.data.regs_values.keys()):\n        for register in self.data.regs_values[registers]:\n            print(register)\n</code></pre>"},{"location":"reference/architectures/ppc/#mmushell.architectures.ppc.MMUShellGTruth","title":"<code>MMUShellGTruth</code>","text":"<p>             Bases: <code>MMUShell</code></p> Source code in <code>mmushell/architectures/ppc.py</code> <pre><code>class MMUShellGTruth(MMUShell):\n    def do_show_hashtables_gtruth(self, args):\n        \"\"\"Show hash tables found and compare them with the ground truth\"\"\"\n        if not self.data.is_mem_parsed:\n            logger.warning(\"Please, parse the memory first\")\n            return\n\n        table = PrettyTable()\n        table.field_names = [\n            \"Address\",\n            \"Size\",\n            \"Found\",\n            \"Correct size\",\n            \"First seen\",\n            \"Last seen\",\n        ]\n\n        # Collect valid true table\n        valids = {}\n        for sdr1_value, sdr1_data in self.gtruth[\"SDR1\"].items():\n            sdr1_obj = SDR1(sdr1_value)\n            if not sdr1_obj.valid:\n                continue\n            valids[sdr1_obj.address] = [\n                sdr1_obj.size,\n                sdr1_data[\"first_seen\"],\n                sdr1_data[\"last_seen\"],\n            ]\n\n        # MMUShell found values\n        found = {}\n        for size in self.data.htables:\n            for table_obj in self.data.htables[size]:\n                found[table_obj.address] = [\n                    table_obj.size,\n                    \"False positive\",\n                    \"False positive\",\n                ]\n\n        already_visited = set()\n        for k, v in valids.items():\n            table.add_row(\n                [\n                    hex(k),\n                    hex(v[0]),\n                    \"X\" if k in found else \"\",\n                    \"X\"\n                    if v[0]\n                    == found.get(\n                        k,\n                        [\n                            None,\n                        ],\n                    )[0]\n                    else \"\",\n                    v[1],\n                    v[2],\n                ]\n            )\n            already_visited.add((k, v[0]))\n\n        fps = 0\n        for k, v in found.items():\n            if (k, v[0]) in already_visited:\n                continue\n            table.add_row([hex(k), hex(v[0]), \"\", \"\", v[1], v[2]])\n            fps += 1\n\n        print(table)\n        print(f\"FP: {fps}\")\n\n    def do_show_registers_gtruth(self, args):\n        \"\"\"Show registers value retrieved and compare with the ground truth\"\"\"\n        if not self.data.is_registers_found:\n            logging.info(\"Please, find them first!\")\n            return\n\n        # Check if the last value of SDR1 was found\n        last_sdr1 = SDR1(\n            sorted(\n                self.gtruth[\"SDR1\"].keys(),\n                key=lambda x: self.gtruth[\"SDR1\"][x][\"last_seen\"],\n                reverse=True,\n            )[0]\n        )\n        print(f\"Correct SDR1 value: {last_sdr1}\")\n        print(\n            \"SDR1 correct value... {}FOUND\".format(\n                \"\" if last_sdr1 in self.data.regs_values[\"SDR1\"] else \"NOT \"\n            )\n        )\n\n        # Found last BAT registers used by the system\n        bats_found = {}\n        for t in [\"I\", \"D\"]:\n            for i in range(4):\n                reg_name = t + \"BAT\" + str(i)\n                batu_v, batl_v = sorted(\n                    self.gtruth[reg_name].keys(),\n                    key=lambda x: self.gtruth[reg_name][x][1],\n                    reverse=True,\n                )[0]\n                bats_found[reg_name + \"U\"] = BATU(batu_v, reg_name + \"U\")\n                bats_found[reg_name + \"L\"] = BATL(batl_v, reg_name + \"L\")\n\n        # Check if values are found\n        for reg_name in bats_found:\n            print(\n                \"{} correct value... {}FOUND\\t\\t{}\".format(\n                    reg_name,\n                    \"\"\n                    if bats_found[reg_name] in self.data.regs_values[reg_name]\n                    else \"NOT \",\n                    bats_found[reg_name],\n                )\n            )\n</code></pre>"},{"location":"reference/architectures/ppc/#mmushell.architectures.ppc.MMUShellGTruth.do_show_hashtables_gtruth","title":"<code>do_show_hashtables_gtruth(args)</code>","text":"<p>Show hash tables found and compare them with the ground truth</p> Source code in <code>mmushell/architectures/ppc.py</code> <pre><code>def do_show_hashtables_gtruth(self, args):\n    \"\"\"Show hash tables found and compare them with the ground truth\"\"\"\n    if not self.data.is_mem_parsed:\n        logger.warning(\"Please, parse the memory first\")\n        return\n\n    table = PrettyTable()\n    table.field_names = [\n        \"Address\",\n        \"Size\",\n        \"Found\",\n        \"Correct size\",\n        \"First seen\",\n        \"Last seen\",\n    ]\n\n    # Collect valid true table\n    valids = {}\n    for sdr1_value, sdr1_data in self.gtruth[\"SDR1\"].items():\n        sdr1_obj = SDR1(sdr1_value)\n        if not sdr1_obj.valid:\n            continue\n        valids[sdr1_obj.address] = [\n            sdr1_obj.size,\n            sdr1_data[\"first_seen\"],\n            sdr1_data[\"last_seen\"],\n        ]\n\n    # MMUShell found values\n    found = {}\n    for size in self.data.htables:\n        for table_obj in self.data.htables[size]:\n            found[table_obj.address] = [\n                table_obj.size,\n                \"False positive\",\n                \"False positive\",\n            ]\n\n    already_visited = set()\n    for k, v in valids.items():\n        table.add_row(\n            [\n                hex(k),\n                hex(v[0]),\n                \"X\" if k in found else \"\",\n                \"X\"\n                if v[0]\n                == found.get(\n                    k,\n                    [\n                        None,\n                    ],\n                )[0]\n                else \"\",\n                v[1],\n                v[2],\n            ]\n        )\n        already_visited.add((k, v[0]))\n\n    fps = 0\n    for k, v in found.items():\n        if (k, v[0]) in already_visited:\n            continue\n        table.add_row([hex(k), hex(v[0]), \"\", \"\", v[1], v[2]])\n        fps += 1\n\n    print(table)\n    print(f\"FP: {fps}\")\n</code></pre>"},{"location":"reference/architectures/ppc/#mmushell.architectures.ppc.MMUShellGTruth.do_show_registers_gtruth","title":"<code>do_show_registers_gtruth(args)</code>","text":"<p>Show registers value retrieved and compare with the ground truth</p> Source code in <code>mmushell/architectures/ppc.py</code> <pre><code>def do_show_registers_gtruth(self, args):\n    \"\"\"Show registers value retrieved and compare with the ground truth\"\"\"\n    if not self.data.is_registers_found:\n        logging.info(\"Please, find them first!\")\n        return\n\n    # Check if the last value of SDR1 was found\n    last_sdr1 = SDR1(\n        sorted(\n            self.gtruth[\"SDR1\"].keys(),\n            key=lambda x: self.gtruth[\"SDR1\"][x][\"last_seen\"],\n            reverse=True,\n        )[0]\n    )\n    print(f\"Correct SDR1 value: {last_sdr1}\")\n    print(\n        \"SDR1 correct value... {}FOUND\".format(\n            \"\" if last_sdr1 in self.data.regs_values[\"SDR1\"] else \"NOT \"\n        )\n    )\n\n    # Found last BAT registers used by the system\n    bats_found = {}\n    for t in [\"I\", \"D\"]:\n        for i in range(4):\n            reg_name = t + \"BAT\" + str(i)\n            batu_v, batl_v = sorted(\n                self.gtruth[reg_name].keys(),\n                key=lambda x: self.gtruth[reg_name][x][1],\n                reverse=True,\n            )[0]\n            bats_found[reg_name + \"U\"] = BATU(batu_v, reg_name + \"U\")\n            bats_found[reg_name + \"L\"] = BATL(batl_v, reg_name + \"L\")\n\n    # Check if values are found\n    for reg_name in bats_found:\n        print(\n            \"{} correct value... {}FOUND\\t\\t{}\".format(\n                reg_name,\n                \"\"\n                if bats_found[reg_name] in self.data.regs_values[reg_name]\n                else \"NOT \",\n                bats_found[reg_name],\n            )\n        )\n</code></pre>"},{"location":"reference/architectures/riscv/","title":"RISC-V","text":""},{"location":"reference/architectures/riscv/#risc-v","title":"RISC-V","text":""},{"location":"reference/architectures/riscv/#mmushell.architectures.riscv.MMUShell","title":"<code>MMUShell</code>","text":"<p>             Bases: <code>MMUShell</code></p> Source code in <code>mmushell/architectures/riscv.py</code> <pre><code>class MMUShell(MMUShellDefault):\n    def __init__(self, completekey=\"tab\", stdin=None, stdout=None, machine={}):\n        super(MMUShell, self).__init__(completekey, stdin, stdout, machine)\n\n        if not self.data:\n            self.data = Data(\n                is_mem_parsed=False,\n                is_radix_found=False,\n                page_tables={\n                    \"global\": [\n                        {} for i in range(self.machine.mmu.radix_levels[\"global\"])\n                    ]\n                },\n                data_pages=[],\n                empty_tables=[],\n                reverse_map_tables=[\n                    defaultdict(set)\n                    for i in range(self.machine.mmu.radix_levels[\"global\"])\n                ],\n                reverse_map_pages=[\n                    defaultdict(set)\n                    for i in range(self.machine.mmu.radix_levels[\"global\"])\n                ],\n                satps={},\n            )\n\n    def do_parse_memory(self, args):\n        \"\"\"Parse memory to find tables\"\"\"\n        if self.data.is_mem_parsed:\n            logger.warning(\"Memory already parsed\")\n            return\n        self.parse_memory()\n        self.data.is_mem_parsed = True\n\n    def do_show_table(self, args):\n        \"\"\"Show MMU table. Usage: show_table ADDRESS [level]\"\"\"\n        args = args.split()\n        if len(args) &lt; 1:\n            logger.warning(\"Missing table address\")\n            return\n\n        try:\n            addr = self.parse_int(args[0])\n        except ValueError:\n            logger.warning(\"Invalid table address\")\n            return\n\n        if addr not in self.machine.memory:\n            logger.warning(\"Table not in RAM range\")\n            return\n\n        lvl = -1\n        if len(args) &gt; 1:\n            try:\n                lvl = self.parse_int(args[1])\n                if lvl &gt; self.machine.mmu.radix_levels[\"global\"] - 1:\n                    raise ValueError\n            except ValueError:\n                logger.warning(\n                    \"Level must be an integer between 0 and {}\".format(\n                        str(self.machine.mmu.radix_levels[\"global\"] - 1)\n                    )\n                )\n                return\n\n        if lvl == -1:\n            table_size = self.machine.mmu.PAGE_SIZE\n        else:\n            table_size = self.machine.mmu.map_level_to_table_size[\"global\"][lvl]\n        table_buff = self.machine.memory.get_data(addr, self.machine.mmu.PAGE_SIZE)\n        invalids, pt_classes, table_obj = self.machine.mmu.parse_frame(\n            table_buff, addr, table_size, lvl\n        )\n        print(table_obj)\n        print(f\"Invalid entries: {invalids} Table levels: {pt_classes}\")\n\n    def parse_memory(self):\n        logger.info(\"Look for paging tables...\")\n        parallel_results = self.machine.apply_parallel(\n            self.machine.mmu.PAGE_SIZE, self.machine.mmu.parse_parallel_frame\n        )\n        logger.info(\"Reaggregate threads data...\")\n        for result in parallel_results:\n            page_tables, data_pages, empty_tables = result.get()\n\n            for level in range(self.machine.mmu.radix_levels[\"global\"]):\n                self.data.page_tables[\"global\"][level].update(page_tables[level])\n\n            self.data.data_pages.extend(data_pages)\n            self.data.empty_tables.extend(empty_tables)\n\n        self.data.data_pages = set(self.data.data_pages)\n        self.data.empty_tables = set(self.data.empty_tables)\n\n        logger.info(\"Reduce false positives...\")\n        # Remove all tables which point to inexistent table of lower level\n        for lvl in range(self.machine.mmu.radix_levels[\"global\"] - 1):\n            ptr_class = self.machine.mmu.map_ptr_entries_to_levels[\"global\"][lvl]\n\n            referenced_nxt = []\n            for table_addr in list(self.data.page_tables[\"global\"][lvl].keys()):\n                for entry_obj in (\n                    self.data.page_tables[\"global\"][lvl][table_addr]\n                    .entries[ptr_class]\n                    .values()\n                ):\n                    if (\n                        entry_obj.address\n                        not in self.data.page_tables[\"global\"][lvl + 1]\n                        and entry_obj.address not in self.data.empty_tables\n                    ):\n                        # Remove the table\n                        self.data.page_tables[\"global\"][lvl].pop(table_addr)\n                        break\n\n                    else:\n                        referenced_nxt.append(entry_obj.address)\n\n            # Remove table not referenced by upper levels\n            referenced_nxt = set(referenced_nxt)\n            for table_addr in set(\n                self.data.page_tables[\"global\"][lvl + 1].keys()\n            ).difference(referenced_nxt):\n                self.data.page_tables[\"global\"][lvl + 1].pop(table_addr)\n\n        logger.info(\"Fill reverse maps...\")\n        for lvl in range(0, self.machine.mmu.radix_levels[\"global\"]):\n            ptr_class = self.machine.mmu.map_ptr_entries_to_levels[\"global\"][lvl]\n            page_class = self.machine.mmu.map_datapages_entries_to_levels[\"global\"][\n                lvl\n            ][\n                0\n            ]  # Trick: it has only one dataclass per level\n            for table_addr, table_obj in self.data.page_tables[\"global\"][lvl].items():\n                for entry_obj in table_obj.entries[ptr_class].values():\n                    self.data.reverse_map_tables[lvl][entry_obj.address].add(\n                        table_obj.address\n                    )\n                for entry_obj in table_obj.entries[page_class].values():\n                    self.data.reverse_map_pages[lvl][entry_obj.address].add(\n                        table_obj.address\n                    )\n\n    def do_find_radix_trees(self, args):\n        \"\"\"Reconstruct radix trees\"\"\"\n        if not self.data.is_mem_parsed:\n            logging.info(\"Please, parse the memory first!\")\n            return\n\n        # Some table level was not found...\n        if not len(self.data.page_tables[\"global\"][0]):\n            logger.warning(\"OOPS... no tables in first level... Wrong MMU mode?\")\n            return\n\n        # Go back from PTLn up to top level, the particular form of PTLn permits to find PTL0\n        logging.info(\"Go up the paging trees starting from data pages...\")\n        candidates = []\n        already_explored = set()\n        for page_addr in tqdm(self.data.data_pages):\n            derived_addresses = self.machine.mmu.derive_page_address(page_addr)\n            for derived_address in derived_addresses:\n                if derived_address in already_explored:\n                    continue\n                lvl, addr = derived_address\n                candidates.extend(\n                    self.radix_roots_from_data_page(\n                        lvl,\n                        addr,\n                        self.data.reverse_map_pages,\n                        self.data.reverse_map_tables,\n                    )\n                )\n                already_explored.add(derived_address)\n        candidates = list(\n            set(candidates).intersection(self.data.page_tables[\"global\"][0].keys())\n        )\n        candidates.sort()\n\n        logger.info(\"Filter candidates...\")\n        satps = {}\n        for candidate in tqdm(candidates):\n            # Obtain radix tree infos\n            consistency, pas = self.physpace(\n                candidate, self.data.page_tables[\"global\"], self.data.empty_tables\n            )\n\n            # Only consistent trees are valid\n            if not consistency:\n                continue\n\n            # Esclude empty trees\n            if pas.get_kernel_size() == pas.get_user_size() == 0:\n                continue\n\n            vas = self.virtspace(candidate, 0, self.machine.mmu.top_prefix)\n            satps[candidate] = RadixTree(candidate, 0, pas, vas)\n\n        self.data.satps = satps\n        self.data.is_radix_found = True\n\n    def do_show_radix_trees(self, args):\n        \"\"\"Show found radix trees\"\"\"\n        if not self.data.is_radix_found:\n            logging.info(\"Please, find them first!\")\n            return\n\n        labels = [\n            \"Radix address\",\n            \"First level\",\n            \"Kernel size (Bytes)\",\n            \"User size (Bytes)\",\n        ]\n        table = PrettyTable()\n        table.field_names = labels\n        for satp in self.data.satps.values():\n            table.add_row(satp.entry_resume_stringified())\n        table.sortby = \"Radix address\"\n        print(table)\n</code></pre>"},{"location":"reference/architectures/riscv/#mmushell.architectures.riscv.MMUShell.do_find_radix_trees","title":"<code>do_find_radix_trees(args)</code>","text":"<p>Reconstruct radix trees</p> Source code in <code>mmushell/architectures/riscv.py</code> <pre><code>def do_find_radix_trees(self, args):\n    \"\"\"Reconstruct radix trees\"\"\"\n    if not self.data.is_mem_parsed:\n        logging.info(\"Please, parse the memory first!\")\n        return\n\n    # Some table level was not found...\n    if not len(self.data.page_tables[\"global\"][0]):\n        logger.warning(\"OOPS... no tables in first level... Wrong MMU mode?\")\n        return\n\n    # Go back from PTLn up to top level, the particular form of PTLn permits to find PTL0\n    logging.info(\"Go up the paging trees starting from data pages...\")\n    candidates = []\n    already_explored = set()\n    for page_addr in tqdm(self.data.data_pages):\n        derived_addresses = self.machine.mmu.derive_page_address(page_addr)\n        for derived_address in derived_addresses:\n            if derived_address in already_explored:\n                continue\n            lvl, addr = derived_address\n            candidates.extend(\n                self.radix_roots_from_data_page(\n                    lvl,\n                    addr,\n                    self.data.reverse_map_pages,\n                    self.data.reverse_map_tables,\n                )\n            )\n            already_explored.add(derived_address)\n    candidates = list(\n        set(candidates).intersection(self.data.page_tables[\"global\"][0].keys())\n    )\n    candidates.sort()\n\n    logger.info(\"Filter candidates...\")\n    satps = {}\n    for candidate in tqdm(candidates):\n        # Obtain radix tree infos\n        consistency, pas = self.physpace(\n            candidate, self.data.page_tables[\"global\"], self.data.empty_tables\n        )\n\n        # Only consistent trees are valid\n        if not consistency:\n            continue\n\n        # Esclude empty trees\n        if pas.get_kernel_size() == pas.get_user_size() == 0:\n            continue\n\n        vas = self.virtspace(candidate, 0, self.machine.mmu.top_prefix)\n        satps[candidate] = RadixTree(candidate, 0, pas, vas)\n\n    self.data.satps = satps\n    self.data.is_radix_found = True\n</code></pre>"},{"location":"reference/architectures/riscv/#mmushell.architectures.riscv.MMUShell.do_parse_memory","title":"<code>do_parse_memory(args)</code>","text":"<p>Parse memory to find tables</p> Source code in <code>mmushell/architectures/riscv.py</code> <pre><code>def do_parse_memory(self, args):\n    \"\"\"Parse memory to find tables\"\"\"\n    if self.data.is_mem_parsed:\n        logger.warning(\"Memory already parsed\")\n        return\n    self.parse_memory()\n    self.data.is_mem_parsed = True\n</code></pre>"},{"location":"reference/architectures/riscv/#mmushell.architectures.riscv.MMUShell.do_show_radix_trees","title":"<code>do_show_radix_trees(args)</code>","text":"<p>Show found radix trees</p> Source code in <code>mmushell/architectures/riscv.py</code> <pre><code>def do_show_radix_trees(self, args):\n    \"\"\"Show found radix trees\"\"\"\n    if not self.data.is_radix_found:\n        logging.info(\"Please, find them first!\")\n        return\n\n    labels = [\n        \"Radix address\",\n        \"First level\",\n        \"Kernel size (Bytes)\",\n        \"User size (Bytes)\",\n    ]\n    table = PrettyTable()\n    table.field_names = labels\n    for satp in self.data.satps.values():\n        table.add_row(satp.entry_resume_stringified())\n    table.sortby = \"Radix address\"\n    print(table)\n</code></pre>"},{"location":"reference/architectures/riscv/#mmushell.architectures.riscv.MMUShell.do_show_table","title":"<code>do_show_table(args)</code>","text":"<p>Show MMU table. Usage: show_table ADDRESS [level]</p> Source code in <code>mmushell/architectures/riscv.py</code> <pre><code>def do_show_table(self, args):\n    \"\"\"Show MMU table. Usage: show_table ADDRESS [level]\"\"\"\n    args = args.split()\n    if len(args) &lt; 1:\n        logger.warning(\"Missing table address\")\n        return\n\n    try:\n        addr = self.parse_int(args[0])\n    except ValueError:\n        logger.warning(\"Invalid table address\")\n        return\n\n    if addr not in self.machine.memory:\n        logger.warning(\"Table not in RAM range\")\n        return\n\n    lvl = -1\n    if len(args) &gt; 1:\n        try:\n            lvl = self.parse_int(args[1])\n            if lvl &gt; self.machine.mmu.radix_levels[\"global\"] - 1:\n                raise ValueError\n        except ValueError:\n            logger.warning(\n                \"Level must be an integer between 0 and {}\".format(\n                    str(self.machine.mmu.radix_levels[\"global\"] - 1)\n                )\n            )\n            return\n\n    if lvl == -1:\n        table_size = self.machine.mmu.PAGE_SIZE\n    else:\n        table_size = self.machine.mmu.map_level_to_table_size[\"global\"][lvl]\n    table_buff = self.machine.memory.get_data(addr, self.machine.mmu.PAGE_SIZE)\n    invalids, pt_classes, table_obj = self.machine.mmu.parse_frame(\n        table_buff, addr, table_size, lvl\n    )\n    print(table_obj)\n    print(f\"Invalid entries: {invalids} Table levels: {pt_classes}\")\n</code></pre>"},{"location":"reference/architectures/riscv/#mmushell.architectures.riscv.MMUShellGTruth","title":"<code>MMUShellGTruth</code>","text":"<p>             Bases: <code>MMUShell</code></p> Source code in <code>mmushell/architectures/riscv.py</code> <pre><code>class MMUShellGTruth(MMUShell):\n    def do_show_radix_trees_gtruth(self, args):\n        \"\"\"Compare found radix trees with the gound truth\"\"\"\n        if not self.data.is_radix_found:\n            logging.info(\"Please, find them first!\")\n            return\n\n        # Parse TP SATPs\n        satp_tp = {}\n        for satp in self.gtruth[\"SATP\"]:\n            new_satp = SATP(satp)\n            if new_satp.address in satp_tp:\n                continue\n\n            # Validate SATP\n            if new_satp.address not in self.data.page_tables[\"global\"][0]:\n                continue\n\n            consistency, pas = self.physpace(\n                new_satp.address,\n                self.data.page_tables[\"global\"],\n                self.data.empty_tables,\n            )\n            if not consistency or (\n                not pas.get_kernel_size() and not pas.get_user_size()\n            ):\n                continue\n            satp_tp[new_satp.address] = new_satp\n\n        # True positives, false negatives, false positives\n        tps = set(satp_tp.keys()).intersection(set(self.data.satps.keys()))\n        fns = set(satp_tp.keys()).difference(set(self.data.satps.keys()))\n        fps = set(self.data.satps.keys()).difference(set(satp_tp.keys()))\n\n        # Show results\n        table = PrettyTable()\n        table.field_names = [\"Address\", \"Found\", \"First seen\", \"Last seen\"]\n        for tp in sorted(tps):\n            table.add_row(\n                [\n                    hex(tp),\n                    \"X\",\n                    self.gtruth[\"SATP\"][satp_tp[tp].satp][0],\n                    self.gtruth[\"SATP\"][satp_tp[tp].satp][1],\n                ]\n            )\n\n        for fn in sorted(fns):\n            table.add_row(\n                [\n                    hex(fn),\n                    \"\",\n                    self.gtruth[\"SATP\"][satp_tp[fn].satp][0],\n                    self.gtruth[\"SATP\"][satp_tp[fn].satp][1],\n                ]\n            )\n\n        for fp in sorted(fps):\n            table.add_row([hex(fp), \"False positive\", \"\", \"\"])\n\n        print(table)\n        print(f\"TP:{len(tps)} FN:{len(fns)} FP:{len(fps)}\")\n\n        # Export results for next analysis\n        if len(args):\n            from pickle import dump as dump_p\n\n            with open(\"dump.mmu\", \"wb\") as f:\n                results = [{\"satp\": tp} for tp in sorted(tps)]\n                dump_p(results, f)\n</code></pre>"},{"location":"reference/architectures/riscv/#mmushell.architectures.riscv.MMUShellGTruth.do_show_radix_trees_gtruth","title":"<code>do_show_radix_trees_gtruth(args)</code>","text":"<p>Compare found radix trees with the gound truth</p> Source code in <code>mmushell/architectures/riscv.py</code> <pre><code>def do_show_radix_trees_gtruth(self, args):\n    \"\"\"Compare found radix trees with the gound truth\"\"\"\n    if not self.data.is_radix_found:\n        logging.info(\"Please, find them first!\")\n        return\n\n    # Parse TP SATPs\n    satp_tp = {}\n    for satp in self.gtruth[\"SATP\"]:\n        new_satp = SATP(satp)\n        if new_satp.address in satp_tp:\n            continue\n\n        # Validate SATP\n        if new_satp.address not in self.data.page_tables[\"global\"][0]:\n            continue\n\n        consistency, pas = self.physpace(\n            new_satp.address,\n            self.data.page_tables[\"global\"],\n            self.data.empty_tables,\n        )\n        if not consistency or (\n            not pas.get_kernel_size() and not pas.get_user_size()\n        ):\n            continue\n        satp_tp[new_satp.address] = new_satp\n\n    # True positives, false negatives, false positives\n    tps = set(satp_tp.keys()).intersection(set(self.data.satps.keys()))\n    fns = set(satp_tp.keys()).difference(set(self.data.satps.keys()))\n    fps = set(self.data.satps.keys()).difference(set(satp_tp.keys()))\n\n    # Show results\n    table = PrettyTable()\n    table.field_names = [\"Address\", \"Found\", \"First seen\", \"Last seen\"]\n    for tp in sorted(tps):\n        table.add_row(\n            [\n                hex(tp),\n                \"X\",\n                self.gtruth[\"SATP\"][satp_tp[tp].satp][0],\n                self.gtruth[\"SATP\"][satp_tp[tp].satp][1],\n            ]\n        )\n\n    for fn in sorted(fns):\n        table.add_row(\n            [\n                hex(fn),\n                \"\",\n                self.gtruth[\"SATP\"][satp_tp[fn].satp][0],\n                self.gtruth[\"SATP\"][satp_tp[fn].satp][1],\n            ]\n        )\n\n    for fp in sorted(fps):\n        table.add_row([hex(fp), \"False positive\", \"\", \"\"])\n\n    print(table)\n    print(f\"TP:{len(tps)} FN:{len(fns)} FP:{len(fps)}\")\n\n    # Export results for next analysis\n    if len(args):\n        from pickle import dump as dump_p\n\n        with open(\"dump.mmu\", \"wb\") as f:\n            results = [{\"satp\": tp} for tp in sorted(tps)]\n            dump_p(results, f)\n</code></pre>"}]}